{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Constructions\n",
    "\n",
    "Towards a usage-based, constructional taxonomy of time indicators in Biblical Hebrew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.4.11\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "142 features found and 4 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.15s B g_cons_utf8          from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.10s B lex                  from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.11s B vs                   from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.10s B vt                   from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.10s B pdp                  from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.13s B gloss                from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.11s B language             from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.17s B rela                 from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.18s B typ                  from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.22s B number               from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.13s B function             from /Users/cody/github/csl/time_collocations/data\n",
      "   |     0.11s B prs                  from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.11s B nu                   from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.21s B mother               from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.10s B st                   from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.11s B uvf                  from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.41s B head                 from /Users/cody/github/etcbc/heads/tf/c\n",
      "   |     0.28s B nhead                from /Users/cody/github/etcbc/heads/tf/c\n",
      "   |     0.21s B obj_prep             from /Users/cody/github/etcbc/heads/tf/c\n",
      "   |     0.03s B sem_set              from /Users/cody/github/etcbc/heads/tf/c\n",
      "   |     0.11s B ls                   from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.09s B topAssoc             from /Users/cody/github/csl/time_collocations/data/funct_associations\n",
      "   |     0.07s B TimeAssoc            from /Users/cody/github/csl/time_collocations/data/funct_associations\n",
      "   |     0.07s B LocaAssoc            from /Users/cody/github/csl/time_collocations/data/funct_associations\n",
      "   |     0.02s B label                from /Users/cody/github/csl/time_collocations/data\n",
      "   |     0.00s B role                 from /Users/cody/github/csl/time_collocations/data\n",
      "  9.48s All features loaded/computed - for details use loadLog()\n",
      "TF app is up-to-date.\n",
      "Using annotation/app-bhsa commit d3cf8f0c2ab5d690a0fda14ea31c33da5c5c8483 (=latest)\n",
      "  in /Users/cody/text-fabric-data/__apps__/bhsa.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src:\n",
       "    local(\"SILEOT.ttf\"),\n",
       "    url(\"https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.woff?raw=true\");\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0a6611;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    direction: ltr;\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -0.1rem 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: x-small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 0.1em 0em;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-style: italic;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".ltr {\n",
       "    direction: ltr ! important;\n",
       "}\n",
       ".verse {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".vl {\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-end;\n",
       "    align-items: flex-end;\n",
       "    direction: ltr;\n",
       "    width: 100%;\n",
       "}\n",
       ".outeritem {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".sentence,.clause,.phrase {\n",
       "    margin-top: -1.2em;\n",
       "    margin-left: 1em;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 0.3em;\n",
       "    border-style: solid;\n",
       "    border-radius: 0.2em;\n",
       "    font-size: small;\n",
       "    display: block;\n",
       "    width: fit-content;\n",
       "    max-width: fit-content;\n",
       "    direction: ltr;\n",
       "}\n",
       ".atoms {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".satom,.catom,.patom {\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    border-radius: 0.3em;\n",
       "    border-style: solid;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".sentence {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".clause {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".phrase {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".satom {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 4px;\n",
       "}\n",
       ".catom {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".patom {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".word {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 1px solid #cccccc;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".lextp {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 2px solid #888888;\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".occs {\n",
       "    font-size: x-small;\n",
       "}\n",
       ".satom.l,.catom.l,.patom.l {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".satom.r,.catom.r,.patom.r {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".satom.lno,.catom.lno,.patom.lno {\n",
       "    border-left-style: none\n",
       "}\n",
       ".satom.rno,.catom.rno,.patom.rno {\n",
       "    border-right-style: none\n",
       "}\n",
       ".tr,.tr a:visited,.tr a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".trb,.trb a:visited,.trb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: normal;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".prb,.prb a:visited,.prb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".h,.h a:visited,.h a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".hb,.hb a:visited,.hb a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    line-height: 2;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".vn {\n",
       "  font-size: small !important;\n",
       "  padding-right: 1em;\n",
       "}\n",
       ".rela,.function,.typ {\n",
       "    font-family: monospace;\n",
       "    font-size: small;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".pdp,.pdp a:visited,.pdp a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".voc_lex {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vs {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vt {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".gloss {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #444444;\n",
       "}\n",
       ".vrs {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: #444444;\n",
       "}\n",
       ".nd {\n",
       "    font-family: monospace;\n",
       "    font-size: x-small;\n",
       "    color: #999999;\n",
       "}\n",
       ".hl {\n",
       "    background-color: #ffee66;\n",
       "}\n",
       "span.hldot {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder: 0.2rem solid var(--hl-rim);\n",
       "\tborder-radius: 0.4rem;\n",
       "\t/*\n",
       "\tdisplay: inline-block;\n",
       "\twidth: 0.8rem;\n",
       "\theight: 0.8rem;\n",
       "\t*/\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "\n",
       "span.hlup {\n",
       "\tborder-color: var(--hl-dark);\n",
       "\tborder-width: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 0.2rem;\n",
       "  padding: 0.2rem;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55, 100%,  60%, 0.9  );\n",
       "\t--hl-dark:          hsla( 55, 100%,  40%, 0.9  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import collections, csv, random\n",
    "from textwrap import indent\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5, style='whitegrid')\n",
    "import matplotlib.pyplot as plt\n",
    "from tf.fabric import Fabric\n",
    "from tf.app import use\n",
    "\n",
    "custom_data = ['/Users/cody/text-fabric-data/etcbc/bhsa/tf/c',\n",
    "               '/Users/cody/github/etcbc/heads/tf/c',\n",
    "               '../data/',\n",
    "               '../data/funct_associations/'\n",
    "              ]\n",
    "\n",
    "TF = Fabric(locations=custom_data)\n",
    "api = TF.load('''\n",
    "\n",
    "vs vt pdp gloss lex language \n",
    "rela typ number function prs\n",
    "g_cons_utf8 nu mother st uvf\n",
    "head nhead obj_prep sem_set\n",
    "ls topAssoc TimeAssoc LocaAssoc\n",
    "label role\n",
    "''')\n",
    "\n",
    "A = use('bhsa', api=api, hoist=globals(), silent=True)\n",
    "\n",
    "A.displaySetup(condenseType='clause', condensed=True, withNodes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLex(lex_str):\n",
    "    '''\n",
    "    Finds a lex node.\n",
    "    '''\n",
    "    return [(l, F.gloss.v(l), F.lex.v(l)) \n",
    "                for l in F.otype.s('lex')\n",
    "                if lex_str == F.lex.v(l)]\n",
    "\n",
    "\n",
    "# map lexeme 2 surface forms here\n",
    "lex2token = {}\n",
    "\n",
    "# map def article to ה (for cases of unconsonantal versions)\n",
    "lex2token[1437572] = 'ha'\n",
    "\n",
    "# map cardinals to מ׳׳\n",
    "for lex in F.otype.s('lex'):\n",
    "    if F.ls.v(lex) == 'card':\n",
    "        lex2token[lex] = 'card'\n",
    "\n",
    "def tokenWord(wordnode, lex_mapping=lex2token):\n",
    "    '''\n",
    "    Tokenizes a word. If lexeme is mapped,\n",
    "    uses mapped string. Otherwise uses g_cons_utf8\n",
    "    '''\n",
    "    lex = L.u(wordnode, 'lex')[0]\n",
    "    return lex2token.get(lex, F.pdp.v(wordnode))\n",
    "\n",
    "def tokenSP(wordnode):\n",
    "    state = '-c' if F.st.v(wordnode) == 'c' else ''\n",
    "    return F.pdp.v(wordnode) + state\n",
    "\n",
    "def tokenPhrase(phrasenode, tokener=tokenWord):\n",
    "    '''\n",
    "    Tokenizes a phrase with\n",
    "    dot-separated words.\n",
    "    input: phrase node number\n",
    "    output: token string\n",
    "    '''\n",
    "    words = [tokener(w) for w in L.d(phrasenode, 'word')]\n",
    "    return '.'.join(words)\n",
    "\n",
    "def flattenNodes(nodeList):\n",
    "    '''\n",
    "    Takes any list of mixed node types\n",
    "    and flattens them to a list of slots.\n",
    "    '''\n",
    "    slots = []\n",
    "    for n in nodeList:\n",
    "        if F.otype.v(n) == 'word':\n",
    "            slots.append(n)\n",
    "        else:\n",
    "            slots.extend(L.d(n, 'word'))\n",
    "    return sorted(set(slots))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare to Write Construction Objects\n",
    "\n",
    "Previously calculated database features are loaded so they are included in eventual export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeFeatures = collections.defaultdict(lambda:collections.defaultdict())\n",
    "nodeFeatures = collections.defaultdict(lambda:collections.defaultdict())\n",
    "node = max(N())\n",
    "\n",
    "# add previously calculated features\n",
    "nodeFeatures['otype'] = dict((n, F.otype.v(n)) for n in N())\n",
    "edgeFeatures['oslots'] = dict((n, L.d(n, 'word')) for n in N() if F.otype.v(n) != 'word')\n",
    "nodeFeatures['label'] = dict((n, F.label.v(n)) for n in N() if F.label.v(n))\n",
    "nodeFeatures['role'] = {} # role\n",
    "for n in N():\n",
    "    for mother, role in E.role.f(n):\n",
    "        nodeFeatures['role'][n] = {mother:role}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Time Phrase Dispersion\n",
    "\n",
    "This analysis of time constructions is based on frequency. In a usage-based approach to language, highly frequent terms are the prototypes which other structures in the language are based on. In the analysis of time constructions, the top occurring surface forms, or tokens, are proposed to represent the primary means of representing time. However, raw frequencies can be misleading. For this reason, we apply a frequency adjustment as suggested by Stefan Gries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.61s 3376 results\n"
     ]
    }
   ],
   "source": [
    "time_tokens = collections.defaultdict(lambda:collections.Counter())\n",
    "time_phrases = set()\n",
    "explore2results = collections.defaultdict(list)\n",
    "\n",
    "times = A.search('''\n",
    "\n",
    "phrase2 function=Time\n",
    "/without/\n",
    "    word lex=>K|>Z|<TH|KN\n",
    "/-/\n",
    "    word language=Hebrew\n",
    "\n",
    "''', shallow=True)\n",
    "\n",
    "for tp in times:\n",
    "    token = tokenPhrase(tp, tokener=tokenWord)\n",
    "    book, chapter, verse = T.sectionFromNode(tp)\n",
    "    time_tokens[book][token] += 1\n",
    "    explore2results[token].append((tp,))\n",
    "    time_phrases.add(tp)\n",
    "    \n",
    "time_tokens = pd.DataFrame(time_tokens).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345, 39)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prep.subs</th>\n",
       "      <td>472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.ha.subs.ha.prde</th>\n",
       "      <td>427.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.ha.subs</th>\n",
       "      <td>298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ha.subs</th>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card.subs</th>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advb</th>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.subs.subs</th>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.ha.subs.ha.adjv</th>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subs.ha.subs</th>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.subs.ha.subs</th>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subs.subs</th>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.inrg</th>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep</th>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card.conj.card.subs</th>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subs</th>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subs.subs.subs</th>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ha.subs.ha.prde</th>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card.card.subs</th>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.subs.nmpr</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.subs.card</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0\n",
       "prep.subs             472.0\n",
       "prep.ha.subs.ha.prde  427.0\n",
       "prep.ha.subs          298.0\n",
       "ha.subs               216.0\n",
       "card.subs             205.0\n",
       "advb                  179.0\n",
       "prep.subs.subs        173.0\n",
       "prep.ha.subs.ha.adjv  148.0\n",
       "subs.ha.subs          101.0\n",
       "prep.subs.ha.subs      83.0\n",
       "subs.subs              49.0\n",
       "prep.inrg              39.0\n",
       "prep                   33.0\n",
       "card.conj.card.subs    31.0\n",
       "subs                   31.0\n",
       "subs.subs.subs         30.0\n",
       "ha.subs.ha.prde        30.0\n",
       "card.card.subs         29.0\n",
       "prep.subs.nmpr         24.0\n",
       "prep.subs.card         24.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(time_tokens.sum(1).sort_values(ascending=False)).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "showme = explore2results['subs.subs']\n",
    "\n",
    "#A.show([L.d(res[0]) for res in showme], end=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Constructions\n",
    "\n",
    "Attempting to describe the most productive constructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2results = collections.defaultdict(list)\n",
    "found_phrases = set()\n",
    "\n",
    "def show_progress(setA, setB):\n",
    "    lenA, lenB = len(setA), len(setB)\n",
    "    print(f'{lenA} / {lenB}\\t{round(lenA/lenB, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. prep + H + timeNoun + H + demonstrative/ordinal/other\n",
    "\n",
    "The ב.ה.יום.ה.הוא construction is the most common with a relatively high DP score of (0.56), and there are numerous similar variants of this construction. Below I aim to represent this construction abstractly, with each of the pieces constructed with parts of speech fillers. I want to see how much of the data this construction accounts for, and I want to compare its distribution and use accross other categories and functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.51s 715 results\n",
      "\n",
      "696 / 3376\t0.21\n"
     ]
    }
   ],
   "source": [
    "hh_cx = A.search('''\n",
    "\n",
    "phrase2 function=Time\n",
    "    chunk label=prep\n",
    "    <: word lex=H language=Hebrew\n",
    "    <: word pdp=subs\n",
    "    <: word lex=H\n",
    "    <: word\n",
    "    /with/\n",
    "    pdp=prde\n",
    "    /or/\n",
    "    ls=ordn\n",
    "    /-/\n",
    "\n",
    "''')\n",
    "\n",
    "hh_name = 'prep_H_time_H_{}'\n",
    "token2results[hh_name] = hh_cx\n",
    "\n",
    "# log time construction object\n",
    "for result in hh_cx:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    named_slot = 'demon' if F.pdp.v(result[5]) == 'prde' else 'ordinal'\n",
    "    nodeFeatures['label'][node] = hh_name.format(named_slot)\n",
    "    edgeFeatures['oslot'][node] = tuple(L.d(result[1], 'word')) + result[2:]\n",
    "    edgeFeatures['role'][result[2]] = {'timenoun':node}\n",
    "    edgeFeatures['role'][result[1]] = {'orient':node}\n",
    "    edgeFeatures['role'][result[-1]] = {named_slot:node}\n",
    "\n",
    "# report progress\n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(hh_cx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 ø + H + timeNoun + H + demonstrative/ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.52s 35 results\n",
      "\n",
      "731 / 3376\t0.22\n"
     ]
    }
   ],
   "source": [
    "hh_cx = A.search('''\n",
    "\n",
    "phrase2 function=Time\n",
    "/without/\n",
    "    chunk label=prep\n",
    "/-/\n",
    "    word lex=H language=Hebrew\n",
    "    <: word pdp=subs\n",
    "    <: word lex=H\n",
    "    <: word\n",
    "    /with/\n",
    "    pdp=prde\n",
    "    /or/\n",
    "    ls=ordn\n",
    "    /-/\n",
    "\n",
    "''')\n",
    "\n",
    "hh_name = 'H_time_H_{}'\n",
    "token2results[hh_name] = hh_cx\n",
    "\n",
    "# log time construction object\n",
    "for result in hh_cx:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    named_slot = 'demon' if F.pdp.v(result[-1]) == 'prde' else 'ordinal'\n",
    "    nodeFeatures['label'][node] = hh_name.format(named_slot)\n",
    "    edgeFeatures['oslot'][node] = tuple(L.d(result[1], 'word')) + result[2:]\n",
    "    edgeFeatures['role'][result[2]] = {'timenoun':node}\n",
    "    edgeFeatures['role'][result[1]] = {'orient':node}\n",
    "    edgeFeatures['role'][result[-1]] = {named_slot:node}\n",
    "\n",
    "# report progress\n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. H + timeNoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.74s 216 results\n",
      "\n",
      "947 / 3376\t0.28\n"
     ]
    }
   ],
   "source": [
    "the_cx = A.search('''\n",
    "\n",
    "p:phrase2 function=Time\n",
    "    =: word lex=H language=Hebrew\n",
    "    <: w1:word pdp=subs\n",
    "p := w1\n",
    "\n",
    "''')\n",
    "\n",
    "the_cx_name = 'H_time'\n",
    "token2results[the_cx_name] = the_cx\n",
    "\n",
    "for result in the_cx:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    nodeFeatures['label'][node] = the_cx_name\n",
    "    edgeFeatures['oslot'][node] = L.d(result[0], 'word')\n",
    "    edgeFeatures['role'][result[2]] = {'timenoun':node}\n",
    "    edgeFeatures['role'][result[1]] = {'H':node}\n",
    "    \n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(the_cx, condenseType='sentence', extraFeatures='st')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Quantified Constructions (מ׳׳)\n",
    "\n",
    "Time constructions with quantifiers seem to inherit the quantified NP construction, and there are thus relatively complex chains that are formed. These constructions are pre-processed into quantifier constructions in [quantifier_constructions.ipynb](preprocessing/quantifier_constructions.ipynb). The result is a new object, constructions, and constructions with a label of 'quantified_NP' are base units of constructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Quantifier Construction Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenQuants(phrasenode):\n",
    "    '''\n",
    "    Generic tokenizer\n",
    "    for non-tagged constructions.\n",
    "    '''\n",
    "    \n",
    "    words = list(L.d(phrasenode, 'word'))\n",
    "    token = []\n",
    "    i = 0 \n",
    "    while i < len(words):\n",
    "        word = words[i]\n",
    "        i += 1\n",
    "        \n",
    "        construct = next((c for c in L.u(word, 'chunk') if F.label.v(c) != 'prep'), 0)\n",
    "\n",
    "        # replace quantified cx\n",
    "        if construct:\n",
    "            \n",
    "            if F.label.v(construct) in {'quant_NP', 'quant_NP_chain'}:\n",
    "            \n",
    "                construct = sorted((len(L.d(cx, 'word')), cx)\n",
    "                                    for cx in L.u(word, 'chunk')\n",
    "                                    if 'quant_NP' in F.label.v(cx))[-1][1]\n",
    "                token.append('מד׳׳')\n",
    "\n",
    "            elif F.label.v(construct) == 'quant':\n",
    "                token.append('מ׳׳')\n",
    "                \n",
    "            # skip subsequent words in the construction\n",
    "            i += len(L.d(construct, 'word'))-1\n",
    "\n",
    "            \n",
    "        elif F.lex.v(word) == 'H':\n",
    "            token.append('ה')\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            if token and token[0] == 'מד׳׳': # ignore additional modifiers\n",
    "                token = ['מד׳׳']\n",
    "                i = len(words)\n",
    "            \n",
    "            else:\n",
    "                token.append(F.g_cons_utf8.v(word))\n",
    "            \n",
    "    return '.'.join(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.44s 165 results\n",
      "  1.54s 165 results\n",
      "  0.81s 54 results\n",
      "\n",
      " 202 phrases accounted for in these loops\n"
     ]
    }
   ],
   "source": [
    "qmeta = [] # put all construction data here\n",
    "count_quants = collections.Counter()\n",
    "\n",
    "prep_time_l_time = A.search('''\n",
    "\n",
    "sentence\n",
    "    chunk label=prep\n",
    "    <: word st=c ls#card\n",
    "    <1: c1:chunk label=quant_NP|quant_NP_chain|quant\n",
    "    /with/\n",
    "    :> word pdp=art\n",
    "    /or/\n",
    "    :> word st=c ls#card\n",
    "    /-/\n",
    "    \n",
    "    /without/\n",
    "    chunk\n",
    "        ..\n",
    "    /-/\n",
    "        word\n",
    "    w1:word lex=L language=Hebrew\n",
    "    <: word sem_set#prep\n",
    "\n",
    "    c1 <: w1\n",
    "''') \n",
    "\n",
    "qmeta.append({'results': prep_time_l_time,\n",
    "              'label':'prep_q[time]_L',\n",
    "              'phrase2_ref': 1,\n",
    "              'oslot_ends': (1, 6),\n",
    "              'semroles':{1:'orient',\n",
    "                          2:'time',\n",
    "                          3:'quantNP',\n",
    "                          5:'L',\n",
    "                          6:'reference'\n",
    "                          }\n",
    "              })\n",
    "\n",
    "    \n",
    "prep_l_time = A.search('''\n",
    "\n",
    "sentence\n",
    "    chunk label=prep\n",
    "    <: c1:chunk label=quant_NP|quant_NP_chain|quant\n",
    "\n",
    "    /without/\n",
    "    chunk\n",
    "        ..\n",
    "    /-/\n",
    "        word\n",
    "    w1:word lex=L language=Hebrew\n",
    "    <: word sem_set#prep\n",
    "\n",
    "    c1 <: w1\n",
    "''') \n",
    "\n",
    "\n",
    "qmeta.append({'results': prep_l_time,\n",
    "              'label':'prep_q[time]_L',\n",
    "              'phrase2_ref': 1,\n",
    "              'oslot_ends': (1, 5),\n",
    "              'semroles':{1:'orient',\n",
    "                          2:'quantNP',\n",
    "                          4:'L',\n",
    "                          5:'reference'\n",
    "                          }\n",
    "              })\n",
    "\n",
    "\n",
    "# This pattern is very long because \n",
    "# there are restrictions needed to ensure that\n",
    "# the quantified NP time phrase is truly\n",
    "# standing on its own without contributing\n",
    "# to a larger construction\n",
    "prep_qTime = A.search('''\n",
    "\n",
    "sentence\n",
    "    phrase2 function=Time\n",
    "        chunk label=prep\n",
    "        /without/\n",
    "        phrase2\n",
    "            chunk label=quant_NP|quant_NP_chain|quant\n",
    "            <: ..\n",
    "        /-/\n",
    "        /without/\n",
    "        phrase2\n",
    "            phrase_atom typ=PP\n",
    "            <: ..\n",
    "        /-/\n",
    "            =: word lex#>T\n",
    "        \n",
    "        <: chunk label=quant_NP|quant_NP_chain\n",
    "        /without/\n",
    "        chunk\n",
    "            ..\n",
    "        /-/\n",
    "        /without/\n",
    "        ..\n",
    "        <: word pdp=prep language=Hebrew\n",
    "        /-/\n",
    "        /without/\n",
    "        phrase2\n",
    "            ..\n",
    "            < word pdp=prep\n",
    "        /-/\n",
    "        /without/\n",
    "        sentence\n",
    "            ..\n",
    "            < phrase function=Time typ=PP\n",
    "        /-/\n",
    "\n",
    "''') \n",
    "token = 'prep_qNP'\n",
    "\n",
    "qmeta.append({'results': prep_qTime,\n",
    "              'label':'prep_qNP',\n",
    "              'phrase2_ref': 2,\n",
    "              'oslot_ends': (2, 4),\n",
    "              'semroles':{2:'orient',\n",
    "                          4:'quantNP',\n",
    "                          }\n",
    "              })    \n",
    "    \n",
    "# PUT NEW LOOP HERE!\n",
    "    \n",
    "these_phrases = set()\n",
    "\n",
    "for query in qmeta:\n",
    "    token2results[query['label']] = query['results']\n",
    "    \n",
    "    for res in query['results']:\n",
    "        count_quants[query['label']] += 1\n",
    "\n",
    "        # update phrase2 tracking\n",
    "        phrase2 = L.u(res[query['phrase2_ref']], 'phrase2')[0]\n",
    "        found_phrases.add(phrase2)\n",
    "        these_phrases.add(phrase2)\n",
    "        \n",
    "        # map to CX object\n",
    "        node += 1\n",
    "        nodeFeatures['otype'][node] = 'construction'\n",
    "        nodeFeatures['label'][node] = query['label']\n",
    "        start, end = query['oslot_ends']\n",
    "        edgeFeatures['oslot'][node] = flattenNodes(res[start:end+1])\n",
    "        for i, semrole in query['semroles'].items():\n",
    "            edgeFeatures['role'][res[i]] = {semrole:node}\n",
    "            \n",
    "print('\\n', len(these_phrases), 'phrases accounted for in these loops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1109 / 3376\t0.33\n"
     ]
    }
   ],
   "source": [
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remaining cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.83s 1005 results\n",
      "\n",
      "phrases added here:\t339\n",
      "phrases NOT added:\t49\n",
      "\n",
      "TOTAL progress\n",
      "1448 / 3376\t0.43\n"
     ]
    }
   ],
   "source": [
    "remaining2res = collections.defaultdict(list)\n",
    "\n",
    "quant_cx = A.search('''\n",
    "\n",
    "phrase2\n",
    "    phrase function=Time\n",
    "        <nhead- word pdp=subs\n",
    "        word ls=card language=Hebrew\n",
    " \n",
    "''')\n",
    "    \n",
    "these_phrases = set()\n",
    "unknown_phrases = set()\n",
    "    \n",
    "for result in quant_cx:\n",
    "    \n",
    "    if result[0] in found_phrases:\n",
    "        continue\n",
    "    \n",
    "    ph_token = tokenQuants(result[0])\n",
    "    \n",
    "    # case-by-case basis constructions handled here\n",
    "    # these are constructions where it is easier to \n",
    "    # take the subset of phrases  NOT yet accounted for\n",
    "    # since the other cases are by now filtered out\n",
    "    \n",
    "    # handle durative cases\n",
    "    if ph_token == 'מד׳׳':\n",
    "                \n",
    "        ph_token = 'ø_quantNP'\n",
    "        found_phrases.add(result[0])\n",
    "        these_phrases.add(result[0])\n",
    "        \n",
    "        node += 1\n",
    "        nodeFeatures['otype'][node] = 'construction'\n",
    "        nodeFeatures['label'][node] = ph_token\n",
    "        edgeFeatures['oslot'][node] = L.d(result[0], 'word')\n",
    "        edgeFeatures['role'][result[2]] = {'timenoun':node}\n",
    "    \n",
    "    else:\n",
    "        unknown_phrases.add(result[0])\n",
    "    \n",
    "    # all other cases just count them\n",
    "    count_quants[ph_token] += 1\n",
    "    remaining2res[ph_token].append(result)\n",
    "    \n",
    "print()\n",
    "print(f'phrases added here:\\t{len(these_phrases)}')\n",
    "print(f'phrases NOT added:\\t{len(unknown_phrases)}')\n",
    "\n",
    "print('\\nTOTAL progress')\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect What Is There"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_quants = pd.DataFrame(count_quants.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "showresult = 0\n",
    "showme = remaining2res['ב.מד׳׳']\n",
    "\n",
    "#A.show(showme, extraFeatures='st', condenseType='sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_quants.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ø_quantNP</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prep_q[time]_L</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prep_qNP</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>מד׳׳.מד׳׳</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ב.מ׳׳.בו</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ב.מ׳׳.בו.ו.ב.מ׳׳.בו</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>אחר.ה.מבול.מד׳׳</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>עד.ערב.מד׳׳</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ב.יום.מד׳׳</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>את.מ׳׳.ה.יום.ו.את.מ׳׳.ה.לילה</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>מ׳׳.ל.מד׳׳</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ב.מד׳׳</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>מ.יום.ל.יום.ו.מ.חדשׁ.ל.מד׳׳</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>מ׳׳</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>מ׳׳.ב.ה.שׁנה</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>מספר.ה.ימים.מד׳׳</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ל.ה.שׁבתות.ו.ל.ה.חדשׁים.ו.ל.ה.מועדות.מד׳׳.ב.ה....</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ל.ה.יום.מד׳׳</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>מ.קצה.מד׳׳</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ב.ה.שׁנה.ה.מ׳׳.ב.ירח.בול</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>אחרי.מות.יהואשׁ.בן.יהואחז.מלך.ישׂראל.מד׳׳</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>אחרי.זאת.מד׳׳</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ימים.רבים.מד׳׳</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ב.מד׳׳.בו.ב.ה.יום</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>אחרי.ה.מד׳׳</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ל.מד׳׳</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>אחרי.מות.יואשׁ.בן.יהואחז.מלך.ישׂראל.מד׳׳</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ל.ימים.עוד.מ׳׳</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>את.מד׳׳</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>יומם.ו.לילה.מד׳׳</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>אחרי.מות.מד׳׳.אהרן</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>מ.קץ.מד׳׳.ב.מעד.שׁנת.ה.שׁמטה</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ב.ימי.פלשׁתים.מד׳׳</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ה.יום.מד׳׳</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ה.מד׳׳</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ב.ימי.דוד.מד׳׳.שׁנה.אחרי.שׁנה</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ב.שׁנת.מ׳׳</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ב.מ׳׳.ב.ה.חדשׁ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ב.חדשׁ.כסלו.שׁנת.מ׳׳</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ב.חדשׁ.ניסן.שׁנת.מ׳׳.ל.ארתחשׁסתא.ה.מלך</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>בין.מד׳׳</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0    1\n",
       "0                                           ø_quantNP  339\n",
       "1                                      prep_q[time]_L  330\n",
       "2                                            prep_qNP   54\n",
       "3                                           מד׳׳.מד׳׳    8\n",
       "4                                            ב.מ׳׳.בו    8\n",
       "5                                 ב.מ׳׳.בו.ו.ב.מ׳׳.בו    8\n",
       "6                                     אחר.ה.מבול.מד׳׳    6\n",
       "7                                         עד.ערב.מד׳׳    6\n",
       "8                                          ב.יום.מד׳׳    4\n",
       "9                        את.מ׳׳.ה.יום.ו.את.מ׳׳.ה.לילה    4\n",
       "10                                         מ׳׳.ל.מד׳׳    4\n",
       "11                                             ב.מד׳׳    4\n",
       "12                        מ.יום.ל.יום.ו.מ.חדשׁ.ל.מד׳׳    4\n",
       "13                                                מ׳׳    4\n",
       "14                                       מ׳׳.ב.ה.שׁנה    3\n",
       "15                                   מספר.ה.ימים.מד׳׳    3\n",
       "16  ל.ה.שׁבתות.ו.ל.ה.חדשׁים.ו.ל.ה.מועדות.מד׳׳.ב.ה....    3\n",
       "17                                       ל.ה.יום.מד׳׳    2\n",
       "18                                         מ.קצה.מד׳׳    2\n",
       "19                           ב.ה.שׁנה.ה.מ׳׳.ב.ירח.בול    2\n",
       "20          אחרי.מות.יהואשׁ.בן.יהואחז.מלך.ישׂראל.מד׳׳    2\n",
       "21                                      אחרי.זאת.מד׳׳    2\n",
       "22                                     ימים.רבים.מד׳׳    2\n",
       "23                                  ב.מד׳׳.בו.ב.ה.יום    2\n",
       "24                                        אחרי.ה.מד׳׳    2\n",
       "25                                             ל.מד׳׳    2\n",
       "26           אחרי.מות.יואשׁ.בן.יהואחז.מלך.ישׂראל.מד׳׳    2\n",
       "27                                     ל.ימים.עוד.מ׳׳    1\n",
       "28                                            את.מד׳׳    1\n",
       "29                                   יומם.ו.לילה.מד׳׳    1\n",
       "30                                 אחרי.מות.מד׳׳.אהרן    1\n",
       "31                       מ.קץ.מד׳׳.ב.מעד.שׁנת.ה.שׁמטה    1\n",
       "32                                 ב.ימי.פלשׁתים.מד׳׳    1\n",
       "33                                         ה.יום.מד׳׳    1\n",
       "34                                             ה.מד׳׳    1\n",
       "35                      ב.ימי.דוד.מד׳׳.שׁנה.אחרי.שׁנה    1\n",
       "36                                         ב.שׁנת.מ׳׳    1\n",
       "37                                     ב.מ׳׳.ב.ה.חדשׁ    1\n",
       "38                               ב.חדשׁ.כסלו.שׁנת.מ׳׳    1\n",
       "39             ב.חדשׁ.ניסן.שׁנת.מ׳׳.ל.ארתחשׁסתא.ה.מלך    1\n",
       "40                                           בין.מד׳׳    1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_quants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Qualitative Quantifiers (ø)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.62s 191 results\n",
      "\n",
      "1625 / 3376\t0.48\n"
     ]
    }
   ],
   "source": [
    "null_qq = A.search('''\n",
    "\n",
    "phrase2 function=Time\n",
    "/without/\n",
    "    chunk label=prep\n",
    "/-/\n",
    "    word sem_set=quant ls#card language=Hebrew\n",
    "    <1: word pdp=subs ls#card\n",
    "    /with/\n",
    "    :> word pdp=art\n",
    "    /or/\n",
    "    :> word sem_set=quant ls#card\n",
    "    /-/\n",
    "''')\n",
    "\n",
    "\n",
    "null_qq_name = 'ø_qualityQuant_NP'\n",
    "token2results[null_qq_name] = null_qq\n",
    "\n",
    "for result in null_qq:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    nodeFeatures['label'][node] = null_qq_name\n",
    "    edgeFeatures['oslot'][node] = result\n",
    "    edgeFeatures['role'][result[2]] = {'timenoun':node}\n",
    "    edgeFeatures['role'][result[1]] = {'qualQuant':node}\n",
    "\n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(null_qq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Dual-Endings\n",
    "\n",
    "Nouns that are otherwise unmarked for number can be marked with a dual ending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.95s 25 results\n",
      "\n",
      "1650 / 3376\t0.49\n"
     ]
    }
   ],
   "source": [
    "timeDual = A.search('''\n",
    "\n",
    "phrase2 function=Time\n",
    "    =: chunk label=prep\n",
    "    <1: word nu=du ls#card\n",
    "    /with/\n",
    "    :> word pdp=art\n",
    "    /or/\n",
    "    :> chunk label=prep\n",
    "    /-/\n",
    "    \n",
    "''')\n",
    "\n",
    "tDual_name = 'prep_timeDual'\n",
    "token2results[tDual_name] = timeDual\n",
    "\n",
    "for result in timeDual:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    nodeFeatures['label'][node] = tDual_name\n",
    "    edgeFeatures['oslot'][node] = flattenNodes(result[1:])\n",
    "    edgeFeatures['role'][result[2]] = {'timenoun':node}\n",
    "    edgeFeatures['role'][result[1]] = {'orient':node}\n",
    "    \n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. PP + NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.79s 665 results\n",
      "  2.88s 460 results\n",
      "\n",
      "2628 / 3376\t0.78\n"
     ]
    }
   ],
   "source": [
    "pp_np = []\n",
    "\n",
    "pp_np_query = '''\n",
    "\n",
    "p:phrase2 function=Time\n",
    "/without/\n",
    "    word\n",
    "    /with/\n",
    "    <mother- clause\n",
    "    /or/\n",
    "    sem_set=quant\n",
    "    /or/\n",
    "    nu=du\n",
    "    /or/\n",
    "    pdp=prde|conj\n",
    "    /-/\n",
    "/-/\n",
    "    =: chunk label=prep\n",
    "    /without/\n",
    "    phrase2\n",
    "        ..\n",
    "        << word pdp=prep\n",
    "    /-/\n",
    "    \n",
    "    {option}\n",
    "    \n",
    "    <: n:word pdp=subs ls#card sem_set#prep language=Hebrew\n",
    "'''\n",
    "\n",
    "for option in {'', '<: word pdp=art'}:\n",
    "    pp_np.extend(A.search(pp_np_query.format(option=option)))\n",
    "\n",
    "ppnp_name = 'prep_time'\n",
    "token2results[ppnp_name] = pp_np\n",
    "\n",
    "for result in pp_np:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    nodeFeatures['label'][node] = ppnp_name\n",
    "    edgeFeatures['oslot'][node] = L.d(result[0], 'word')\n",
    "    edgeFeatures['role'][result[-1]] = {'timenoun':node}\n",
    "    edgeFeatures['role'][result[1]] = {'orient':node}\n",
    "    \n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.shuffle(pp_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(pp_np, extraFeatures='st', condensed=False, condenseType='clause')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. prep + noun + inf_verb_clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.73s 114 results\n",
      "\n",
      "2736 / 3376\t0.81\n"
     ]
    }
   ],
   "source": [
    "pp_np_cl = A.search('''\n",
    "\n",
    "phrase2 function=Time\n",
    "    =: chunk label=prep\n",
    "    w1:word pdp=subs language=Hebrew\n",
    "    \n",
    "w1 \n",
    "<mother- clause\n",
    "    \n",
    "''')\n",
    "\n",
    "\n",
    "pptc_name = 'prep_time_clause'\n",
    "token2results[pptc_name] = pp_np_cl\n",
    "\n",
    "for result in pp_np_cl:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    nodeFeatures['label'][node] = pptc_name\n",
    "    edgeFeatures['oslot'][node] = flattenNodes(result)\n",
    "    edgeFeatures['role'][result[2]] = {'timenoun':node}\n",
    "    edgeFeatures['role'][result[1]] = {'orient':node}\n",
    "    edgeFeatures['role'][result[-1]] = {'event':node}\n",
    "\n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 prep + inrg\n",
    "\n",
    "The preposition + interrogative construction is related to the prep+NP construction. The interrogative particle is extended into the position of a noun. In many cases, these nouns are habitually associated with temporal question phrases, e.g. מתי"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.19s 39 results\n",
      "\n",
      "2775 / 3376\t0.82\n"
     ]
    }
   ],
   "source": [
    "prep_inrg = A.search('''\n",
    "\n",
    "p:phrase2 function=Time\n",
    "    =: chunk label=prep\n",
    "    <: w1:word pdp=inrg language=Hebrew\n",
    "\n",
    "''')\n",
    "\n",
    "pp_inrg_name = 'prep_timeQuestion'\n",
    "token2results[pp_inrg_name] = prep_inrg\n",
    "\n",
    "for result in prep_inrg:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    nodeFeatures['label'][node] = pp_inrg_name\n",
    "    edgeFeatures['oslot'][node] = L.d(result[0], 'word')\n",
    "    edgeFeatures['role'][result[2]] = {'timeQuestion':node}\n",
    "    edgeFeatures['role'][result[1]] = {'orient':node}\n",
    "\n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.shuffle(prep_inrg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(prep_inrg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 prep + pronominal suffix\n",
    "\n",
    "This construction is also related to the prep+NP, especially in the sense the the NP often takes a suffix when refering to event-type nouns. The cases below consist of time constructions where a preposition is the only item, and a pronominal suffix is attached to it. These cases seem to involve some existential sense related to a person: \"after me\", \"after them\" i.e. \"after [I exist]\". In fact, the preposition seems to play a kind of double duty in theses cases: both as a sort of noun and as a preposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.77s 34 results\n",
      "\n",
      "2809 / 3376\t0.83\n"
     ]
    }
   ],
   "source": [
    "prep_sffx = A.search('''\n",
    "\n",
    "p:phrase2 function=Time\n",
    "    w1:word pdp=prep prs#absent\n",
    "\n",
    "p =: w1\n",
    "p := w1\n",
    "''')\n",
    "\n",
    "prep_sffx_name = 'prep_suffix'\n",
    "token2results[prep_sffx_name] = prep_sffx\n",
    "\n",
    "for result in prep_sffx:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    nodeFeatures['label'][node] = prep_sffx_name\n",
    "    edgeFeatures['oslot'][node] = L.d(result[0], 'word')\n",
    "    edgeFeatures['role'][result[1]] = {'orientExist':node}\n",
    "\n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.shuffle(prep_sffx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(prep_sffx, condensed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. \"Adverb\" Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.41s 179 results\n",
      "\n",
      "2988 / 3376\t0.89\n"
     ]
    }
   ],
   "source": [
    "advb = A.search('''\n",
    "\n",
    "p:phrase2 function=Time\n",
    "    w1:word pdp=advb lex#>K|>Z|<TH|KN language=Hebrew\n",
    "\n",
    "w1 =: p\n",
    "w1 := p\n",
    "''')\n",
    "\n",
    "\n",
    "advb_name = 'timeAdvb'\n",
    "token2results[advb_name] = advb\n",
    "\n",
    "for result in advb:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    nodeFeatures['label'][node] = advb_name\n",
    "    edgeFeatures['oslot'][node] = result\n",
    "    edgeFeatures['role'][result[0]] = {'timenoun':node}\n",
    "\n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(advb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show([res for res in advb if F.lex.v(res[1]) == '>XR/'], condensed=False, condenseType='sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. timeNoun Only\n",
    "\n",
    "If a timenoun solely occupies the time construction it is nearly always morphologically marked in some way. Two cases are seen: time nouns with dual endings (indicating a specified segment of time), and time nouns with plural endings (indicating an unmarked duration). While different in function, these time nouns are similar in form, and they especially resemble the adverbials recognized above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. PP/NP Repetition\n",
    "\n",
    "The repetition of the same phrase/noun twice is used to indicate repetitive, cyclic time. This takes advantage of the repeating noun construction used to represent plurality, but the function is extended in the time function. This highlights how plurality can be an indicator of time duration.\n",
    "\n",
    "This analysis requires some hand-coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 pp results...\n",
      "9 nn results...\n"
     ]
    }
   ],
   "source": [
    "repeats = []\n",
    "\n",
    "pp_pp = '''\n",
    "\n",
    "phrase2 function=Time\n",
    "    chunk label=prep\n",
    "    {option}\n",
    "    <: word pdp=subs\n",
    "    <: chunk label=prep\n",
    "    {option}\n",
    "    <: word pdp=subs\n",
    "'''\n",
    "\n",
    "pp_pp = [res for opt in ('', '<: word pdp=art')\n",
    "            for res in A.search(pp_pp.format(option=opt), silent=True)]\n",
    "\n",
    "for res in pp_pp:\n",
    "    prep1, prep2 = (c for c in res if F.otype.v(c) == 'chunk')\n",
    "    word1, word2 = (w for w in res if F.pdp.v(w) != 'art' and w not in {prep1, prep2, res[0]})\n",
    "    prepT1, prepT2 = [T.text(prep, fmt='text-orig-plain', descend=True) for prep in (prep1, prep2)]\n",
    "    wordT1, wordT2 = [F.g_cons_utf8.v(w) for w in (word1, word2)]\n",
    "    \n",
    "    if all([prepT1 == prepT2,\n",
    "            wordT1 == wordT2]):\n",
    "        repeats.append(res)\n",
    "        \n",
    "print(f'{len(res)} pp results...')\n",
    "\n",
    "\n",
    "np_np = A.search(f'''\n",
    "\n",
    "phrase2 function=Time\n",
    "/without/\n",
    "    chunk label=prep\n",
    "/-/\n",
    "    word\n",
    "    <: word    \n",
    "    \n",
    "''', silent=True)\n",
    "\n",
    "npnpct = 0\n",
    "for res in np_np:\n",
    "    \n",
    "    word1, word2 = F.g_cons_utf8.v(res[1]), F.g_cons_utf8.v(res[2])\n",
    "    \n",
    "    if word1 == word2:\n",
    "        repeats.append(res)\n",
    "        npnpct += 1\n",
    "        \n",
    "print(f'{npnpct} nn results...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3012 / 3376\t0.89\n"
     ]
    }
   ],
   "source": [
    "trepeat = 'timeRepeat'\n",
    "token2results[trepeat] = repeats\n",
    "\n",
    "for result in repeats:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    nodeFeatures['label'][node] = trepeat\n",
    "    edgeFeatures['oslot'][node] = result\n",
    "#     edgeFeatures['semrole'][result[0]] = {'timenoun':node}\n",
    "\n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.shuffle(repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(repeats, condensed=False, condenseType='phrase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STATUS CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prep_time</th>\n",
       "      <td>1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep_H_time_H_{}</th>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_time</th>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ø_qualityQuant_NP</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timeAdvb</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep_q[time]_L</th>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep_time_clause</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep_qNP</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep_timeQuestion</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_time_H_{}</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep_suffix</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep_timeDual</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timeRepeat</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count\n",
       "prep_time           1125\n",
       "prep_H_time_H_{}     715\n",
       "H_time               216\n",
       "ø_qualityQuant_NP    191\n",
       "timeAdvb             179\n",
       "prep_q[time]_L       165\n",
       "prep_time_clause     114\n",
       "prep_qNP              54\n",
       "prep_timeQuestion     39\n",
       "H_time_H_{}           35\n",
       "prep_suffix           34\n",
       "prep_timeDual         25\n",
       "timeRepeat            25"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = dict((token, len(res)) for token, res in token2results.items())\n",
    "stats = pd.DataFrame.from_dict(stats, orient='index', columns=['count'])\n",
    "stats.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2917"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_tp = time_phrases-found_phrases\n",
    "remaining_patterns = collections.Counter()\n",
    "remain2result = collections.defaultdict(list)\n",
    "\n",
    "for tp in remaining_tp:\n",
    "    token = tokenPhrase(tp, tokener=tokenWord)\n",
    "    remaining_patterns[token] += 1\n",
    "    remain2result[token].append(L.d(tp, 'word'))\n",
    "    \n",
    "remaining_patterns = pd.DataFrame.from_dict(dict(remaining_patterns.most_common()), orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>subs</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.subs.subs</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.subs.conj.subs</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subs.adjv</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.subs.ha.subs.ha.prde</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advb.conj.advb</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.subs.prep.subs</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subs.subs</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.ha.subs.conj.prep.ha.subs</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.advb</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0\n",
       "subs                            31\n",
       "prep.subs.subs                  24\n",
       "prep.subs.conj.subs             20\n",
       "subs.adjv                       19\n",
       "prep.subs.ha.subs.ha.prde       19\n",
       "advb.conj.advb                  19\n",
       "prep.subs.prep.subs             15\n",
       "subs.subs                       14\n",
       "prep.ha.subs.conj.prep.ha.subs  10\n",
       "prep.advb                        8"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conj_tags = [t for t in remaining_patterns.index if 'conj' in t]\n",
    "\n",
    "remaining_patterns.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(remain2result['subs'], condenseType='sentence', extraFeatures='sem_set ls nu st')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(res for res in )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chained PP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.60s 178 results\n"
     ]
    }
   ],
   "source": [
    "missingp2 = set(ph for ph in F.otype.s('phrase2') if ph not in found_phrases)\n",
    "\n",
    "t = A.search('''\n",
    "\n",
    "missingphrase2 function=Time\n",
    "    construction label=prep\n",
    "    << construction label=prep\n",
    "\n",
    "''', sets={'missingphrase2':missingp2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show([L.d(ph[0], 'word') for ph in t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "primitives\n",
    "\n",
    "* NP chunks — chunk from head to head **[head mod mod mod CONJ head mod]**, split on conj (conjunction) or **[head mod mod head mod]** split on head.\n",
    "    * have to account for \"prefixed\" entities: namely definite article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other cases of H+noun+H+modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.show(A.search('''\n",
    "\n",
    "# phrase2 function=Time\n",
    "#     word lex=H\n",
    "#     <: word pdp=subs\n",
    "#     <: word lex=H\n",
    "#     <: word ls#ordn pdp#prde\n",
    "\n",
    "# '''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Degree of Dispersion *DP*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # count all phrase tokens in all books\n",
    "# phrase_tokens = collections.defaultdict(lambda:collections.Counter())\n",
    "\n",
    "# for phrase in F.otype.s('phrase'):\n",
    "#     book, chapter, verse = T.sectionFromNode(phrase)\n",
    "#     phrase_tokens[book][tokenPhrase(phrase)] += 1\n",
    "    \n",
    "# phrase_tokens = pd.DataFrame(phrase_tokens).fillna(0)\n",
    "\n",
    "# phrase_tokens.shape\n",
    "\n",
    "# expected_prop = phrase_tokens.sum() / phrase_tokens.sum().sum()\n",
    "# observed_prop = time_tokens.div(time_tokens.sum(1), axis=0)\n",
    "# prop_diffs = abs(expected_prop-observed_prop)\n",
    "# dp = 1-pd.DataFrame(prop_diffs.sum(1) / 2, columns=['DP'])\n",
    "\n",
    "# time_dp_total = pd.concat((dp, time_tokens.sum(1)), axis=1)\n",
    "# time_dp_total.columns = ('DP', 'Total')\n",
    "# time_dp_total = time_dp_total[['Total', 'DP']]\n",
    "\n",
    "# time_dp_total.sort_values(by='Total', ascending=False).head(20)\n",
    "\n",
    "# dp.sort_values(ascending=False, by='DP').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8,6))\n",
    "# plt.plot(sorted(dp.values, reverse=True), color='darkblue')\n",
    "# plt.xlabel('Rank', size=18)\n",
    "# plt.ylabel('DP', size=18)\n",
    "# plt.title('DP Score by Token Rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8,6))\n",
    "# plt.plot(sorted(time_tokens.sum(1).values, reverse=True), color='darkblue')\n",
    "# plt.xlabel('Rank', size=18)\n",
    "# plt.ylabel('Frequency', size=18)\n",
    "# plt.title('Token Frequency by Rank')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

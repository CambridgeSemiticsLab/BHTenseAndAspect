{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Constructions, Part 2\n",
    "\n",
    "In part 1 of time construction analysis, I used exploratory analysis to find the top major forms amongst time constructions in Biblical Hebrew. That analysis culminated in a tokenization strategy which labeled like-elements within time constructions to obtain raw groups. Those groups were counted, and it was found that out of 312 raw different surface forms, the top 11 attested for 75% of individual instances. These few forms thus encapsulate a majority of the data.\n",
    "\n",
    "In this notebook, I want to break down the major subcategories of the top surface forms. For instance, the most common token is `prep.time`, i.e. a preposition + a time word. But there are major differences amongst this group. Specifically, the time noun is often specified by a further element. In some cases this further element consists of an infinitival clause that modifies the time noun. Some time nouns are statistically associated with the time function, such as יום, שׁנה etc. But some are not, such as nouns which describe events. These are of a different semantic type.\n",
    "\n",
    "This analysis will follow a similar strategy as part 1, using a process of elimination to narrow down the primary groups amongst the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections, csv, random, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5, style='whitegrid')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from skfuzzy.cluster import cmeans\n",
    "from tf.fabric import Fabric\n",
    "from tf.app import use\n",
    "\n",
    "# import custom tools\n",
    "os.sys.path.append('../')\n",
    "from tools.locations import data_locations \n",
    "from tools.significance import contingency_table, apply_fishers\n",
    "from tools.pca import plot_PCA\n",
    "from tools.helpers import convert2pandas\n",
    "from tools.visualize import reverse_hb\n",
    "from tools.tokenize import tokenize_surface\n",
    "from tools.time import Time\n",
    "\n",
    "TF = Fabric(locations=data_locations.values())\n",
    "api = TF.load('''\n",
    "\n",
    "vs vt pdp gloss lex language ps gn\n",
    "rela typ number function prs\n",
    "g_cons_utf8 lex_utf8 nu mother st uvf\n",
    "g_word_utf8 trailer_utf8 voc_lex_utf8\n",
    "head nhead obj_prep sem_set\n",
    "ls top_assoc funct_assoc kind txt\n",
    "label role\n",
    "''')\n",
    "\n",
    "A = use('bhsa', api=api, hoist=globals(), silent=True)\n",
    "\n",
    "A.displaySetup(condenseType='clause', condensed=True, withNodes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstyear = '../../data/paper_data/firstyear2' # directory for first year review paper saves\n",
    "\n",
    "def countBarplot(count_df, \n",
    "                 title='', \n",
    "                 column='Total', \n",
    "                 reverse_labels=False, \n",
    "                 size=(8, 6),\n",
    "                 xlab_rotation=None,\n",
    "                 ylim=None,\n",
    "                 save=None,\n",
    "                 xlabel=None,\n",
    "                ):\n",
    "    '''\n",
    "    Makes simple barplot from collections.Counter type objects.\n",
    "    '''\n",
    "    n_bars = list(range(0, count_df.shape[0]))\n",
    "    x_labels = [''.join(reversed(prep)) for prep in count_df.index] if reverse_labels else count_df.index\n",
    "    plt.figure(figsize=size)\n",
    "    sns.barplot(n_bars, count_df[column], color='darkblue')\n",
    "    plt.xticks(n_bars, x_labels, size=18, rotation=xlab_rotation)\n",
    "    plt.yticks(size=18)\n",
    "    if ylim:\n",
    "        plt.ylim(top=ylim[0], bottom=ylim[1])\n",
    "    if xlabel:\n",
    "        plt.xlabel(xlabel,size=18)\n",
    "    plt.ylabel(column, size=18)    \n",
    "    if save:\n",
    "        plt.savefig(save, dpi=300, bbox_inches='tight')\n",
    "    plt.title(title, size=18,  y=1.05)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label2result = collections.defaultdict(list)\n",
    "# for cx in F.otype.s('chunk'):\n",
    "#     label2result[F.label.v(cx)].append(L.d(cx, 'phrase'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Constructions: Their Distribution and Make-Up\n",
    "\n",
    "This analysis repeats some parts of previous studies, [SBH_time_expressions](https://nbviewer.jupyter.org/github/CambridgeSemiticsLab/BH_time_collocations/blob/master/analysis/SBH_time_expressions.ipynb) and [duratives](https://nbviewer.jupyter.org/github/CambridgeSemiticsLab/BH_time_collocations/blob/master/analysis/duratives.ipynb), but now with the new time construction data and for all known time constructions in the Hebrew Bible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic BSHA Stats\n",
    "\n",
    "#### number of phrases in BHSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = A.search('''\n",
    "\n",
    "phrase\n",
    "/with/\n",
    "    word language=Hebrew\n",
    "/-/\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### number of functions in BHSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(F.function.freqList())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.function.freqList()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hebrew time phrases (not processed and raw)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = A.search('''\n",
    "\n",
    "phrase function=Time\n",
    "/with/\n",
    "    word language=Hebrew\n",
    "/-/\n",
    "    \n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the post-processing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cx = A.search('''\n",
    "\n",
    "construction\n",
    "    \n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Construction Distribution and Selectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Time Constructions Across Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_data = []\n",
    "covered_chapters = set()\n",
    "bookboundaries = {}\n",
    "\n",
    "twelve = ('Hosea', 'Joel', 'Amos', 'Obadiah',\n",
    "          'Jonah', 'Micah', 'Nahum', 'Habakkuk',\n",
    "          'Zephaniah', 'Haggai', 'Zechariah',\n",
    "          'Malachi')\n",
    "\n",
    "# map grouped book names\n",
    "megilloth = ('Ruth', 'Lamentations', 'Ecclesiastes', 'Esther', 'Song_of_songs')\n",
    "book_map = {'1_Kings': 'Kings', '2_Kings':'Kings', '1_Samuel':'Samuel',\n",
    "            '2_Samuel':'Samuel', '1_Chronicles':'Chronicles', '2_Chronicles':'Chronicles',}\n",
    "for book in twelve: book_map[book] = 'Twelve'\n",
    "for book in megilloth: book_map[book] = 'Megilloth'\n",
    "for book in ('Ezra', 'Nehemiah', 'Daniel'): book_map[book] = 'Daniel-Neh'\n",
    "\n",
    "    \n",
    "# iterate through constructions and gather book data\n",
    "this_book = None\n",
    "\n",
    "for cx in F.otype.s('construction'):\n",
    "    chapter_node = L.u(cx, 'chapter')[0]\n",
    "    book, chapter, verse = T.sectionFromNode(cx)\n",
    "    this_book = book_map.get(book, book)\n",
    "    covered_chapters.add(chapter_node)\n",
    "    chapter_label = len(covered_chapters)\n",
    "    \n",
    "    if this_book not in bookboundaries: # add first chapter to boundaries for plotting\n",
    "        bookboundaries[this_book] = chapter_label\n",
    "    \n",
    "    strip_data.append(chapter_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_title = 'Distribution of Time Function Constructions by Chapter (smaller books are grouped together)'\n",
    "plt.figure(figsize=(20, 6))\n",
    "sns.stripplot(x=strip_data, jitter=0.3, color='darkblue')\n",
    "plt.xticks(ticks=list(bookboundaries.values()), labels=list(bookboundaries.keys()), rotation='vertical', size=20)\n",
    "plt.savefig('paper_data/firstyear/chapter_distribution.png', dpi=300, bbox_inches='tight')\n",
    "print(strip_title) # keep title out of savefig\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree of Dispersion Compared to Other Functions\n",
    "\n",
    "The strip chart gives a good sense of how spread out time constructions are in the Hebrew Bible. We can also see that the distribution is sparser throughout the poetics books, from Isaiah until the beginning of Daniel-Nehemiah. This variation in density can be quantified using a statistical measure known as **degree of dispersion** (Gries, S. 2008. \"Dispersions and Adjusted Frequencies in Corpora\"). We can use this measure to compare the time construction against other functions in corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count all phrase tokens per book\n",
    "phrase_functions = collections.defaultdict(lambda:collections.Counter())\n",
    "\n",
    "functionmap = {'PreO': 'Pred', 'PreS': 'Pred', 'PtcO': 'Pred', # collect some of the idiosyncratic BHSA functions\n",
    "              'IntS': 'Intj', 'NCoS': 'NCop','ModS': 'Modi',\n",
    "              'ExsS': 'Exst'}\n",
    "\n",
    "for phrase in F.otype.s('phrase'):\n",
    "    book, chapter, verse = T.sectionFromNode(phrase)\n",
    "    book = book_map.get(book, book)\n",
    "    # use constructional phrases only for Time function phrases\n",
    "    # some time phrases are excluded, others follow a primary time phrase\n",
    "    # ignore excluded TPs and secondary TPs\n",
    "    if F.function.v(phrase) == 'Time':\n",
    "        time_cx = L.u(phrase, 'construction')[0] if L.u(phrase, 'construction') else tuple()\n",
    "        if not time_cx: # excluded TP\n",
    "            continue\n",
    "        elif list(L.d(time_cx, 'phrase')).index(phrase) == 0:\n",
    "            phrase_functions[book]['Time'] += 1\n",
    "\n",
    "    # count all other function types\n",
    "    else:\n",
    "        funct = functionmap.get(F.function.v(phrase), F.function.v(phrase))\n",
    "        function = funct2function[funct].title()\n",
    "        phrase_functions[book][function] += 1\n",
    "    \n",
    "    \n",
    "phrase_functions = pd.DataFrame(phrase_functions).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BHSA has some idiosyncatic functions that only occur a handfull of times relative to the whole corpus. See especially those below that fall below a frequency of 300:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_functions.sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've decided to remove these marginal forms from the analysis by selecting only those that occur total > 300 times. The new functions are seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_functions = phrase_functions[phrase_functions.sum(1) > 200]\n",
    "\n",
    "phrase_functions.sum(1).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_prop = phrase_functions.sum() / phrase_functions.sum().sum()\n",
    "observed_prop = phrase_functions.div(phrase_functions.sum(1), axis=0)\n",
    "prop_diffs = abs(expected_prop-observed_prop)\n",
    "dp = prop_diffs.sum(1) / 2\n",
    "dp = 1-pd.DataFrame(dp, columns=['Degree of Dispersion']).sort_values(by='Degree of Dispersion') # DP score finalized here, NB 1- to make it more intuitive (Bigger==more distributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_prop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.loc['Time'] - dp.loc['Adjunct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Degree of Dispersion by Phrase Function per Book in Hebrew Bible (higher is more evenly distributed)'\n",
    "save = 'paper_data/firstyear/phrase_DP.png'\n",
    "countBarplot(dp, title=title, column='Degree of Dispersion', size=(15, 6), xlab_rotation='vertical', ylim=(1, 0.60), save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is significant here that the time construction is more consistently spread than the regular Adjunct function. Its spread relative to Location is harder to evaluate due to the presence of some Location functioning phrases residing in the Complement function. The BHSA labels many locative phrases as simple complements to movement verbs without providing a further distinction that they are likewise locative in nature. That is a shortcoming to the data. This data does tell us, however, that the Time function is more evenly spread than the generic adjunct function, and certainly it is more evenly distributed than Vocative or Question phrases.\n",
    "\n",
    "We observed in the stripplot that the Time function appeared to be less attested in the books ranging from Isaiah through the end of the Megilloth. \n",
    "\n",
    "**Presented below is the difference in proportion, per book, between the expected proportion and the actual observed proportion of Time phrases**. They are sorted from greatest to least, with a higher value indicating that the Time function is under-represented in relation to the size of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_diffs_book = pd.DataFrame((observed_prop-expected_prop).loc['Time'].sort_values(ascending=False))\n",
    "prop_diffs_book.columns = ['difference']\n",
    "\n",
    "prop_diffs_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Difference in Expected / Observed Proportions Per Book for Time, a lower value means less were observed than expected'\n",
    "countBarplot(prop_diffs_book, column='difference', title=title, size=(15, 6), xlab_rotation='vertical', save='paper_data/firstyear/dp_book_diff.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected from observing the strippchart, poetic books like Ezekiel, Job, Jeremiah, Proverbs, and Isaiah contain less than expected frequencies of Time function. The inclusion of Genesis in this group is surprising, although the barplot helps to see that the difference from Isaiah to Ezekiel is proportionately large. Likewise surprising is the difference in spread between Kings and Chronicles.\n",
    "\n",
    "I am a bit curious how these differences compare with other kinds of functions. Let's look at the `Pred` function, the function that is said to be the most distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_diffs_book_PRED = pd.DataFrame((observed_prop-expected_prop).loc['Predicate'].sort_values(ascending=False))\n",
    "prop_diffs_book_PRED.columns = ['difference']\n",
    "title = 'Difference in Expected / Observed Proportions Per Book for Pred, a lower value means less were observed than expected'\n",
    "countBarplot(prop_diffs_book_PRED, column='difference', title=title, size=(15, 6), xlab_rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very interesting that Chronicles and Daniel-Nehemiah are less verbal than expected, while Psalms is more so! To put it another way, relative to all other books in the corpus, Chronicles and Daniel-Nehemiah have a lower distribution of predicate phrases relative to the total number of phrases they contain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excursus: Why is Pred so underpresented in Chronicles?\n",
    "\n",
    "To answer this question, let's find the function which is most OVER-represented in the book..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Difference in Expected / Observed Function Proportions in Chronicles, a lower value means less were observed than expected'\n",
    "diff_all = observed_prop - expected_prop\n",
    "chronicles_diffs = pd.DataFrame(diff_all['Chronicles'].sort_values(ascending=False))\n",
    "chronicles_diffs.columns = ['difference']\n",
    "countBarplot(chronicles_diffs, title=title, column='difference', size=(15, 6), xlab_rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PreC seems like a possible candidate explanation...To find out for sure we could do a count of nominal clauses between all books, and see if Chronicles has a higher than expected proportion. But for now we will be satisfied with this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Variety within the Head Lexemes of Phrases with Various Functions\n",
    "\n",
    "I want to know how the Time phrase compares with other phrase functions in terms of the diversity of its head lexemes. In other words, does the Time function have a wide variety of terms that it regularly uses, or is it more highly selective of key terms? If the latter is true, it could show that time nouns are specialized in their use. Note that for this test, I do not look at lexical heads, but semantic heads. So, for instance, for a prepositional phrase I do not take the preposition but rather the object of the preposition. \n",
    "\n",
    "After making a count of all head lexeme/function co-ocurrences, I will normalize the number of lexemes per 100 uses of each function. The normalization is adapted from the helpful explanation of the [grammar lab](http://www.thegrammarlab.com/?p=160). I've adapted it by replacing \"word counts\" with \"lexeme counts\" and \"corpus size\" with \"frequency of function.\" The frequency of all functions is calculated by simply taking the sum of the co-occurrence function counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a co-occurrence matrix of function columns and co-occurring head lexeme rows\n",
    "\n",
    "function_heads = collections.defaultdict(lambda: collections.Counter())\n",
    "\n",
    "for ph in F.otype.s('phrase'):\n",
    "    \n",
    "    if not E.head.t(ph): # it should have a head\n",
    "        continue\n",
    "    \n",
    "    funct = functionmap.get(F.function.v(ph), F.function.v(ph))\n",
    "    function = funct2function[funct].title()\n",
    "    \n",
    "    if function in {'Exst', 'EPPr'}:\n",
    "        continue\n",
    "    \n",
    "    for head in E.nhead.t(ph):\n",
    "        function_heads[function][F.lex.v(head)] += 1\n",
    "        \n",
    "function_heads = pd.DataFrame(function_heads).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the normalizations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_to_lexs = dict((funct, (function_heads[function_heads[funct] > 0]).shape[0]) for funct in function_heads)\n",
    "function_to_lexs = pd.DataFrame.from_dict(function_to_lexs, orient='index')\n",
    "function_to_lexs = function_to_lexs[(function_to_lexs > 4).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_fs_lex = function_to_lexs*100\n",
    "norm_fs_lex = norm_fs_lex.div(function_heads.sum(), axis='rows')\n",
    "norm_fs_lex = norm_fs_lex.sort_values(by=0).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 7))\n",
    "sns.barplot(data=norm_fs_lex.transpose(), color='darkblue')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylabel('Unique Head Lexemes')\n",
    "#plt.xlabel('Phrase Functions')\n",
    "plt.savefig('paper_data/firstyear/unique_heads.png', dpi=300, bbox_inches='tight')\n",
    "#plt.annotate('Time is very selective', xy=(10, 3), xytext=(10, 10), arrowprops=dict(facecolor='red', shrink=0.05), size=18)\n",
    "plt.title('Number of Unique Head Lexemes per Function per 100 Uses')\n",
    "plt.show()\n",
    "display(norm_fs_lex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Make-Up of Time Constructions\n",
    "\n",
    "Beginning with their phrase types, I will analyze the kind of time constructions found in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrase Types Reflected in Constructions\n",
    "\n",
    "`PP` is prepotional phrase, `NP` is noun phrase, `AdvP` is adverb phrase, as might be expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx_types = collections.Counter()\n",
    "\n",
    "for cx in F.otype.s('construction'):\n",
    "    firstphrase = L.d(cx, 'phrase')[0]\n",
    "    cx_types[F.typ.v(firstphrase)] += 1\n",
    "    \n",
    "cx_types = convert2pandas(cx_types)\n",
    "\n",
    "cx_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx_types.to_excel(firstyear+'phrase_types.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countBarplot(cx_types, title='Phrase Types in Time Construction Set', xlabel='Phrase Types', save='paper_data/firstyear/phrase_types.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion of prepositional phrases..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx_types.loc['PP']['Total'] / cx_types.sum()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, 67%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a difference of 156% between the counts of NP and those of PP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cx_types.loc['PP']['Total'] - cx_types.loc['NP']['Total']) / cx_types.loc['NP']['Total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preposition is the most influential form within time constructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with unprocessed Time Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_types = collections.Counter()\n",
    "\n",
    "for ph in tp:\n",
    "    tp_types[F.typ.v(ph[0])] += 1\n",
    "    \n",
    "tp_types = convert2pandas(tp_types)\n",
    "\n",
    "display(tp_types)\n",
    "\n",
    "countBarplot(tp_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_types.loc['AdvP'] - cx_types.loc['AdvP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with Location\n",
    "\n",
    "This includes `Loca` phrases as well as complement phrases with a semantic head that has high association with location phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = A.search('''\n",
    "\n",
    "phrase function=Cmpl\n",
    "/with/\n",
    "    <nhead- word LocaAssoc>2\n",
    "/-/\n",
    "\n",
    "''', shallow=True) | A.search('''\n",
    "\n",
    "phrase function=Loca\n",
    "\n",
    "\n",
    "''', shallow=True)\n",
    "\n",
    "print(len(locations), 'total locations found...')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loca_types = collections.Counter()\n",
    "\n",
    "for ph in locations:\n",
    "    loca_types[F.typ.v(ph)] += 1\n",
    "    \n",
    "loca_types = convert2pandas(loca_types)\n",
    "\n",
    "loca_types.index = ['PP', 'AdvP', 'NP', 'PrNP\\n(proper noun phrase)']\n",
    "\n",
    "display(loca_types)\n",
    "\n",
    "countBarplot(loca_types, save=firstyear+'loca_types.png', xlabel='Phrase Functions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loca_types.to_excel(firstyear+'loca_types.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare percentage of prepositions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loca_types.loc['PP'][0]  / loca_types.sum()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cases with a proper noun in Time Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.show(A.search('''\n",
    "\n",
    "# phrase function=Time\n",
    "# /with/\n",
    "#     <nhead- word st=c lex#JWM/|MWT/\n",
    "#     <: word language=Hebrew pdp=nmpr\n",
    "# /-/\n",
    "\n",
    "# '''), extraFeatures='st')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See if Differences Between Loca and Time are Statistically Significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loca_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_vs_loca = pd.concat([cx_types, loca_types], axis=1, sort=False).fillna(0)\n",
    "time_vs_loca.columns = ['Time', 'Loca']\n",
    "\n",
    "time_vs_loca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Fisher's test for significance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_vs_loca_fish = apply_fishers(time_vs_loca)\n",
    "\n",
    "time_vs_loca_fish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preposition & Time Associations\n",
    "\n",
    "I want to see whether certain prepositions are particularly associated with certain time nouns. A version of this analysis was done [SBH_time_expressions](https://nbviewer.jupyter.org/github/CambridgeSemiticsLab/BH_time_collocations/blob/master/analysis/SBH_time_expressions.ipynb) for Genesis-Kings. Here we do the analysis for the entire Hebrew Bible.\n",
    "\n",
    "The association measure is the Fisher's exact test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_obj_counts = collections.defaultdict(lambda: collections.Counter())\n",
    "prep2obj2res = collections.defaultdict(lambda: collections.defaultdict(list))\n",
    "allpreps = collections.Counter()\n",
    "\n",
    "for cx in F.otype.s('construction'):\n",
    "    \n",
    "    ph = L.d(cx, 'phrase')[0] # get first phrase\n",
    "    \n",
    "    if F.typ.v(ph) != 'PP':\n",
    "        continue\n",
    "            \n",
    "    prep_chunk = next(obj for obj in L.d(cx, 'chunk') if F.label.v(obj) == 'prep') # get prep chunk\n",
    "    prep_obj = E.obj_prep.t(L.d(prep_chunk, 'word')[-1])\n",
    "    prep_text = '.'.join(F.lex_utf8.v(w) for w in L.d(prep_chunk, 'word'))\n",
    "    allpreps[prep_text] += 1\n",
    "    \n",
    "    if prep_obj:\n",
    "        obj_text = F.lex_utf8.v(prep_obj[0])\n",
    "        prep_obj_counts[prep_text][obj_text] += 1\n",
    "        prep2obj2res[prep_text][obj_text].append(L.d(cx, 'phrase'))\n",
    "        \n",
    "prep_obj_counts = pd.DataFrame(prep_obj_counts).fillna(0)\n",
    "allpreps = convert2pandas(allpreps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Preposition Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpreps.to_excel(firstyear+'prep_counts.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count בְּ's share..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpreps.loc['ב'].sum() / allpreps.sum()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = A.search('''\n",
    "\n",
    "phrase function=Time typ=PP\n",
    "    <nhead- word lex=>RK=/\n",
    "\n",
    "''')\n",
    "\n",
    "A.show(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatPassages(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the association test below. This will take some time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po_assoc = apply_fishers(prep_obj_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attraction Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_hue(iterable_data, p=1.3, maxvalue=10, minvalue=-10):\n",
    "    '''\n",
    "    Function to assign heat-map hues based \n",
    "    on a p-value midpoint and max/min attraction\n",
    "    values.\n",
    "    \n",
    "    The following rules are used for making\n",
    "    the colors:\n",
    "    p = pvalue, i.e. significance level\n",
    "    upper grey = p\n",
    "    lower grey = -p\n",
    "    starting red = p+0.1\n",
    "    starting blue = -p-0.4\n",
    "    max_red = max(dataset) if > p = hotmax\n",
    "    max_blue = min(dataset) if < p = coldmax\n",
    "    \n",
    "    --output--\n",
    "    1. a dataframe with values mapped to a unique color code\n",
    "    2. a list of rgba colors that are aligned with the\n",
    "       indices of the data\n",
    "    '''\n",
    "    \n",
    "    maxvalue = int(maxvalue) # for max red\n",
    "    minvalue = int(minvalue) # for max blue\n",
    "        \n",
    "    # assign ranges based on p values and red/blue/grey\n",
    "    red_range = len(range(int(p), maxvalue+1))\n",
    "    blue_range = len(range(int(p), abs(minvalue-1)))\n",
    "        \n",
    "    blues = sns.light_palette('blue', blue_range)\n",
    "    reds = sns.light_palette('red', red_range)\n",
    "    grey = sns.color_palette('Greys')[0]\n",
    "    \n",
    "    # assign colors based on p-value\n",
    "    data = list()\n",
    "    colorCount = collections.Counter()\n",
    "    rgbs = list()\n",
    "    for point in iterable_data:\n",
    "        if point > p:\n",
    "            rgb = reds[int(point)-1]\n",
    "            color = 'red'\n",
    "        elif point < -p:\n",
    "            rgb = blues[abs(int(point))-1] \n",
    "            color = 'blue'\n",
    "        else:\n",
    "            rgb = grey\n",
    "            color = 'grey'\n",
    "            \n",
    "        color_count = colorCount.get(color, 0)\n",
    "        colorCount[color] += 1\n",
    "        data.append([point, f'{color}{color_count}'])\n",
    "        rgbs.append(rgb)\n",
    "        \n",
    "    data = pd.DataFrame(data, columns=('value', 'color'))\n",
    "        \n",
    "    return data, rgbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values for uniform hue assignment:\n",
    "maxattraction = float(po_assoc.max().max())\n",
    "minattraction = float(po_assoc.min().min())\n",
    "pvalue = 1.3\n",
    "\n",
    "def plot_attraction(prep, size=(15, 5), save=''):\n",
    "        \n",
    "    # get plot data and generate hues\n",
    "    colexs = po_assoc[prep].sort_values()    \n",
    "    colex_data, colors = assign_hue(colexs.values, p=pvalue, maxvalue=maxattraction, minvalue=minattraction)\n",
    "    \n",
    "    # plot the figure\n",
    "    plt.figure(figsize=size)\n",
    "    dummyY = ['']*colexs.shape[0] # needed due to bug with Y & hue\n",
    "    ax = sns.swarmplot(x=colex_data['value'], y=dummyY, hue=colex_data['color'], size=15, palette=colors)\n",
    "    ax.legend_.remove()\n",
    "        \n",
    "     # offset annotation text from dot for readability\n",
    "    offsetX, offsetY = np.array(ax.collections[0].get_offsets()).T\n",
    "    \n",
    "    plt.xlabel('log10 Fisher\\'s Scores (attraction)')\n",
    "    \n",
    "    # annotate lexemes for those with significant values\n",
    "    for i, colex in enumerate(colexs.index):  \n",
    "        annotateX = offsetX[i]\n",
    "        annotateY = offsetY[i] - 0.06\n",
    "        colex_text = reverse_hb(colex).replace('/','').replace('=','')\n",
    "        if colexs[colex] > pvalue:\n",
    "            ax.annotate(colex_text, (annotateX, annotateY), size=20, fontname='Times New Roman')\n",
    "        elif colexs[colex] < -pvalue:\n",
    "            ax.annotate(colex_text, (annotateX, annotateY), size=20, fontname='Times New Roman')\n",
    "            \n",
    "    if save:\n",
    "        plt.savefig(f'paper_data/firstyear/{prep}_assocs.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.title(f'Time Attractions to {reverse_hb(prep)}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at everything up to כ by setting a count limit of > 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prep in prep_obj_counts.columns[(prep_obj_counts.sum() > 20)]:\n",
    "    \n",
    "    top_attractions = pd.DataFrame(po_assoc[prep].sort_values(ascending=False))\n",
    "    top_attractions.columns = ['Fisher\\'s Score']\n",
    "    top_attractions['Raw Counts'] = prep_obj_counts[prep].loc[top_attractions.index]\n",
    "    top_attractions.round(2).to_excel(firstyear+f'{prep}_top_assocs.xlsx')\n",
    "    \n",
    "    plot_attraction(prep, size=(18, 5), save=True)\n",
    "    display(top_attractions.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at ממחרת..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mxrt = A.search('''\n",
    "\n",
    "verse\n",
    "    clause\n",
    "        phrase function=Time\n",
    "            <head- word lex=MN\n",
    "            <obj_prep- word lex=MXRT/\n",
    "\n",
    "''')\n",
    "\n",
    "'; '.join(['{} {}:{}'.format(*T.sectionFromNode(res[0])) for res in min_mxrt if F.txt.v(res[1]) in {'N', '?N'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'; '.join(['{} {}:{}'.format(*T.sectionFromNode(res[0])) for res in min_mxrt if F.txt.v(res[1]) not in {'N', '?N'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with מתמול"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_tmwl = A.search('''\n",
    "\n",
    "verse\n",
    "    clause\n",
    "        phrase function=Time\n",
    "            <head- word lex=MN\n",
    "            <obj_prep- word lex=TMWL/\n",
    "\n",
    "''')\n",
    "\n",
    "'; '.join(['{} {}:{}'.format(*T.sectionFromNode(res[0])) for res in min_tmwl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text(min_tmwl[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.show(A.search('''\n",
    "\n",
    "phrase function=Time\n",
    "    <head- word lex=MN\n",
    "    <obj_prep- word lex=RXM/\n",
    "\n",
    "'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see that times which are attracted to ב are primarily calendrical times like \"day\", \"year\", \"month\", \"morning\", but also עת \"time\". The attraction between יום and ב is quite strong.\n",
    "\n",
    "The ל preposition, as well as עד, prefers more deictic, adverbial kinds of indicators like לעולם, לצח, לפני, מחר. Indeed עד has nearly identical preferences. The association between ל and עולם is the strongest in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('top 5 association scores in dataset by their prep')\n",
    "po_assoc.max().sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('top 5 associations to ל')\n",
    "po_assoc['ל'].sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This very strong score suggests the possibility that ל and עולם together constitute a strongly entrenched unit. Note also that the association between ל and נצח is likewise quite strong, as is the association with פנה. These smaller associations can be interpreted through the entrenched combination of ל+עולם.  \n",
    "\n",
    "The preposition אחר has a distinct preference for nouns that are not necessary associated with time, such as proper names and nouns representing events. \n",
    "\n",
    "כ is attracted to עת, which is a notable similarity with ב. This is consistent with observations that these two prepositions have similar meanings. The use with תמול and אתמול are worth investigating. \n",
    "\n",
    "Finally, מן is primarily attracted to מחרת, a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Constructions, Raw Forms (without accents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_inventory = set(l for w in F.otype.s('word') for l in F.voc_lex_utf8.v(w))\n",
    "\n",
    "raw_surfaces = collections.Counter()\n",
    "\n",
    "for cx in F.otype.s('construction'):\n",
    "    surface = ''\n",
    "    for w in L.d(cx, 'word'):\n",
    "        for let in F.g_word_utf8.v(w):\n",
    "            if let in letter_inventory:\n",
    "                surface += let\n",
    "        if F.trailer_utf8.v(w) in letter_inventory:\n",
    "            surface += F.trailer_utf8.v(w)\n",
    "    raw_surfaces[surface] += 1\n",
    "        \n",
    "raw_surfaces = convert2pandas(raw_surfaces)\n",
    "\n",
    "raw_surfaces.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_surfaces.head(20).to_excel(firstyear+'raw_surfaces.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Constructions, Clustered on Raw Surface Forms without Vocalization (tokens)\n",
    "\n",
    "In this section, I break down time constructions by clustering them based on surface forms and various surface form filters. This is a rough form of clustering, by which two time constructions are grouped together if their tokenized strings match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surfaceToken(phrasenode):\n",
    "    '''\n",
    "    Return a surface token of a phrase node.\n",
    "    The words are dot-separated and heh consonants\n",
    "    are added if they are present in vocalized form. \n",
    "    '''\n",
    "    subtokens = []\n",
    "    for w in L.d(phrasenode, 'word'):\n",
    "        if F.lex.v(w) == 'H':\n",
    "            subtokens.append('ה')\n",
    "        else:\n",
    "            subtokens.append(F.g_cons_utf8.v(w))\n",
    "    return '.'.join(subtokens)\n",
    "    \n",
    "\n",
    "freq_surface = collections.Counter()\n",
    "for cx in F.otype.s('construction'):\n",
    "    freq_surface[surfaceToken(cx)] += 1\n",
    "freq_surface = convert2pandas(freq_surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_surface.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_surface.to_excel(firstyear+'raw_tokens.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_surface.head(50).sum()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_surface.head(50).sum()[0] / len(list(F.otype.s('construction')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ב.ה.יום.ה.הוא is a dominant pattern. But there are other patterns that are similar to it, such as עד.ה.יום.ה.זה or ב.ה.עת.ה.היא. Other similarities include ל.ֹעולם and עד.עולם. Taking a broader definition of similarity to include a role within the phrase, we can see similarities between the preposition + object constructions such as: ל.עולם, ב.יום, ל.נצח."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = '''\n",
    "ב.ה.יום.ה.הוא\n",
    "עד.ה.יום.ה.זה\n",
    "ב.ה.עת.ה.היא\n",
    "ב.ה.ימים.ה.הם\n",
    "ב.ה.עת.ה.הוא \n",
    "ב.ה.לילה.ה.הוא \n",
    "ב.עצם.ה.יום.ה.זה \n",
    "'''.split('\\n')\n",
    "demos = [c.strip() for c in cases if c]\n",
    "\n",
    "freq_surface.loc[demos].sum()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_surface.loc[demos].sum()[0] / len(list(F.otype.s('construction')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defi = '''\n",
    "ה.יום\n",
    "ב.ה.בקר\n",
    "עד.ה.ערב\n",
    "ה.לילה\n",
    "ב.ה.ערב\n",
    "ב.ה.לילה'''.split('\\n')\n",
    "\n",
    "defis = [c.strip() for c in defi if c]\n",
    "\n",
    "freq_surface.loc[defis].sum()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_surface.loc[defis].sum()[0] / len(list(F.otype.s('construction')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Semantic Head Lexemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_heads = collections.Counter()\n",
    "\n",
    "for cx in F.otype.s('construction'):\n",
    "    \n",
    "    firstphrase = L.d(cx, 'phrase')[0]\n",
    "    semhead = E.nhead.t(firstphrase)[0]\n",
    "    \n",
    "    sem_heads[F.voc_lex_utf8.v(semhead)] += 1\n",
    "    \n",
    "sem_heads = convert2pandas(sem_heads)\n",
    "\n",
    "sem_heads.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_heads.head(50).to_excel(firstyear+'semantic_heads.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Headed by מלכות"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.show(A.search('''\n",
    "\n",
    "# construction\n",
    "#     =: phrase\n",
    "#     /with/\n",
    "#     <nhead- word lex=MLKWT/\n",
    "#     /-/\n",
    "\n",
    "# '''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Headed by ראשׁ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.show(A.search('''\n",
    "\n",
    "construction\n",
    "    =: phrase\n",
    "    /with/\n",
    "    <nhead- word lex=<WD/\n",
    "    /-/\n",
    "\n",
    "'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Constructions, Clustered on Parts of Speech and Chunks\n",
    "\n",
    "Based on the kinds of resemblances mentioned above, I wanted to obtain a clustering that better reflected word types and sub-constructions within the time constructions. A \"sub-construction\", what I have called \"chunks\", consist of either chained prepositional phrases: e.g. מקץ \"from the end of...\", or quantified noun phrases, which can consist of chained cardinal numbers such as שׁבעים ושׁשׁ שׁנה. These chunks were processed in [chunking](https://nbviewer.jupyter.org/github/CambridgeSemiticsLab/BH_time_collocations/blob/master/analysis/preprocessing/chunking.ipynb) and then further refined into complete tags in [time constructions [part 1]](https://nbviewer.jupyter.org/github/CambridgeSemiticsLab/BH_time_collocations/blob/master/analysis/time_constructions1.ipynb).\n",
    "\n",
    "The result is a tokenization strategy which produces larger, more useful clusters. In fact, the top 11 of these clusters account for 76% of the entire dataset, as I show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_times = collections.Counter()\n",
    "for cx in F.otype.s('construction'):\n",
    "    freq_times[F.label.v(cx)] += 1\n",
    "freq_times = convert2pandas(freq_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_times.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 11 account for 76% of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_times.head(11)['Total'].sum() / freq_times['Total'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 20 account for 83% of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_times.head(20)['Total'].sum() / freq_times['Total'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is my hunch that the remaining 25% / 17% of the data most often consists of some combination of the major types reflected in the top 75% group. Thus by describing and understanding these major types, we can obtain even better clustering parameters.\n",
    "\n",
    "From this point forward I will focus on accounting for the subgroups found amongst these major clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `prep.time`\n",
    "\n",
    "What kind of time nouns most often appear in the `time` slot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_time = collections.Counter()\n",
    "pt_prep = collections.Counter()\n",
    "pt_cx = collections.Counter()\n",
    "\n",
    "tag2res = collections.defaultdict(list)\n",
    "\n",
    "for cx in set(F.otype.s('construction')) & set(F.label.s('prep.time')):\n",
    "    time = next(role[0] for role in E.role.t(cx) if role[1]=='time')\n",
    "    prep = next(role[0] for role in E.role.t(cx) if role[1]=='prep')\n",
    "    time_text = F.lex_utf8.v(time)\n",
    "    prep_text = '.'.join(F.lex_utf8.v(w) for w in L.d(prep, 'word'))\n",
    "    cx_text = '.'.join(F.g_cons_utf8.v(w) for w in L.d(cx, 'word'))\n",
    "    \n",
    "    pt_time[time_text] += 1\n",
    "    pt_prep[prep_text] += 1\n",
    "    pt_cx[cx_text] += 1\n",
    "    tag2res[cx_text].append(L.d(cx, 'phrase'))\n",
    "    tag2res[time_text].append(L.d(cx, 'phrase'))\n",
    "    tag2res[prep_text].append(L.d(cx, 'phrase'))\n",
    "    \n",
    "pt_time = convert2pandas(pt_time)\n",
    "pt_prep = convert2pandas(pt_prep)\n",
    "pt_cx = convert2pandas(pt_cx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Raw Surface Form Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_cx.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_time.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Preposition Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does עולם ever have additional modifications? I know from previous analysis of time constructions that they often have various morphological modifications or additional specifications. I would expect this to be different with עולם, and I would also expect this situation to resemble other words that are being used adverbially. If there is indeed a strict separation between patterns with and without these kinds of modifications, I may have good reason to define this as an \"adverb construction,\" i.e. a construction with deictic sense and that caries its temporal modifications internally. \n",
    "\n",
    "Practically it makes more sense to first define what I mean, especially in terms of database querying, of \"modifications.\" In order to do that, I move on to the next most common item in the list, יום. I know from the previous analysis that יום *does* in fact attract these modifications. By definining them here, I might have a way to identify other cases that have such modifications. Then I can define those without modifications as the inverse of these search parameters.\n",
    "\n",
    "**Below are a few examples of יום as used with a preposition.** The examples are shown in the context of a sentence, because infinitival modifiers of יום will exist occur as clauses embedded in the same sentence. These cases in particular are marked with a clause relation of `RgRc` (Regens/rectum connection). Note that I have collapsed the cases with `end=1`. Modify this to see all the other examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.show(tag2res['יום'], condenseType='sentence', extraFeatures='st vt', end=1) # <- NB modify end= to see more than 5 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(tag2res['יום'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jwm = tag2res['יום']\n",
    "\n",
    "for ph in jwm[:5]:\n",
    "    print('{} {}:{}'.format(*T.sectionFromNode(ph[0])))\n",
    "    print(T.text(L.u(ph[0], 'sentence')[0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.search('''\n",
    "\n",
    "sentence\n",
    "    phrase function=Time\n",
    "    <nhead- word lex=JWM/\n",
    "    <: word lex=>CR\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.sectionFromNode(1181030)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text(1181030)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text(L.u(1181030, 'verse')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reviewing several dozen cases, I see 4 specific patterns that follow the construction ב+יום:\n",
    "\n",
    "* \\+ [CONSTRUCT] + [VERBAL CLAUSE rela=RgRc] (often with infinitive but occasionally with qatal)\n",
    "* \\+ [PLURAL ENDING]\n",
    "* \\+ [PRONOMINAL SUFFIX]\n",
    "* \\+ [אשׁר in VERBAL CLAUSE rela=Attr]\n",
    "\n",
    "Let's see how much of the יום pattern this accounts for. The individual cases are stored under `tag2res['יום']`. We define a few search patterns to account for the cases above. The phrases stored in `tag2res` are fed in as sets so that only those cases are queried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yom_phrases = set(phrase for res in tag2res['יום'] for phrase in res)\n",
    "found_yom = set()\n",
    "\n",
    "print(len(yom_phrases), 'total יום phrases')\n",
    "\n",
    "# + CONSTRUCT + VERBAL CLAUSE\n",
    "verbal_construct = set(res[1] for res in A.search('''\n",
    "\n",
    "sentence\n",
    "    yomphrase\n",
    "        word lex=JWM/\n",
    "        /with/\n",
    "        <mother- clause rela=RgRc kind=VC\n",
    "        /or/\n",
    "        y1:yomphrase\n",
    "            ..\n",
    "        c1:clause rela=Attr\n",
    "        y1 <mother- c1\n",
    "        /-/\n",
    "\n",
    "''', sets={'yomphrase': yom_phrases}, silent=True))\n",
    "found_yom |= (verbal_construct)\n",
    "\n",
    "print(f'verbal construct cases found: {len(verbal_construct)}')\n",
    "\n",
    "\n",
    "# + PLURAL\n",
    "pluralday = set(res[1] for res in A.search('''\n",
    "\n",
    "sentence\n",
    "    yomphrase\n",
    "        word lex=JWM/ nu=pl\n",
    "\n",
    "''', sets={'yomphrase': yom_phrases}, silent=True))\n",
    "found_yom |= (pluralday)\n",
    "\n",
    "print(f'plural cases found: {len(pluralday)}')\n",
    "\n",
    "# + PRONOMINAL \n",
    "pronominalday = set(res[1] for res in A.search('''\n",
    "\n",
    "sentence\n",
    "    yomphrase\n",
    "        word lex=JWM/ prs#absent\n",
    "\n",
    "''', sets={'yomphrase': yom_phrases}, silent=True))\n",
    "found_yom |= (pronominalday)\n",
    "print(f'pronominal suffix cases found: {len(pronominalday)}')\n",
    "\n",
    "# + אשׁר/relative + VERBAL CLAUSE \n",
    "asher_day = set(res[1] for res in A.search('''\n",
    "\n",
    "sentence\n",
    "        yomphrase\n",
    "            word lex=JWM/\n",
    "            /with/\n",
    "            sentence\n",
    "                ..\n",
    "                <: clause rela=Attr\n",
    "                    =: phrase function=Rela\n",
    "            /-/\n",
    "\n",
    "''', sets={'yomphrase': yom_phrases}, silent=True))\n",
    "found_yom |= (asher_day)\n",
    "print(f'relative attributive cases found: {len(asher_day)}')\n",
    "\n",
    "print(f'remaining cases: {len(yom_phrases-found_yom)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the 5 remaining cases..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_jwm = [(case,) for case in yom_phrases-found_yom]\n",
    "A.show(rare_jwm, extraFeatures='st nu', condenseType='sentence') # uncomment to see cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.sectionFromNode(822516)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text(L.u(822516, 'verse')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.show(A.search('''\n",
    "\n",
    "phrase function=Time\n",
    "    <head- word lex=MN\n",
    "    <obj_prep- word lex=<WLM/\n",
    "\n",
    "\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.sectionFromNode(722459)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text(L.u(722459, 'verse')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining cases are all interesting, especially Psalm 138:3 and Ruth 4:5. These may be true cases of non-modification, **construing יום as an adverb.** The case of Ezra 3:4 does not look like an adverbial use of the time construction. I will consider removing it from the samples moving forward. \n",
    "\n",
    "There is one important case that I did not account for at first: the dual ending. I added that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + PLURAL\n",
    "dualday = set(res[1] for res in A.search('''\n",
    "\n",
    "sentence\n",
    "    yomphrase\n",
    "        word lex=JWM/ nu=du\n",
    "\n",
    "''', sets={'yomphrase': yom_phrases}, silent=True))\n",
    "found_yom |= (dualday)\n",
    "\n",
    "print(f'dual cases found: {len(dualday)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below this final case is added to the others, bringing the total construction forms to 5:\n",
    "\n",
    "* \\+ [CONSTRUCT] + [VERBAL CLAUSE rela=RgRc | occasionally Attr in BHSA] (often with infinitive but occasionally with qatal)\n",
    "* \\+ [PLURAL ENDING]\n",
    "* \\+ [PRONOMINAL SUFFIX]\n",
    "* \\+ [אשׁר in VERBAL CLAUSE rela=Attr]\n",
    "* \\+ [DUAL ENDING]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on these features, I propose to attempt a two-way subdivision of all constructions in the `prep.time` construction: 1) those that appear with specification, and 2) those that appear without specification.** I will test the efficacy of this division below with a handcoded version of the templates from above. \n",
    "\n",
    "The specified times will go into `cx_specified` mapped to the form that they were found in.\n",
    "\n",
    "NB: I have moved the plural to the bottom. The plural can offten co-occur with other specifications. Yet it seems that the other specifications have the \"final say\" so-to-speak, in the sense that they are still able to function as they do. The effect of the plural is the same as it is elsewhere: to extend the time over a duration through quantification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagSpecs(cx):\n",
    "    \n",
    "    '''\n",
    "    A function that queries for \n",
    "    specifications on a time noun\n",
    "    or phrase within a construction \n",
    "    marked for time function.\n",
    "    \n",
    "    output - string\n",
    "    '''\n",
    "    \n",
    "    phrase = L.d(cx, 'phrase')[0]\n",
    "    time = next(role[0] for role in E.role.t(cx) if role[1]=='time')\n",
    "    time_mother = [cl for cl in E.mother.t(time) if F.rela.v(cl) == 'RgRc']\n",
    "    phrase_mother = [cl for cl in E.mother.t(phrase) if F.rela.v(cl) == 'Attr']\n",
    "    result = (phrase, time)\n",
    "\n",
    "    \n",
    "    tag = []\n",
    "    \n",
    "    # isolate construct + verbal clauses\n",
    "    if time_mother:\n",
    "        tag.append('construct + VC')\n",
    "        \n",
    "    elif F.st.v(time) == 'c':\n",
    "        tag.append('construct + NP?')\n",
    "        \n",
    "    # isolate pronominal suffixes\n",
    "    if F.prs.v(time) not in {'absent', 'n/a'}:\n",
    "        tag.append('pronominal suffix')\n",
    "        \n",
    "    # isolate relative clauses | attributives\n",
    "    if phrase_mother:\n",
    "        if 'Rela' in set(F.function.v(ph) for ph in L.d(phrase_mother[0], 'phrase')):\n",
    "            tag.append('RELA + VC')\n",
    "        else:\n",
    "            tag.append('+ VC')\n",
    "        \n",
    "    # isolate plural endings\n",
    "    if F.nu.v(time) == 'pl' and F.pdp.v(time) not in {'prde'}: # exclude plural forms inherent to the word\n",
    "        tag.append('plural')\n",
    "        \n",
    "    # isolate dual endings\n",
    "    if F.nu.v(time) == 'du':\n",
    "        tag.append('dual')\n",
    "        \n",
    "    return ' & '.join(tag), result, time\n",
    "\n",
    "\n",
    "cx_specified = collections.defaultdict(list)\n",
    "lex2tag2result = collections.defaultdict(lambda: collections.defaultdict(list)) # keep a mapping from time lexemes to their specific results \n",
    "\n",
    "for cx in set(F.otype.s('construction')) & set(F.label.s('prep.time')):\n",
    "    \n",
    "    tag, result, time = tagSpecs(cx)\n",
    "    \n",
    "    if tag:\n",
    "        cx_specified[tag].append(result)\n",
    "        lex2tag2result[F.lex_utf8.v(time)][tag].append(result)\n",
    "        \n",
    "cx_specified_all = set(res for tag in cx_specified for res in cx_specified[tag])\n",
    "        \n",
    "found = len(set(res[0] for res in cx_specified_all))\n",
    "\n",
    "print(f'number found {found} ({found / pt_cx[\"Total\"].sum()})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag, results in cx_specified.items():\n",
    "    print('{:<30} {}'.format(tag, len(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These patterns thus account for 40% of the cases in this construction. That is a good discrimination rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(cx_specified['construct + NP?'], condenseType='sentence', extraFeatures='st')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what lexemes those accounted for..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_count = collections.Counter()\n",
    "\n",
    "for phrase, time in cx_specified_all:\n",
    "    lex_count[F.lex_utf8.v(time)] += 1\n",
    "    \n",
    "lex_count = convert2pandas(lex_count)\n",
    "\n",
    "lex_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex2tag2result['פנה']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(lex2tag2result['יום']['pronominal suffix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of these lexemes are quite similar to יום in terms of being calendrical or having similar prepositional preferences.\n",
    "\n",
    "Below are lexemes that were not found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_specified = []\n",
    "nsresults = collections.defaultdict(list)\n",
    "\n",
    "spec_set = set(res[0] for res in cx_specified_all)\n",
    "\n",
    "for cx in set(F.otype.s('construction')) & set(F.label.s('prep.time')):\n",
    "    \n",
    "    phrase = L.d(cx, 'phrase')[0]\n",
    "    \n",
    "    if phrase not in spec_set:\n",
    "        time = next(role[0] for role in E.role.t(cx) if role[1]=='time')\n",
    "        result = (phrase, time)\n",
    "        not_specified.append(result)\n",
    "        nsresults[F.lex_utf8.v(time)].append(result)\n",
    "        \n",
    "print(len(not_specified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_count2 = collections.Counter()\n",
    "\n",
    "for phrase, time in not_specified:\n",
    "    lex_count2[F.lex_utf8.v(time)] += 1\n",
    "    \n",
    "lex_count2 = convert2pandas(lex_count2)\n",
    "\n",
    "lex_count2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a strong list of adverbial forms. There are also several nouns mixed in. Note the appearance of יומם as well, which is a great example of a nominal form that is slotted as an adverbial—in this case that is obvious because of the adverbial ending that is appended to it.\n",
    "\n",
    "**The cases above, as they are not modified, are anchored either to discourse context or the time of speech.** Others, such as בטן, have rather inferred anchor points. It would be interesting to isolate when the reference is discourse-anchored. For example, the case of proper names this would be relatively easy to ascertain. However, most of these seem to be anchored to speech time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.show(tag2res['זאת'], extraFeatures='prs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This case ^ is a good example, though, of a discourse-anchored form.\n",
    "\n",
    "Below, I randomize the not specified list and manually inspect many examples to make sure there are no specifications I've missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(not_specified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(not_specified, condensed=False, condenseType='sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Role of Specifications\n",
    "\n",
    "After reflecting on the specifications that I've isolated in the `prep.time` group, I am wondering what they have in common and where they differ. The + verbal clause specifications and pronominal suffixes anchor the time references to specific participants or events in the discourse. The pronominal suffixes also have a commonality with the verbal clauses since both contain markers of person, often identically so as the infinitive accepts the pronominal suffix. The other two specifications, that of the plural and the dual, then seemingly have a quite different role to play. They do not anchor the time, but they modify it by extending it in quantity, which metaphorically indicates a duration of time. In the case of the dual this duration is specified. **Furthermore, the plural differs from the other specifications in that it is compatible with them—in all other cases the specifications are mutually exclusive.**\n",
    "\n",
    "The time of יום accepts all of the major roles, revealing its multi-purpose utility as the generic time marker, as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spec, results in lex2tag2result['יום'].items():\n",
    "    print('{:<30} {}'.format(spec, len(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "עת, as a seeming near synonym of יום, also accepts a variety of specifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spec, results in lex2tag2result['עת'].items():\n",
    "    print('{:<30} {}'.format(spec, len(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next most common term, פנה, appears in all cases in the plural, but in 6 cases with an additional specification of the suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spec, results in lex2tag2result['פנה'].items():\n",
    "    print('{:<30} {}'.format(spec, len(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "מות only occurs with the pronominal suffix though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spec, results in lex2tag2result['מות'].items():\n",
    "    print('{:<20} {}'.format(spec, len(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After more data has been gathered, it would be a good idea to see whether there are any statistical associations between certain terms and specification. For instance, it is clear the עולם has a strong association with non-specification. Then some terms are used both with and without it.\n",
    "\n",
    "**Looking through the list of other major clusters besides `prep.time`, it seems that the other clusters are likewise defined by different methods of specification:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_times.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I propose the possibility that specification is the means by which a time is anchored to discourse.** That is self-evident in the prominence of the form `prep.H.time.H.dem`, i.e. the demonstrative plays a front-and-center role, anchoring the time noun to a point forward or backward relative to the discourse. The same is evident with the cluster `prep.H.time.H.ordn`, with the ordinal number anchoring the time to a day or month on the calendar.\n",
    "\n",
    "Other clusters potentially resemble the unspecified times found above, such as `quantNP`, a quantified noun phrase. These times technically have the specification of quantification, but it is likely, as we have seen with the plural, that this form can variously be combined with or without additional specifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-specifications with `prep.H.time.H.dem`?\n",
    "\n",
    "This is the next most frequent cluster in the set. With the demonstrative already in place, it seems likely that this construction deflects additional specifications. Let's write a query to see if this is so. The query will utilize similar parameters as were used to separate specified from non-specifieds above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prephdem_specs = collections.Counter()\n",
    "phdtag2res = collections.defaultdict(list)\n",
    "\n",
    "for cx in set(F.otype.s('construction')) & set(F.label.s('prep.H.time.H.dem')):\n",
    "    tag, result, time = tagSpecs(cx)\n",
    "    tag = tag or 'no further specification'\n",
    "    prephdem_specs[tag] += 1\n",
    "    phdtag2res[tag].append(result)\n",
    "    \n",
    "convert2pandas(prephdem_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 4 cases of additional specification. Let's look closer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.show(phdtag2res['RELA + VC'], condenseType='sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.show(phdtag2res['RELA + VC & plural'], condenseType='sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These specifications *may* reveal a difference in the attributive specification characterized by relative particles, and the specification characterized by the construct. The attributive spec can describe an anchored time. But the construct spec, if it plays an anchoring role itself, may resist being combined with additional anchors.\n",
    "\n",
    "The majority of cases, though, seem to disprefer specification. I will examine some random selections from the `no further specification` set to make sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(phdtag2res['no further specification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(phdtag2res['no further specification'], condensed=False, condenseType='sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifications with `quantNP`\n",
    "\n",
    "I will apply the same query method with `quantNP`, to see how much of the data is accounted for and whether any new specifications are missed. The function has to be modified a bit to interact with the `quantNP` chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagSpecsQuant(cx):\n",
    "    \n",
    "    '''\n",
    "    A function that queries for \n",
    "    specifications on a time noun\n",
    "    or phrase within a construction \n",
    "    marked for time function.\n",
    "    \n",
    "    output - string\n",
    "    \n",
    "    Note on Quantifier Constructions:\n",
    "    The quantNP can be a complex construction.\n",
    "    It is built of smaller quantNP chunks, \n",
    "    perhaps a single chunk or perhaps more.\n",
    "    The \"quantified\" edge value identifies a word as the \n",
    "    time noun being quantified. But this is only stored on\n",
    "    the lowest level chunks. A few extra steps are needed\n",
    "    to isolate these nouns and check them for specifications.\n",
    "    '''\n",
    "    \n",
    "    phrase = L.d(cx, 'phrase')[0]\n",
    "    phrase_mother = [cl for cl in E.mother.t(phrase) if F.rela.v(cl) == 'Attr'] # look for attr rela on phrase\n",
    "    \n",
    "    # isolate component quantNP chunks\n",
    "    atomic_chunks = [chunk for chunk in L.d(cx, 'chunk') \n",
    "                         if L.u(chunk, 'chunk') # either is not top level chunk\n",
    "                         or len(L.d(cx, 'chunk')) == 1 # or has no embedded chunks\n",
    "                    ]\n",
    "    # get list of quantified time noun(s)\n",
    "    times = [noun[0] for chunk in atomic_chunks for noun in E.role.t(chunk) if noun[1] == 'quantified']    \n",
    "    time_mothers = [cl for time in times for cl in E.mother.t(time) if F.rela.v(cl) == 'RgRc']\n",
    "    \n",
    "    result = [phrase] + times\n",
    "    tag = []\n",
    "    \n",
    "    # isolate construct + verbal clauses\n",
    "    if time_mothers:\n",
    "        tag.append('construct + VC')\n",
    "    \n",
    "    elif set(t for t in times if F.st.v(t) == 'c'):\n",
    "        tag.append('construct + ??')\n",
    "        \n",
    "    # isolate pronominal suffixes\n",
    "    if set(t for t in times if F.prs.v(t) not in {'absent', 'n/a'}):\n",
    "        tag.append('pronominal suffix')\n",
    "        \n",
    "    # isolate relative clauses | attributives\n",
    "    if phrase_mother:\n",
    "        if 'Rela' in set(F.function.v(ph) for ph in L.d(phrase_mother[0], 'phrase')):\n",
    "            tag.append('RELA + VC')\n",
    "        else:\n",
    "            tag.append('+ VC')\n",
    "        \n",
    "    # isolate plural endings\n",
    "    if set(t for t in times if F.nu.v(t) == 'pl' and F.pdp.v(t) not in {'prde'}): # exclude plural forms inherent to the word\n",
    "        tag.append('plural')\n",
    "        \n",
    "    # isolate dual endings\n",
    "    if set(t for t in times if F.nu.v(t) == 'du'):\n",
    "        tag.append('dual')\n",
    "        \n",
    "    return ' & '.join(tag), result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantnp_specs = collections.Counter()\n",
    "qnptag2res = collections.defaultdict(list)\n",
    "\n",
    "\n",
    "for cx in set(F.otype.s('construction')) & set(F.label.s('quantNP')):\n",
    "    tag, result = tagSpecsQuant(cx)\n",
    "    tag = tag or 'no known spec'\n",
    "    quantnp_specs[tag] += 1\n",
    "    qnptag2res[tag].append(result)\n",
    "    \n",
    "convert2pandas(quantnp_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plural specs are expected with the quantifier NP. As above, the relative attributive spec has appeared. But the quantified NP has resisted any construct relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.show(qnptag2res['RELA + VC & plural'], condenseType='sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will inspect randomized cases of `no known spec` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(qnptag2res['no known spec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(qnptag2res['no known spec'], condensed=False, condenseType='sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: MERGE SEVERAL OF THESE KINDS OF PHRASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.show(A.search('''\n",
    "\n",
    "# phrase function=Time\n",
    "# /with/\n",
    "# clause\n",
    "#     ..\n",
    "#     <: phrase function=Modi\n",
    "# /or/\n",
    "# clause\n",
    "#     phrase function=Modi\n",
    "#     <: ..\n",
    "# /-/\n",
    "\n",
    "# '''), condenseType='sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `prep.H.time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prephtime = collections.Counter()\n",
    "phttag2res = collections.defaultdict(list)\n",
    "\n",
    "\n",
    "for cx in set(F.otype.s('construction')) & set(F.label.s('prep.H.time')):\n",
    "    tag, result, time = tagSpecs(cx)\n",
    "    tag = tag or 'no known spec'\n",
    "    prephtime[tag] += 1\n",
    "    phttag2res[tag].append(result)\n",
    "    \n",
    "convert2pandas(prephtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_times.loc['prep.time.adju']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freq_times.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.show(A.search('''\n",
    "\n",
    "# phrase function=Time\n",
    "#     word lex=JWM/ st=c\n",
    "#     <: word pdp=subs\n",
    "\n",
    "# '''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature-Based Clustering in a Complex Constructional Network\n",
    "\n",
    "After the analysis thus far, I believe I have gathered a list of features which are fairly efficacious at separating time constructions:\n",
    "\n",
    "* PP | NP\n",
    "* ה time\n",
    "* H time H ___\n",
    "    * \\+ demonstrative\n",
    "    * \\+ ordinal\n",
    "    * \\+ attributive\n",
    "* construct\n",
    "    * construct + VP\n",
    "    * construct + NP\n",
    "* attributive (+אשר)\n",
    "* pronominal suffix\n",
    "* plural via du | pl endings\n",
    "* quantification via quantNP\n",
    "\n",
    "It is important that several of these features are \"stackable\"—meaning that they can be combined in different ways. The ultimate goal is to achieve a taxonomy of time constructions at the phrasal level. So how should we think about these various pieces and their inter-relatability?\n",
    "\n",
    "One way to represent these structures would be with tree-like inheritance, so that a timePP inherits its NP patterns from timeNP. The limitations of this approach can be seen in the following construction:\n",
    "\n",
    "* ב.ה.יום.ה.זה (e.g. Ex 19:1, Lev 8:34; 88x total) \n",
    "* ה.יום.ה.זה (e.g. Deut 2:25, 5:24; 29x total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples of ביום הזה and הים הזה isolated below...\n",
    "\n",
    "bhjwm = [L.d(cx,'phrase') for cx in F.label.s('prep.H.time.H.dem')\n",
    "           if not {'JWM/', 'ZH'} - set(F.lex.v(w) for w in L.d(cx, 'word'))]\n",
    "\n",
    "hjwm = [L.d(cx,'phrase') for cx in F.label.s('H.time.H.dem')\n",
    "           if not {'JWM/', 'ZH'} - set(F.lex.v(w) for w in L.d(cx, 'word'))]\n",
    "\n",
    "print(f'{len(bhjwm)} of ב.ה.יום.ה.זה found in dataset...')\n",
    "print(f'{len(hjwm)} of ה.יום.ה.זה found in dataset...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a tree-based taxonomy, these two constructions would be separated into two different groups: PP phrases and NP phrases. This is problematic, because the taxonomy then misses the relatedness of the two phrases. Furthermore, the close relation could indeed be crucial to understanding the semantics of the NP version of this phrase: because ב.ה.יום.ה.זה is more common, hence more entrenched, it should inform how we read ה.יום.ה.זה. Indeed, this phrase seems to have very similar semantics to ב.ה.יום.ה.זה. In fact, the NP ה.יום.ה.זה would seem to have even less in common with other bare NP's, which typically do not indicate a point in time but a duration in time, e.g. שׁבעים שׁנים \"for seven years.\"  \n",
    "\n",
    "A better representation is a graph network, wherein constructions are represented as nodes and inheritances between them as edges. This format allows for multiple inheritance paths, and for numerous features to be modeled and compared at once. Furthermore, by utilizing the notion of a graph, it is possible to cluster based on a set-like comparison between features of constructions. For instance, in the case above: three similarities are registered, the presence of the *heh* definite article, the `H.time.H.modifier` construction, and the presence of the demonstrative. Thus, accounting for the difference of a preposition, we could place a value on this similarity, for instance, by saying they are 3/4 or 75% similar (the Jaccard similarity measure). These similarity values give the raw material needed to build clusters and taxonomic relations in a complex network. A nearest-neighbor clustering method (e.g. T-SNE) can find neighborhoods of similar constructions to identify distinct clusters within the constructions. A method such as PCA can be utilized to find major divisions and distinguish which features create the most separation in the dataset. The feature sets also allows us to easily select constructions based on the presence of a given feature. And we can look for associations and restrictions between particular features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolating a Test Set\n",
    "\n",
    "I make one exclusion:\n",
    "\n",
    "* exclude complex PP and NP constructions, i.e. those with coordination\n",
    "\n",
    "Except for: \n",
    "\n",
    "* coordination in quantNP constructions is allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagcount = collections.Counter()\n",
    "tag2res = collections.defaultdict(list)\n",
    "testset = set()\n",
    "\n",
    "test = []\n",
    "\n",
    "for cx in F.otype.s('construction'):\n",
    "    \n",
    "    cx_words = L.d(cx, 'word')\n",
    "    phrase = L.d(cx, 'phrase')[0]\n",
    "    ph_words = L.d(phrase, 'word')\n",
    "    \n",
    "    # either there is no conj or quantNP\n",
    "    is_quant = 'quantNP' in F.label.v(cx)\n",
    "    conj_check = ('conj' not in set(F.pdp.v(w) for w in cx_words)) or is_quant\n",
    "    # either there is only 1 time or is quantNP\n",
    "    ntime_check = (len([w for w in E.role.t(cx) if w[1] == 'time']) < 2) or is_quant\n",
    "    \n",
    "    singlephrase = len(L.d(cx, 'phrase')) == 1\n",
    "    pp_notin_np = not (F.typ.v(phrase) == 'NP' and 'prep' in set(F.pdp.v(w) for w in ph_words))\n",
    "    nprep_check = [F.pdp.v(w) for w in cx_words].count('prep') < 2\n",
    "    \n",
    "    is_match = all([cx_words, conj_check, ntime_check, \n",
    "                    nprep_check, pp_notin_np, singlephrase])\n",
    "    \n",
    "    if is_match:\n",
    "        tagcount[F.label.v(cx)] += 1\n",
    "        tag2res[F.label.v(cx)].append(L.d(cx, 'phrase'))\n",
    "        testset.add(cx)\n",
    "        \n",
    "tagcount = convert2pandas(tagcount)\n",
    "\n",
    "print(tagcount.shape)\n",
    "\n",
    "print('total time constructions: ', freq_times['Total'].sum())\n",
    "print('accounted for: ',  tagcount['Total'].sum(),' or ', tagcount['Total'].sum() / freq_times['Total'].sum())\n",
    "\n",
    "tagcount.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(tag2res['time.adju'], extraFeatures='sem_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tag in tagcount.index:\n",
    "#     print(tag)\n",
    "#     A.show(tag2res[tag][:1], extraFeatures='st')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndex(thislist, index):\n",
    "    '''\n",
    "    A safe way to get index from \n",
    "    a list/tuple. If indexError returns None.\n",
    "    '''\n",
    "    try:\n",
    "        return thislist[index]\n",
    "    except IndexError:\n",
    "        return None\n",
    "\n",
    "def getQuantTimes(cx):\n",
    "    '''\n",
    "    Extracts times from a quant chunk\n",
    "    '''\n",
    "    # isolate component quantNP chunks\n",
    "    atomic_chunks = [chunk for chunk in L.d(cx, 'chunk') \n",
    "                         if L.u(chunk, 'chunk') # either is not top level chunk\n",
    "                         or len(L.d(cx, 'chunk')) == 1 # or has no embedded chunks\n",
    "                    ]\n",
    "    # get list of quantified time noun(s)\n",
    "    times = [noun[0] for chunk in atomic_chunks for noun in E.role.t(chunk) if noun[1] == 'quantified']\n",
    "    return times\n",
    " \n",
    "def isQualQuant(word):\n",
    "    if F.sem_set.v(word) == 'quant' and F.ls.v(word) != 'card':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def tagConstructionSpecs(cx):\n",
    "    '''\n",
    "    A function that tags time constructions\n",
    "    with specifications found around their \n",
    "    time nouns. Returns a dictionary with\n",
    "    spec strings as keys and 1 as values,\n",
    "    wherein 1 simply means present.\n",
    "    '''\n",
    "    \n",
    "    phrase = L.d(cx, 'phrase')[0]\n",
    "    ph_words = L.d(phrase, 'word')\n",
    "    sent_words = L.d(L.u(phrase, 'sentence')[0], 'word')\n",
    "    dep_cl = next((cl for cl in E.mother.t(phrase) if F.rela.v(cl) == 'Attr'), None)\n",
    "    times = [time[0] for time in E.role.t(cx) if time[1] == 'time'] or getQuantTimes(cx) or E.nhead.t(phrase)\n",
    "    features = {}\n",
    "    \n",
    "    # phrase type, PP or NP, wherein AdvP are considered a kind of NP\n",
    "    typ = 'PPtime' if F.typ.v(phrase) == 'PP' else 'time'\n",
    "    features[typ] = 1\n",
    "    \n",
    "    for time in times:\n",
    "        \n",
    "        # get relative slot positions\n",
    "        timei = ph_words.index(time)\n",
    "        m1 = getIndex(ph_words, timei-1) # minus 1, etc.\n",
    "        m2 = getIndex(ph_words, timei-2)\n",
    "        p1 = getIndex(ph_words, timei+1) # plus 1, etc.\n",
    "        p2 = getIndex(ph_words, timei+2)\n",
    "        # relative slots in sentence\n",
    "        timei_s = sent_words.index(time)\n",
    "        s1 = getIndex(sent_words, timei_s+1)\n",
    "        \n",
    "        # preceding article\n",
    "        if F.lex.v(m1) == 'H':\n",
    "            features['H'] = 1\n",
    "        \n",
    "        # plurals\n",
    "        if F.nu.v(time) == 'pl' and F.pdp.v(time) != 'prde':\n",
    "            features['pl'] = 1\n",
    "            \n",
    "        elif F.nu.v(time) == 'du':\n",
    "            features['quant'] = 1\n",
    "            features['du'] = 1\n",
    "        \n",
    "        # pronom suffixs\n",
    "        if F.prs.v(time) not in {'absent', 'n/a'}:\n",
    "            features['sffx'] = 1\n",
    "        \n",
    "        # check quant & qual quants\n",
    "        is_quant = set(ch for ch in L.u(time, 'chunk') \n",
    "                          if F.label.v(ch) and 'quant' in F.label.v(ch))\n",
    "        if is_quant:\n",
    "            features['quant'] = 1\n",
    "            features['card'] = 1\n",
    "            \n",
    "        is_qualq = any([isQualQuant(m1),\n",
    "                        isQualQuant(m2) and F.lex.v(m1) == 'H',\n",
    "                        F.lex.v(p1) == 'H' and isQualQuant(p2)])\n",
    "        if is_qualq:\n",
    "            features['quant'] = 1\n",
    "            features['qual'] = 1\n",
    "        \n",
    "        # constructs\n",
    "        if F.st.v(time) == 'c':\n",
    "            next_word = p1 if F.pdp.v(p1) != 'art' else p2\n",
    "            next_verb = s1\n",
    "            features['construct'] = 1\n",
    "            if F.pdp.v(next_verb) == 'verb':   \n",
    "                features['cons+VC'] = 1\n",
    "            elif F.pdp.v(next_word):\n",
    "                features['cons+NP'] = 1\n",
    "                \n",
    "        # h.time.h.spec pattern\n",
    "        if F.lex.v(m1) == 'H' and F.lex.v(p1) == 'H':\n",
    "            features['attr_patt'] = 1\n",
    "            \n",
    "        # demonstrative / ordinal / qualquant / spec\n",
    "        is_dem = any([F.pdp.v(p1) == 'prde',\n",
    "                      F.lex.v(p1) == 'H' and F.pdp.v(p2) == 'prde'])\n",
    "        is_ordn = F.lex.v(p1) == 'H' and F.ls.v(p2) == 'ordn'\n",
    "        \n",
    "        is_spec = all([F.lex.v(m1) == 'H', \n",
    "                       F.lex.v(p1) == 'H',\n",
    "                       not F.lex.v(p1) == 'H' and isQualQuant(p2),\n",
    "                       not is_dem, not is_ordn, not is_qualq])\n",
    "        if is_dem:\n",
    "            features['demon'] = 1\n",
    "        elif is_ordn:\n",
    "            features['ord'] = 1\n",
    "        elif is_spec:\n",
    "            features['attrb'] = 1\n",
    "        \n",
    "        # attributives\n",
    "        small_sp = next(iter(sorted(L.u(time, 'subphrase'))), 0)\n",
    "        attr_relas = set(rel_sp for rel_sp in E.mother.t(small_sp) if F.rela.v(rel_sp) == 'atr')\n",
    "        \n",
    "        if attr_relas and  not {'demonstrative', 'ordinal', 'attribute', 'qualitative quant.'} & set(features.keys()):\n",
    "            features['adjv'] = 1    \n",
    "        \n",
    "    # tag relative/attributive specs dependent on phrase\n",
    "    if dep_cl:\n",
    "        rel = 'rela' if 'Rela' in set(F.function.v(ph) for ph in L.d(dep_cl, 'phrase')) else ''\n",
    "        clkind = F.kind.v(dep_cl)        \n",
    "        features[f'{rel}+{clkind}'] = 1        \n",
    "    \n",
    "    tag = '.'.join(features.keys())\n",
    "    result = (cx,) + L.d(cx, 'phrase') + tuple(times)\n",
    "    \n",
    "    return tag, result, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the search..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2result = collections.defaultdict(list)\n",
    "spec2result = collections.defaultdict(list)\n",
    "cx2tag = {}\n",
    "cx2preptags = {}\n",
    "specdata = {}\n",
    "\n",
    "for cx in testset:\n",
    "    tag, result, features = tagConstructionSpecs(cx)\n",
    "    specdata[result[0]] = features # store on first cx node\n",
    "    tag2result[tag].append(result)\n",
    "    cx2tag[cx] = tag\n",
    "    \n",
    "    # build tags with prepositions\n",
    "    phrase = L.d(cx, 'phrase')[0]\n",
    "    if F.typ.v(phrase) == 'PP':\n",
    "        prep = next(ch for ch in L.d(phrase, 'chunk') if F.label.v(ch) == 'prep')\n",
    "        prep_txt = ''.join(F.lex.v(w) for w in L.d(prep, 'word'))\n",
    "        prep_tag = tag.replace('PPtime', prep_txt+'+time')\n",
    "    else:\n",
    "        prep_tag = 'ø+'+tag\n",
    "    cx2preptags[cx] = prep_tag\n",
    "    \n",
    "    for spec in features:    \n",
    "        spec2result[spec].append(result)\n",
    "    \n",
    "specdata = pd.DataFrame(specdata).fillna(0)\n",
    "    \n",
    "print(specdata.shape[0], 'results logged...')\n",
    "print(len(tag2result.keys()), 'separate tags logged...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(specdata.shape)\n",
    "specdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(tag2result['NP'], condenseType='sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering with Fuzzy C-Means\n",
    "\n",
    "C-means is a fuzzy clustering method which allows us to model both strong tendencies and ambiguity in the data. As with K-means, C-means requires a certain number of clusters to be predetermined. In order to find the ideal number of clusters, we can iterate from 2 to N and measure the partition coefficient for each iteration. The coefficient tells how compact the cluster is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specdata.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_coefficients = [] # partition coefficients\n",
    "nclusters = [] # number of clusters\n",
    "\n",
    "# measure coefficients for n-clusters 2 to 30\n",
    "for i in range(2, 31): \n",
    "    cntr, u, u0, d, jm, p, fpc = cmeans(specdata.values, i, 2, error=0.005, maxiter=1000, seed=13)\n",
    "    part_coefficients.append(fpc)\n",
    "    nclusters.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the coefficient scores for each n-cluster. This helps us to see what the ideal number of clusters should be. We have to balance between \"lumping and splitting\" (as Croft calls it). With more clusters, we will inevitably have more consistency but with less usefulness. Thus we need to find the number of clusters that give the greatest consistency with the least amount of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "plt.plot(nclusters, part_coefficients)\n",
    "plt.xticks(nclusters)\n",
    "plt.axvline(18, color='red', linestyle='--')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Fuzzy Partition Coefficient')\n",
    "plt.savefig(firstyear+'cmeans_clustering.png', dpi=300, bbox_inchex='tight')\n",
    "plt.title(f'C-means Clustering Coefficients with Number of Clusters, from {nclusters[0]} to {nclusters[-1]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_clusters = 18\n",
    "\n",
    "cntr, u, u0, d, jm, p, fpc = cmeans(specdata.values, number_clusters, 2, error=0.005, maxiter=1000, seed=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Membership Coefficients within Clusters\n",
    "\n",
    "Since these are fuzzy clusters, all clusters contain **all** the constructions. Each construction has a corresponding score, which tells how close it is to the mean within the cluster. This score helps us to visualize membership ambiguities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examplematrix = []\n",
    "\n",
    "for i, cluster in enumerate(u):\n",
    "    clustdata = pd.DataFrame(cluster, index=specdata.columns).sort_values(by=0, ascending=False)\n",
    "    egcx = int(clustdata.index[0])\n",
    "    eg = surfaceToken(egcx)\n",
    "    size = clustdata[clustdata[0] > 0.9].shape[0]\n",
    "    \n",
    "    examplematrix.append([cx2tag[egcx], eg, size])\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    showdata = clustdata.values[:500]\n",
    "    plt.plot(np.arange(showdata.shape[0]), showdata)\n",
    "    plt.title(f'cluster {i}, {cx2tag[egcx]}, e.g. {reverse_hb(eg)}', size=16)\n",
    "    plt.ylabel('Membership Coefficient', size=14)\n",
    "    plt.xlabel('Constructions 1–N', size=14)\n",
    "    plt.xticks(size=12)\n",
    "    plt.yticks(size=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_examples = pd.DataFrame(examplematrix, columns=['Cluster Name', 'Example', 'Size']).set_index('Cluster Name')\n",
    "cluster_examples = cluster_examples.sort_values(by='Size', ascending=False)\n",
    "cluster_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_examples['Size'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_examples.to_excel(firstyear+'clusters.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Good Fits and Find Misfits\n",
    "\n",
    "Which constructions do not find themselves in an ideal cluster? First find the number of strong fits. All of these clusters have top scores far above the others. We can essentially describe an arbitrary cutoff point above ~0.2. We also store all of the cluster mappings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_fits = set()\n",
    "clust2cx = {}\n",
    "clust2mainlabel = {}\n",
    "cx2clust = {}\n",
    "clustermatrix = []\n",
    "\n",
    "clustmainlabel2cx = collections.defaultdict(list)\n",
    "\n",
    "\n",
    "for i, cluster in enumerate(u):\n",
    "    clustdata = pd.DataFrame(cluster, index=specdata.columns)\n",
    "    clustermatrix.append(clustdata[0].values)\n",
    "    good_fits = clustdata[clustdata[0] > 0.9]\n",
    "    mainlabel = cx2tag[clustdata.sort_values(ascending=False, by=0).index[0]]\n",
    "    clust2mainlabel[i] = mainlabel\n",
    "    \n",
    "    for cx in good_fits.index:\n",
    "        cx2clust[cx] = i\n",
    "        strong_fits.add(cx)\n",
    "        clustmainlabel2cx[mainlabel].append(cx)\n",
    "    clust2cx[i] = set(good_fits.index)\n",
    "    \n",
    "    \n",
    "label2clust = dict((label, clust) for clust, label in clust2mainlabel.items())\n",
    "clustermatrix = pd.DataFrame(np.array(clustermatrix).T, columns=np.arange(number_clusters), index=specdata.columns)\n",
    "\n",
    "print('number of time constructions', freq_times['Total'].sum())\n",
    "print('size of testset: ', len(testset))\n",
    "print('number of strong fits:', len(strong_fits), '({}'.format(len(strong_fits) / freq_times['Total'].sum()), 'of all time constructions)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Misfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misfits = testset - strong_fits\n",
    "\n",
    "print('number of misfits: ', len(misfits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, mf in enumerate(list(misfits)[:100]):\n",
    "    \n",
    "#     closest = clustermatrix.loc[mf].sort_values(ascending=False)\n",
    "#     clust, score = closest.index[0], closest.values[0]\n",
    "\n",
    "#     print(f'closest to: {clust2mainlabel[clust]} ({clust}) with score of {score}')\n",
    "    \n",
    "#     print(cx2tag[mf])\n",
    "#     A.prettyTuple(L.d(mf, 'phrase'), seq=i, condensed=False, extraFeatures='pdp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fact is readily explained in the constructional framework: a proto-typical adverb is placed into a noun construction and construed as such."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather Paper Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tag2result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cx = len(list(F.otype.s('construction')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of +VC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of +VC specs\n",
    "\n",
    "cons_VC = spec2result['cons+VC']\n",
    "rela_VC = spec2result['rela+VC']\n",
    "VC = spec2result['+VC']\n",
    "\n",
    "tota_vc = len(cons_VC) + len(rela_VC) + len(VC)\n",
    "\n",
    "tota_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tota_vc / len(list(F.otype.s('construction')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(spec2result['+VC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatPassages(cons_VC+rela_VC+VC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cases of Bare Plurals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(tag2result['time.pl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tag2result['time.pl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.sectionFromNode(1774787)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text(L.u(1774787,'verse')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatPassages(tag2result['time.pl'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time + cnstr + NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spec2result['cons+NP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spec2result['cons+NP']) / len(list(F.otype.s('construction')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(spec2result['cons+NP'])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.sectionFromNode(1774647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text(L.u(1774647, 'verse')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tag2result['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tag2result['PPtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tag2result['time']) + len(tag2result['PPtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(tag2result['time']) + len(tag2result['PPtime'])) / len(list(F.otype.s('construction')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.sectionFromNode(672200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text(L.u(672200, 'verse')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(spec2result['sffx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(spec2result['sffx'], condensed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.sectionFromNode(800626)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text(L.u(800626, 'verse')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spec2result['sffx']) / total_cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatPassages(spec2result['sffx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(tag2result['PPtime.pl.sffx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.sectionFromNode(654163 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text(L.u(654163, 'verse')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Demonstrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spec2result['demon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spec2result['demon']) / total_cx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definite Article Standalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tag2result['time.H'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tag2result['time.H']) / total_cx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Attributive Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spec2result['attr_patt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spec2result['attr_patt']) / total_cx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Attributed Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.show(tag2result['PPtime.attr_patt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[t for t in tag2result.keys() if 'attr_patt' in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.show(tag2result['time.H.pl.attr_patt.adjv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.sectionFromNode(870275)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text(L.u( 870275, 'verse')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.show(tag2result['time.H.attr_patt.adjv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ordinals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spec2result['ord'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spec2result['ord']) / total_cx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many cases of demonstrative ה are found in discourse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textype = collections.Counter()\n",
    "\n",
    "for res in tag2result['PPtime.H']+tag2result['time.H']:\n",
    "    cx = res[0]\n",
    "    clause = L.u(cx, 'clause')[0]\n",
    "    \n",
    "    txt = F.txt.v(clause)\n",
    "    txt = 'S' if {'Q', 'D'} & set(txt) else txt\n",
    "        \n",
    "    textype[txt] += 1\n",
    "    \n",
    "textype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 380\n",
    "n = 95 + 15 + 4 + 3\n",
    "\n",
    "d / (d+n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associations Between Prepositions and  Specifications\n",
    "\n",
    "I have a hypothesis that the ל preposition may be attracted to plural endings, and that the concept of duration or distance may be crucial for understanding the difference between ל and a marker such as ב, which tends to indicate points in time rather than spans. It it difficult to know whether there will be any statistically significant attractions, given that  ְל can occur with durative terms that do not need the plural to become a duration (especially prototypical adverbs such as עולם). Thus I may try this analysis in a couple of steps. The first will look at all of the data, adverbial words included. Then I want to see if any associations are brought out by looking only at terms which *regularly* accept nominal endings. This can be a bit tricky, since even עולם *can* take nominal endings, as we saw in the tagging study of `prep.time` patterns above: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.show(lex2tag2result['עולם']['plural'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preposition/øPreposition Associations Between Specifications\n",
    "\n",
    "We can utilize the data processed in `specdata`, which contains both construction node ID's and the tagged features. \n",
    "\n",
    "This data is used to construct a co-occurrence matrix of feature x preposition. Non prepositional phrases are marked with null (øprep)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build co-occurrence data\n",
    "\n",
    "specprep_counts = collections.defaultdict(lambda:collections.Counter())\n",
    "\n",
    "for cx in specdata.columns:\n",
    "    \n",
    "    phrase = L.d(cx, 'phrase')[0]\n",
    "    # get features but filter out PPtime and time since that's accounted for below\n",
    "    features = dict((spec, count) for spec, count in specdata[cx].to_dict().items()\n",
    "                       if spec not in {'PPtime', 'time'})\n",
    "    \n",
    "    # count tag and feature co-occurrences\n",
    "    if F.typ.v(phrase) == 'PP':\n",
    "        prep = E.head.t(phrase)[0]\n",
    "        specprep_counts[F.lex_utf8.v(prep)].update(features)\n",
    "    else:\n",
    "        specprep_counts['ø'].update(features)\n",
    "        \n",
    "specprep_counts = pd.DataFrame(specprep_counts)\n",
    "\n",
    "print(specprep_counts.shape)\n",
    "\n",
    "specprep_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specprep_counts.columns # target prepositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specprep_counts.index # co-occurring features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, convert co-occurrence counts to Fisher's exact associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specprep_assocs = apply_fishers(specprep_counts)\n",
    "\n",
    "specprep_assocs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show associations. **Any value greater than 1.3 is statistically associated,** since the p-values have been log10 transformed. **Any value less than -1.3 is significantly repelled.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prep in specprep_assocs:\n",
    "    assocs = specprep_assocs[prep].sort_values(ascending=False)\n",
    "    print(prep)\n",
    "    print(assocs)\n",
    "    print('\\n', '-'*20, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy of data to add reversed Hebrew script\n",
    "heatmap_specprep_assocs = specprep_assocs.copy()\n",
    "heatmap_specprep_assocs.columns = [reverse_hb(spec) for spec in specprep_assocs.columns]\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.heatmap(heatmap_specprep_assocs, center=0, robust=True)\n",
    "plt.xticks(size=25)\n",
    "plt.yticks(size=18)\n",
    "plt.savefig(firstyear+'spec_attractions.png', dpi=300, bbox_inches='tight')\n",
    "plt.title('Co-Spec Attractions (Fisher Exact)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Prepositions with PCA\n",
    "\n",
    "Plotting these prepositions with PCA can give a sense of how similar/dissimilar these prepositions are to one another, as well as inform us which factors most strogly influence their separation. We do that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(10)\n",
    "prep_fit = pca.fit(specprep_assocs.T.values)\n",
    "pca_preps = prep_fit.transform(specprep_assocs.T.values)\n",
    "\n",
    "preploadings = prep_fit.components_.T * np.sqrt(prep_fit.explained_variance_)\n",
    "preploadings = pd.DataFrame(preploadings.T, index=np.arange(10)+1, columns=specprep_assocs.index)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=np.arange(10)+1, y=prep_fit.explained_variance_ratio_[:10], color='darkblue')\n",
    "plt.xlabel('Principle Component', size=16)\n",
    "plt.ylabel('Raio of Explained Variance', size=16)\n",
    "plt.title('Ratio of Explained Variance for Principle Components 1-10 (Scree Plot)', size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_PCA(specprep_assocs, components=(pca_preps[:,0], pca_preps[:,1]), annoTags=[reverse_hb(token) for token in specprep_assocs.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the top influencing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter x & y\n",
    "x_filt = pd.DataFrame(pca_preps[:,0], index=specprep_assocs.columns)\n",
    "y_filt = pd.DataFrame(pca_preps[:,1], index=specprep_assocs.columns)\n",
    "x_filt = x_filt[specprep_counts.sum() > 100]\n",
    "y_filt = y_filt[specprep_counts.sum() > 100]\n",
    "\n",
    "# make simple x,y\n",
    "x, y = x_filt.values, y_filt.values\n",
    "\n",
    "influences = list(preploadings[:2].min().sort_values().head(4).index) + list(preploadings[:2].max().sort_values(ascending=False).head(4).index)\n",
    "\n",
    "# plot coordinates\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(x, y, color='black')\n",
    "plt.xlabel('PC1', size=18)\n",
    "plt.ylabel('PC2', size=18)\n",
    "plt.axhline(color='red', linestyle=':')\n",
    "plt.axvline(color='red', linestyle=':')\n",
    "\n",
    "# annotate prepositions \n",
    "prep_xy = {} # for noun_dict\n",
    "annoTags = x_filt.index\n",
    "for i, prep in enumerate(annoTags):\n",
    "    prep_x, prep_y = x[i], y[i]\n",
    "    prep_xy[annoTags[i]] = (prep_x, prep_y)\n",
    "    plt.annotate(reverse_hb(prep), xy=(prep_x, prep_y), size=26, fontname='Times New Roman')\n",
    "\n",
    "# annotate loadings \n",
    "for feat in preploadings:\n",
    "    if feat not in influences: # skip under-influencers\n",
    "        continue\n",
    "    x, y = preploadings[feat][:2]\n",
    "    plt.arrow(0, 0, x, y, color='green')\n",
    "    plt.annotate(feat, xy=(x*1.15, y*1.15), color='green', size=18)\n",
    "    \n",
    "plt.title('Prepositions (black) and the features (green) which influence their placements on PC1 and PC2; \\n(features found on time noun they govern)', size=18, pad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ל and בקר\n",
    "\n",
    "ל seems to be associated with plurality. But it also occurs with terms like בקר \"morning,\" which is a term that occurs 90+ times with ל's opposite: ב. Interestingly, the query below shows that 3 of 10 uses with בקר actually have \"morning\" in the plural! Could the singular uses represent a construal of a pointilliar time as a duration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.show(A.search('''\n",
    "\n",
    "# construction\n",
    "#     phrase\n",
    "#         =: word lex=L\n",
    "#         <: word lex=H\n",
    "#         <: word lex=BQR=/\n",
    "# '''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Associations Between Specifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specicollocations = collections.defaultdict(lambda: collections.Counter())\n",
    "\n",
    "for cx in specdata.columns:\n",
    "    \n",
    "    pos_values = specdata[cx][specdata[cx] > 0]\n",
    "    \n",
    "    for speci in pos_values.index:\n",
    "        for specj in pos_values.index:\n",
    "            if speci == specj:\n",
    "                continue\n",
    "            else:\n",
    "                specicollocations[speci][specj] += 1\n",
    "                \n",
    "specicollocations = pd.DataFrame(specicollocations).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specicollocations = specicollocations.reindex(sorted(specicollocations.index), axis=1) # reorder index by sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specicollocations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specicollocations_assoc = apply_fishers(specicollocations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change identical pairwise comparison scores to 0\n",
    "for speci in specicollocations_assoc.columns:\n",
    "    for specj in specicollocations_assoc.index:\n",
    "        if speci == specj:\n",
    "            specicollocations_assoc[speci][specj] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specicollocations_assoc = specicollocations_assoc.reindex(np.abs(specicollocations_assoc).mean().sort_values().index, axis=1) # reindex based on mean of absolute value on axis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.title('Co-Spec Attractions (Fisher Exact)')\n",
    "sns.heatmap(specicollocations_assoc, center=1.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specicollocations_assoc['pl'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring In-Clause Constituent Order\n",
    "\n",
    "Position from verb is represented as v+1 or v-1 etc.\n",
    "\n",
    "**NB: Account for WJHJ...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count total number of time constructions in verbal clauses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clause_kinds_raw = collections.Counter()\n",
    "\n",
    "for cx in F.otype.s('construction'):\n",
    "    clause = L.u(cx, 'clause')[0]\n",
    "    clause_kinds_raw[F.kind.v(clause)] += 1\n",
    "    \n",
    "convert2pandas(clause_kinds_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clause_kinds = collections.Counter()\n",
    "timeorders = collections.Counter()\n",
    "pos2res = collections.defaultdict(list)\n",
    "order2res = collections.defaultdict(list)\n",
    "order2tense2res = collections.defaultdict(lambda: collections.defaultdict(list))\n",
    "orderbytense = collections.defaultdict(lambda: collections.Counter())\n",
    "posbytense = collections.defaultdict(lambda: collections.Counter())\n",
    "wayehi_cases = []\n",
    "\n",
    "\n",
    "for cx in testset:\n",
    "    clause = L.u(cx, 'clause')[0]\n",
    "    cl_kind = F.kind.v(clause)\n",
    "    clause_kinds[cl_kind] += 1\n",
    "    \n",
    "    if cl_kind != 'VC':\n",
    "        continue\n",
    "        \n",
    "    time = next(ph for ph in L.d(clause, 'phrase') if F.function.v(ph) == 'Time')\n",
    "\n",
    "    # get the clause's primary predicate\n",
    "    if F.typ.v(clause) in {'Ptcp'}:\n",
    "        pred = next(ph for ph in L.d(clause, 'phrase') if F.function.v(ph) in {'PtcO', 'PreC'})\n",
    "    else:\n",
    "        pred = next(ph for ph in L.d(clause, 'phrase') if F.function.v(ph) in {'Pred', 'PreS', 'PreO'})\n",
    "\n",
    "    # check for ויהי\n",
    "    # get next clause if so\n",
    "    order = None\n",
    "    verb = next(w for w in L.d(pred, 'word') if F.pdp.v(w) == 'verb')\n",
    "    vt, lex, ps, gn, nu = filter_tense(verb), F.lex.v(verb), F.ps.v(verb), F.gn.v(verb), F.nu.v(verb)\n",
    "    if all([vt in {'wayq', 'perf', 'weqt'}, lex == 'HJH[', ps == 'p3', gn == 'm', nu == 'sg']):\n",
    "        try:\n",
    "            clause_atom = L.d(clause, 'clause_atom')[0]\n",
    "            next_clause = E.mother.t(clause_atom)[0]\n",
    "            wayehi_cases.append([clause, L.d(cx, 'phrase')[0]])\n",
    "            pred = next(ph for ph in L.d(clause, 'phrase') if F.function.v(ph) in {'Pred', 'PreS', 'PreO'})\n",
    "            verb = next(w for w in L.d(pred, 'word') if F.pdp.v(w) == 'verb')        \n",
    "            order = '-c'\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    tense = filter_tense(verb)\n",
    "    order = order or time-pred\n",
    "    sign = '+' if type(order)==int and order > 0 else ''\n",
    "    order_txt = f'{sign}{order}'\n",
    "    timeorders[order_txt] += 1\n",
    "    order2res[order_txt].append((cx, clause, time, pred))\n",
    "    timepos = 'fronted' if order == '-c' or order < 0 else 'postverbal'\n",
    "\n",
    "    pos2res[timepos].append((cx, clause, time, pred))\n",
    "    orderbytense[order_txt][vt] += 1\n",
    "    posbytense[timepos][vt] += 1\n",
    "    order2tense2res[order_txt][vt].append((cx, clause, time, pred))\n",
    "\n",
    "clause_kinds = convert2pandas(clause_kinds)\n",
    "timeorders = convert2pandas(timeorders)\n",
    "orderbytense = pd.DataFrame(orderbytense).fillna(0)\n",
    "posbytense = pd.DataFrame(posbytense).fillna(0)\n",
    "\n",
    "clause_kinds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wayehi_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeorders.to_excel(firstyear+'time_orders.xlsx')\n",
    "display(timeorders.head(10))\n",
    "countBarplot(timeorders, size=(10, 6), xlabel='Number of Constituents Away from Verb', save=firstyear+'timeposition.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a simpler distinction: pre-verbal or post-verbal..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_count = dict((pos, len(pos2res[pos])) for pos in pos2res)\n",
    "pos_count = convert2pandas(pos_count)\n",
    "pos_count['%'] = (pos_count / pos_count.sum()).round(2) * 100\n",
    "pos_count.to_excel(firstyear+'pos_count.xlsx')\n",
    "pos_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeorders.loc[['+2', '-1', '+1', '-2']].sum() / pos_count['Total'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(order2res[2], end=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Order/Tense Associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posbytense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbt_assoc = apply_fishers(posbytense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pbt_assoc = pbt_assoc.sort_values(by='fronted')\n",
    "\n",
    "plt.figure(figsize=(4, 8))\n",
    "sns.heatmap(show_pbt_assoc, center=0)\n",
    "plt.yticks(size=20, rotation='horizontal')\n",
    "plt.xticks(size=20)\n",
    "plt.savefig(firstyear+'heatmap_timePOS.png', dpi=300, bbox_inches='tight')\n",
    "plt.title('Time Adverbial Positions and Tenses (Fisher Exact)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcounts = posbytense[['postverbal', 'fronted']].sort_values(by='postverbal', ascending=False)\n",
    "pcounts.to_excel(firstyear+'time_position.xlsx')\n",
    "pcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verb Collocations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method\n",
    "\n",
    "This part of the analysis will seek to examine verb collocations against 3 reference points amongst time adverbials: direction, quantity, distance:\n",
    "\n",
    "* direction - a preposition lexeme\n",
    "* quantity - singular or plural (derived from pl, du, card, quant, qual)\n",
    "* distance\n",
    "    * near - e.g. ה, זה\n",
    "    * far - e.g. היא, הוא\n",
    "    \n",
    "The end result will be a 3 part tag, with 9 possible combinations, e.g. **B.sg.near, L.pl.far**.\n",
    "\n",
    "In order to build this data, we have to use a modified tagger function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demon_maps = {'Z>T': 'near',\n",
    "              'HJ>': 'far',\n",
    "              'HMH': 'far',\n",
    "              '>LH': 'near',\n",
    "              'HM': 'far',\n",
    "              'HW>': 'far',\n",
    "              'ZH': 'near'}\n",
    "\n",
    "cx2dqd = collections.defaultdict(set)\n",
    "dqd2res = collections.defaultdict(list)\n",
    "\n",
    "for cx in specdata.columns:\n",
    "    features = specdata[cx]\n",
    "    phrase = L.d(cx, 'phrase')[0]\n",
    "    \n",
    "    # -- TAG DIRECTION --\n",
    "    if F.typ.v(phrase) == 'PP':\n",
    "        prep = next(w for w in L.d(phrase, 'word') if F.pdp.v(w)=='prep')\n",
    "        direct = F.lex.v(prep)\n",
    "    else:\n",
    "        direct = 'ø'\n",
    "        \n",
    "    # -- TAG DISTANCE --\n",
    "    # for standalone H demonstrative tests\n",
    "    standalone = not any([features['demon'], features['attr_patt'],  # ensure no other modifiers\n",
    "                          features['quant'], features['PPtime']])\n",
    "    # check demonstratives\n",
    "    if features['demon']:\n",
    "        demon = next(w for w in L.d(cx, 'word') if F.pdp.v(w) in {'prde'})\n",
    "        \n",
    "        dist = demon_maps[F.lex.v(demon)]\n",
    "    # check for demonstrative H\n",
    "    elif features['H'] and standalone:\n",
    "        dist = 'near'\n",
    "        \n",
    "    else:\n",
    "        dist = 'ø'\n",
    "        \n",
    "    # -- TAG QUANTITY -- \n",
    "    plurals = any([features['quant'], features['pl'], features['du'], features['qual']])\n",
    "    if plurals:\n",
    "        quant = 'pl'\n",
    "    else:\n",
    "        quant = 'sg'\n",
    "        \n",
    "    # configure time for adverbs\n",
    "    is_advb = not set(features[features>0].index) - {'time', 'PPtime'} # make sure nothing else is present\n",
    "    head = 'time' if not is_advb else F.lex.v(E.nhead.t(phrase)[0])\n",
    "        \n",
    "    # Direction, quantity, distance tag\n",
    "    dqd = f'{direct}.{head}.{quant}.{dist}'\n",
    "    cx2dqd[cx] = dqd\n",
    "    dqd2res[dqd].append((cx, phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqd2res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqdbyevent = collections.defaultdict(lambda: collections.Counter())\n",
    "dqdbytense = collections.defaultdict(lambda: collections.Counter())\n",
    "dqd2event2res = collections.defaultdict(lambda: collections.defaultdict(list))\n",
    "event2res = collections.defaultdict(list)\n",
    "dqd2tense2res = collections.defaultdict(lambda: collections.defaultdict(list))\n",
    "wayehi_cases = []\n",
    "wayehi_exceptions = []\n",
    "\n",
    "for cx in testset:\n",
    "        tag = cx2dqd[cx]\n",
    "        clause = L.u(cx, 'clause')[0]\n",
    "        \n",
    "        if F.kind.v(clause) != 'VC': # skip non-verbal clauses\n",
    "            continue\n",
    "            \n",
    "        # get the clause's primary predicate\n",
    "        if F.typ.v(clause) in {'Ptcp'}:\n",
    "            pred = next(ph for ph in L.d(clause, 'phrase') if F.function.v(ph) in {'PtcO', 'PreC'})\n",
    "        else:\n",
    "            pred = next(ph for ph in L.d(clause, 'phrase') if F.function.v(ph) in {'Pred', 'PreS', 'PreO'})\n",
    "            \n",
    "        # check for ויהי\n",
    "        # get next clause if so\n",
    "        verb = next(w for w in L.d(pred, 'word') if F.pdp.v(w) == 'verb')\n",
    "        vt, lex, ps, gn, nu = F.vt.v(verb), F.lex.v(verb), F.ps.v(verb), F.gn.v(verb), F.nu.v(verb)\n",
    "        if all([vt in {'wayq', 'perf'}, lex == 'HJH[', ps == 'p3', gn == 'm', nu == 'sg']):\n",
    "            try:\n",
    "                clause_atom = L.d(clause, 'clause_atom')[0]\n",
    "                next_clause = E.mother.t(clause_atom)[0]\n",
    "                wayehi_cases.append([clause, L.d(cx, 'phrase')[0], next_clause])\n",
    "                clause = L.u(next_clause, 'clause')[0]\n",
    "                pred = next(ph for ph in L.d(clause, 'phrase') if F.function.v(ph) in {'Pred', 'PreS', 'PreO'})\n",
    "                verb = next(w for w in L.d(pred, 'word') if F.pdp.v(w) == 'verb')\n",
    "            except:\n",
    "                wayehi_exceptions.append([L.d(cx, 'phrase')[0], next_clause])\n",
    "                continue # skip them\n",
    "            \n",
    "            \n",
    "        # check for obj/cmpl arguments\n",
    "        obj_cmpl = set(ph for ph in L.d(clause,'phrase') if F.function.v(ph) in {'Objc', 'Cmpl'})\n",
    "        sffx_obj = F.function.v(pred) in {'PtcO', 'PreO'}\n",
    "        oc_check = '+obj/cmp' if any([obj_cmpl, sffx_obj]) else ''\n",
    "        \n",
    "        # tokenize the predicate\n",
    "        vs, lex, vt = F.vs.v(verb), F.lex.v(verb), filter_tense(verb)\n",
    "        verb_token = f'{lex}.{vs}'\n",
    "        \n",
    "        # count co-occurrence\n",
    "        result = (cx, clause, L.d(cx, 'phrase')[0],  verb)\n",
    "        dqdbyevent[tag][verb_token] += 1\n",
    "        dqdbytense[tag][vt] += 1\n",
    "        dqd2event2res[tag][verb_token].append(result)\n",
    "        dqd2tense2res[tag][vt].append(result)\n",
    "        event2res[verb_token].append(result)\n",
    "        \n",
    "dqdbyevent = pd.DataFrame(dqdbyevent).fillna(0)\n",
    "dqdbytense = pd.DataFrame(dqdbytense).fillna(0)\n",
    "\n",
    "print(dqdbyevent.shape)\n",
    "print(len(wayehi_cases), 'wayehi cases handled...')\n",
    "print(len(wayehi_exceptions), 'wayehi exceptions ignored...')\n",
    "\n",
    "dqdbyevent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqdbyevent.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at Raw Associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqdbyevent2 = dqdbyevent.drop('VM>[.qal') # remove outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbe_assoc = apply_fishers(dqdbyevent2)\n",
    "dbe_assoc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbe_assoc.max().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbe_assoc.min().sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_strongest = dbe_assoc.max().sort_values(ascending=False).head(10).index\n",
    "compare = dbe_assoc[top_strongest].sort_values(by='ø.time.pl.ø', ascending=False)\n",
    "\n",
    "#compare = compare.reindex(compare.T.quantile(0.25).sort_values().index).head(20) # get the most polarizing adverbials\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Time Adverbial and Tense Attractions (Fisher Exact)')\n",
    "sns.heatmap(compare, center=0)\n",
    "plt.yticks(size=10)\n",
    "plt.xticks(size=20, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(10)\n",
    "dqd_fit = pca.fit(dbe_assoc.T.values)\n",
    "pca_dqd = dqd_fit.transform(dbe_assoc.T.values)\n",
    "\n",
    "dqdloadings = dqd_fit.components_.T * np.sqrt(dqd_fit.explained_variance_)\n",
    "dqdloadings = pd.DataFrame(dqdloadings.T, index=np.arange(10)+1, columns=dbe_assoc.index)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=np.arange(10)+1, y=dqd_fit.explained_variance_ratio_[:10], color='darkblue')\n",
    "plt.xlabel('Principle Component', size=16)\n",
    "plt.ylabel('Raio of Explained Variance', size=16)\n",
    "plt.title('Ratio of Explained Variance for Principle Components 1-10 (Scree Plot)', size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PCA(pca_nouns, \n",
    "             zoom=tuple(), \n",
    "             noun_xy_dict=False, \n",
    "             save='', \n",
    "             annotate=True, \n",
    "             title='', \n",
    "             components=tuple(),\n",
    "             annoTags=[],\n",
    "             anno_size='18'\n",
    "            ):\n",
    "    '''\n",
    "    Plots a PCA noun space.\n",
    "    Function is useful for presenting various zooms on the data.\n",
    "    '''\n",
    "    \n",
    "    x, y = components\n",
    "    \n",
    "    # plot coordinates\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(x, y, s=50)\n",
    "\n",
    "    if zoom:\n",
    "        xmin, xmax, ymin, ymax = zoom\n",
    "        plt.xlim(xmin, xmax)\n",
    "        plt.ylim(ymin, ymax)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title, size=18)\n",
    "    plt.xlabel('PC1', size=18)\n",
    "    plt.ylabel('PC2', size=18)\n",
    "    plt.axhline(color='red', linestyle=':')\n",
    "    plt.axvline(color='red', linestyle=':')\n",
    "    \n",
    "    # annotate points\n",
    "    if annotate:\n",
    "        noun_xy = {} # for noun_dict\n",
    "        noun_lexs = annoTags\n",
    "        \n",
    "        for i, noun in enumerate(noun_lexs):\n",
    "            noun_x, noun_y = x[i], y[i]\n",
    "            noun_xy[annoTags[i]] = (noun_x, noun_y)\n",
    "            if zoom: # to avoid annotating outside of field of view (makes plot small)\n",
    "                if any([noun_x < xmin, noun_x > xmax, noun_y < ymin, noun_y > ymax]):                \n",
    "                    continue # skip noun\n",
    "            plt.annotate(noun, xy=(noun_x, noun_y), size=anno_size)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(save, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    if noun_xy_dict:\n",
    "        return noun_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_PCA(dbe_assoc, components=(pca_dqd[:,0], pca_dqd[:,1]), annoTags=dbe_assoc.columns, anno_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_PCA(dbe_assoc, zoom=(-5, 5, -5, 5), components=(pca_dqd[:,0], pca_dqd[:,1]), annoTags=dbe_assoc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_PCA(dbe_assoc, zoom=(-0.6, 0.5, -1, 0.5), components=(pca_dqd[:,0], pca_dqd[:,1]), annoTags=dbe_assoc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# influences = list(dqdloadings[:2].min().sort_values().head(5).index) + list(dqdloadings[:2].max().sort_values(ascending=False).head(5).index)\n",
    "\n",
    "# x, y = (pca_dqd[:,0], pca_dqd[:,1])\n",
    "\n",
    "# # plot coordinates\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# plt.scatter(x, y, color='black')\n",
    "# plt.xlabel('PC1', size=18)\n",
    "# plt.ylabel('PC2', size=18)\n",
    "# plt.axhline(color='red', linestyle=':')\n",
    "# plt.axvline(color='red', linestyle=':')\n",
    "\n",
    "# zoom = (-10, 10, -7, 7)\n",
    "# plt.xlim(zoom[0], zoom[1])\n",
    "# plt.ylim(zoom[2], zoom[3])\n",
    "\n",
    "\n",
    "# #plt.savefig('plots/duration/conj_PCA_biplot.png', dpi=300)\n",
    "    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dqd():\n",
    "    x, y = pd.DataFrame(pca_dqd[:,0], index=dqdbyevent.columns), pd.DataFrame(pca_dqd[:,1], index=dqdbyevent.columns)\n",
    "    xy = pd.concat([x, y], 1)\n",
    "    xy.columns = ['x', 'y']\n",
    "\n",
    "    axy = xy[xy.index.str.contains('pl') & xy.index.str.startswith('ø')] # red, ø+pl\n",
    "    bxy = xy[xy.index.str.startswith('ø') & xy.index.str.contains('sg')] # +ø+sg\n",
    "    cxy = xy.loc[[i for i in xy.index if i not in set(axy.index)|set(bxy.index)]] # +prep\n",
    "\n",
    "    # plot coordinates\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    ax1 = plt.scatter(axy['x'], axy['y'], s=dqdbyevent.sum()[axy.index], color='red')\n",
    "    ax2 = plt.scatter(cxy['x'], cxy['y'], s=dqdbyevent.sum()[cxy.index], color='blue')\n",
    "    ax3 = plt.scatter(bxy['x'], bxy['y'], s=dqdbyevent.sum()[bxy.index], color='black', alpha=0.5)\n",
    "    \n",
    "    plt.legend(['øprep + pl', 'prep + sg/pl', 'øprep + sg'], loc='upper right', fontsize=18)\n",
    "\n",
    "    plt.axhline(color='black', linewidth=0.6)\n",
    "    plt.axvline(color='black', linewidth=0.6)\n",
    "    \n",
    "    plt.axis('scaled')\n",
    "    \n",
    "    zoom=False\n",
    "    if zoom:\n",
    "        xmin, xmax, ymin, ymax = zoom\n",
    "        plt.xlim(xmin, xmax)\n",
    "        plt.ylim(ymin, ymax)\n",
    "\n",
    "    title = ''\n",
    "    if title:\n",
    "        plt.title(title, size=18)\n",
    "    plt.xlabel('PC1', size=18)\n",
    "    plt.ylabel('PC2', size=18)\n",
    "    \n",
    "# for lex in dqdloadings:\n",
    "    \n",
    "#     if lex not in influences:\n",
    "#         continue\n",
    "    \n",
    "#     x, y = dqdloadings[lex][:2]\n",
    "#     plt.arrow(0, 0, x, y, color='green')\n",
    "    \n",
    "#     # handle zooms\n",
    "#     if any([x < zoom[0], x > zoom[1], y < zoom[2], y > zoom[3]]):                \n",
    "#         continue\n",
    "        \n",
    "#     plt.annotate(lex, xy=(x*1.15, y*1.15), color = 'green', size=10)\n",
    "    \n",
    "    plt.savefig(firstyear+'aspect_pca.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "show_dqd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dqdloadings.loc[1].sort_values(ascending=False).head(30)).to_excel(firstyear+'durative_loadings.xlsx')\n",
    "dqdloadings.loc[1].sort_values(ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqdloadings.loc[1].sort_values().head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprising Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Durative of Intent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.show(event2res['SGR[.hif'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.sectionFromNode(686186)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text(L.u(686186, 'verse')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.show(dqd2event2res['ø.time.pl.ø']['>KL[.qal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.sectionFromNode(652380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text(L.u(652380, 'verse')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Statistically Insignificant Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surprises = collections.defaultdict(lambda:collections.defaultdict(list))\n",
    "\n",
    "# for clust, events in clust2event2res.items():\n",
    "#     for event in events:\n",
    "        \n",
    "#         results = clust2event2res[clust][event]\n",
    "#         # check association score\n",
    "#         assoc = cbe_assoc[clust][event]\n",
    "#         if assoc < 0:\n",
    "#             surprises[clust][event].extend(results)\n",
    "            \n",
    "# len(surprises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in surprises:\n",
    "#     print(key, '\\t', len(surprises[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for clust, events in surprises.items():\n",
    "#     for event in events:\n",
    "#         print(f'cluster: {clust}')\n",
    "#         print(f'event: {event}')\n",
    "#         print(f'assoc: {cbe_assoc[clust][event]}')\n",
    "#         A.show(surprises[clust][event])\n",
    "#         print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbe_assoc.loc['BW>[.qal+obj/cmp'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dqdbyevent.loc['בוא.qal+obj/cmp'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.show(clust2event2res['time.pl.quant.card']['בוא.qal+obj/cmp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cbe_assoc.loc['אמר.qal'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.show(clust2event2res['PPtime.pl']['אמר.qal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.show(clust2event2res['PPtime.H.pl.attr_patt.demon']['אמר.qal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Durative & Verb Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cbe_assoc[duratives].max(1).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusterbyevent[duratives].sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tense Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqdbytense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples for Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatPassages(dqd2tense2res['ø.time.sg.near']['ptca'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbt_assoc = apply_fishers(dqdbytense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at Raw Associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbt_assoc.max().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbt_assoc.min().sort_values().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(9)\n",
    "cbt_fit = pca.fit(cbt_assoc.T.values)\n",
    "pca_cbt = cbt_fit.transform(cbt_assoc.T.values)\n",
    "\n",
    "cbtloadings = cbt_fit.components_.T * np.sqrt(cbt_fit.explained_variance_)\n",
    "cbtloadings = pd.DataFrame(cbtloadings.T, index=np.arange(9)+1, columns=cbt_assoc.index)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=np.arange(9)+1, y=cbt_fit.explained_variance_ratio_[:9], color='darkblue')\n",
    "plt.xlabel('Principle Component', size=16)\n",
    "plt.ylabel('Raio of Explained Variance', size=16)\n",
    "plt.title('Ratio of Explained Variance for Principle Components 1-9 (Scree Plot)', size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_PCA(cbt_assoc,  components=(pca_cbt[:,0], pca_cbt[:,1]), annoTags=cbt_assoc.columns, anno_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = (pca_cbt[:,0], pca_cbt[:,1])\n",
    "\n",
    "# plot coordinates\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(x, y, color='black')\n",
    "plt.xlabel('PC1', size=18)\n",
    "plt.ylabel('PC2', size=18)\n",
    "plt.axhline(color='red', linestyle=':')\n",
    "plt.axvline(color='red', linestyle=':')\n",
    "\n",
    "for verbconj in ('wayq', 'ptca', 'impf'):\n",
    "    x, y = cbtloadings[verbconj][:2]\n",
    "    plt.arrow(0, 0, x, y, color='green')\n",
    "    plt.annotate(verbconj, xy=(x*1.15, y*1.15), color = 'green', size=20)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Contribution of Prepositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_cbt(zoom=None):\n",
    "\n",
    "#     x, y = pd.DataFrame(pca_cbt[:,0], index=dqdbyevent.columns), pd.DataFrame(pca_cbt[:,1], index=dqdbytense.columns)\n",
    "#     xy = pd.concat([x, y],1)\n",
    "#     xy.columns = ['x', 'y']\n",
    "\n",
    "# #     axy = xy[xy.index.str.contains('sg')]\n",
    "# #     bxy = xy[xy.index.str.contains('pl')]\n",
    "# #     cxy = xy.loc[[i for i in xy.index if i not in set(axy.index)|set(bxy.index)]]\n",
    "\n",
    "#     axy = xy[xy.index.str.startswith('MN')] # blue\n",
    "#     bxy = pd.concat([xy[xy.index.str.startswith('<D')], xy[xy.index.str.startswith('L')]]) # red\n",
    "#     dxy = xy.loc[[i for i in xy.index if i not in set(axy.index)|set(bxy.index)]] # grey\n",
    "\n",
    "#     # plot coordinates\n",
    "#     plt.figure(figsize=(12, 10))\n",
    "#     plt.scatter(axy['x'], axy['y'], s=dqdbyevent.sum()[axy.index], color='blue')\n",
    "#     plt.scatter(bxy['x'], bxy['y'], s=dqdbyevent.sum()[bxy.index], color='red')\n",
    "#     plt.scatter(dxy['x'], dxy['y'], s=dqdbyevent.sum()[dxy.index], color='grey', alpha=0.5)\n",
    "\n",
    "# #     mn = 'ןמ'\n",
    "# #     lad = 'ל & דע'\n",
    "# #     plt.legend([mn, lad], loc='lower left', fontsize=25)\n",
    "    \n",
    "#     if zoom:\n",
    "#         xmin, xmax, ymin, ymax = zoom\n",
    "#         plt.xlim(xmin, xmax)\n",
    "#         plt.ylim(ymin, ymax)\n",
    "\n",
    "#     title = ''\n",
    "#     if title:\n",
    "#         plt.title(title, size=18)\n",
    "#     plt.xlabel('PC1', size=18)\n",
    "#     plt.ylabel('PC2', size=18)\n",
    "    \n",
    "#     plt.axhline(color='red', linestyle=':')\n",
    "#     plt.axvline(color='red', linestyle=':')\n",
    "\n",
    "#     annotate = False\n",
    "#     # annotate points\n",
    "#     if annotate:\n",
    "#         noun_xy = {} # for noun_dict\n",
    "#         noun_lexs = annoTags\n",
    "\n",
    "#         for i, noun in enumerate(noun_lexs):\n",
    "#             noun_x, noun_y = x[i], y[i]\n",
    "#             noun_xy[annoTags[i]] = (noun_x, noun_y)\n",
    "#             if zoom: # to avoid annotating outside of field of view (makes plot small)\n",
    "#                 if any([noun_x < xmin, noun_x > xmax, noun_y < ymin, noun_y > ymax]):                \n",
    "#                     continue # skip noun\n",
    "#             plt.annotate(noun, xy=(noun_x, noun_y), size=anno_size)\n",
    "            \n",
    "#     for verbconj in ('ptca', 'wayq', 'impf', 'perf'):\n",
    "#         x, y = cbtloadings[verbconj][:2]\n",
    "#         plt.arrow(0, 0, x, y, color='green')\n",
    "#         plt.annotate(verbconj, xy=(x*1.15, y*1.15), color = 'green', size=16)\n",
    "            \n",
    "# #    plt.title('Opposition of ל & דע over against ןמ, based on their verb collocation preferences')\n",
    "            \n",
    "#     plt.show()\n",
    "\n",
    "# show_cbt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at Loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbtloadings.loc[1].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(clust2tense2res['time.H']['ptca'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(clust2tense2res['time.pl.quant.card']['wayq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = cbt_assoc.T\n",
    "compare = compare.reindex(compare.T.quantile(0.25).sort_values().index).head(20) # get the most polarizing adverbials\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(compare, center=0)\n",
    "plt.yticks(size=14)\n",
    "plt.xticks(size=20, rotation='vertical')\n",
    "plt.savefig(firstyear+'heatmap_tenses.png', dpi=300, bbox_inches='tight')\n",
    "plt.title('Time Adverbial and Tense Attractions (Fisher Exact)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = cbt_assoc.loc[['wayq', 'impf']].T.sort_values(by='wayq', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(5, 6))\n",
    "sns.heatmap(compare, center=0)\n",
    "plt.yticks(size=15)\n",
    "plt.savefig(firstyear+'heatmap_wayq_yiqt.png', dpi=300, bbox_inches='tight')\n",
    "plt.title('Time Adverbial and Tense Attractions (Fisher Exact)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = cbt_assoc.loc[['wayq', 'impf']].T.sort_values(by='impf', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(5, 6))\n",
    "sns.heatmap(compare, center=0)\n",
    "plt.yticks(size=15)\n",
    "plt.savefig(firstyear+'heatmap_yqtl_wyqt.png', dpi=300, bbox_inches='tight')\n",
    "plt.title('Time Adverbial and Tense Attractions (Fisher Exact)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = cbt_assoc.loc[['wayq', 'ptca']].T.sort_values(by='ptca', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(5, 6))\n",
    "plt.title('Time Adverbial and Tense Attractions (Fisher Exact)')\n",
    "sns.heatmap(compare, center=1.3)\n",
    "plt.yticks(size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = cbt_assoc.loc[['wayq']].T.sort_values(by='wayq', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(4, 6))\n",
    "plt.title('Time Adverbial and Tense Attractions (Fisher Exact)')\n",
    "sns.heatmap(compare, center=1.3, robust=True)\n",
    "plt.yticks(size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

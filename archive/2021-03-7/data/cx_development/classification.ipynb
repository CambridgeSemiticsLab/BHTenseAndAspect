{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying timephrases\n",
    "\n",
    "This notebook will seek to establish a taxonomy of time phrases in Biblical Hebrew that is as comprehensive as possible. The `Construction` object is used as the starting point for the analysis. We already have a set of `Construction` objects (henceforth simply \"cx\") that have been preprocessed based on their subphrase grammar. These subphrases allow us to make certain selections of the data and place labels on the time phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.9.0\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "120 features found and 4 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s No structure info in otext, the structure part of the T-API cannot be used\n",
      "  5.21s All features loaded/computed - for details use loadLog()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src:\n",
       "    local(\"SILEOT.ttf\"),\n",
       "    url(\"https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.woff?raw=true\");\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0a6611;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    direction: ltr;\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -0.1rem 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: x-small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 0.1em 0em;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-style: italic;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".ltr {\n",
       "    direction: ltr ! important;\n",
       "}\n",
       ".verse {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".vl {\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-end;\n",
       "    align-items: flex-end;\n",
       "    direction: ltr;\n",
       "    width: 100%;\n",
       "}\n",
       ".outeritem {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".sentence,.clause,.phrase {\n",
       "    margin-top: -1.2em;\n",
       "    margin-left: 1em;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 0.3em;\n",
       "    border-style: solid;\n",
       "    border-radius: 0.2em;\n",
       "    font-size: small;\n",
       "    display: block;\n",
       "    width: fit-content;\n",
       "    max-width: fit-content;\n",
       "    direction: ltr;\n",
       "}\n",
       ".atoms {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".satom,.catom,.patom {\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    border-radius: 0.3em;\n",
       "    border-style: solid;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".sentence {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".clause {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".phrase {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".satom {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 4px;\n",
       "}\n",
       ".catom {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".patom {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".word {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 1px solid #cccccc;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".lextp {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 2px solid #888888;\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".occs {\n",
       "    font-size: x-small;\n",
       "}\n",
       ".satom.l,.catom.l,.patom.l {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".satom.r,.catom.r,.patom.r {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".satom.lno,.catom.lno,.patom.lno {\n",
       "    border-left-style: none\n",
       "}\n",
       ".satom.rno,.catom.rno,.patom.rno {\n",
       "    border-right-style: none\n",
       "}\n",
       ".tr,.tr a:visited,.tr a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".trb,.trb a:visited,.trb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: normal;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".prb,.prb a:visited,.prb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".h,.h a:visited,.h a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".hb,.hb a:visited,.hb a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    line-height: 2;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".vn {\n",
       "  font-size: small !important;\n",
       "  padding-right: 1em;\n",
       "}\n",
       ".rela,.function,.typ {\n",
       "    font-family: monospace;\n",
       "    font-size: small;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".pdp,.pdp a:visited,.pdp a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".voc_lex {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vs {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vt {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".gloss {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #444444;\n",
       "}\n",
       ".vrs {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: #444444;\n",
       "}\n",
       ".nd {\n",
       "    font-family: monospace;\n",
       "    font-size: x-small;\n",
       "    color: #999999;\n",
       "}\n",
       ".hl {\n",
       "    background-color: #ffee66;\n",
       "}\n",
       "\n",
       "tr.tf, td.tf, th.tf {\n",
       "  text-align: left;\n",
       "}\n",
       "\n",
       "span.hldot {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder: 0.2rem solid var(--hl-rim);\n",
       "\tborder-radius: 0.4rem;\n",
       "\t/*\n",
       "\tdisplay: inline-block;\n",
       "\twidth: 0.8rem;\n",
       "\theight: 0.8rem;\n",
       "\t*/\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "\n",
       "span.hlup {\n",
       "\tborder-color: var(--hl-dark);\n",
       "\tborder-width: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 0.2rem;\n",
       "  padding: 0.2rem;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55, 100%,  60%, 0.9  );\n",
       "\t--hl-dark:          hsla( 55, 100%,  40%, 0.9  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import collections\n",
    "import pickle\n",
    "import copy\n",
    "import random\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from helpers import barplot_counts, convert2pandas\n",
    "from tf_tools.load import load_tf\n",
    "from tf_tools.tokenizers import tokenize_surface\n",
    "from cx_analysis.cx import Construction\n",
    "from cx_analysis.build import CXbuilder\n",
    "from cx_analysis.search import SearchCX\n",
    "from positions import Positions\n",
    "from paths import cxs as cx_data\n",
    "from paths import semvector\n",
    "\n",
    "TF, api, A = load_tf()\n",
    "F, E, T, L = api.F, api.E, api.T, api.L\n",
    "\n",
    "with open(cx_data, 'rb') as infile:\n",
    "    cx_load = pickle.load(infile)\n",
    "    phrase2cxs = cx_load['phrase2cxs']\n",
    "    \n",
    "with open(semvector, 'rb') as infile:\n",
    "    semdists = pickle.load(infile)\n",
    "    \n",
    "se = SearchCX(A)\n",
    "A.displaySetup(condenseType='phrase', withNodes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "The current cx dataset excludes time phrases that have gaps inside. These will be analyzed at a later stage due to their complexity. Let's get a sense for how many there are and what is included in the analysis set. The `timephrase` object is a custom object built from the ETCBC phrase object. It makes several corrections as well as fusions of the time phrases. The `timephrase` object is what the Construction classes are built upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s 3879 results\n"
     ]
    }
   ],
   "source": [
    "all_times = A.search('timephrase', shallow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_times = set(phrase2cxs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 times not analyzed...\n",
      "\n",
      "summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ב.ה.שׁנה.ה.ראשׁונה.ב.ה.חדשׁ.ה.ראשׁון</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>מן.ה.יום.ו.עד.ה.יום.ה.זה</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>מספר.ה.ימים.שׁלשׁ.מאות.ו.תשׁעים.יום</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.יום.ו.עד.ה.יום.ה.זה</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>כ.ימות.שׁנות</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>מ.ימי.ה.שׁפטים.ו.כל.ימי.מלכי.ישׂראל.ו.מלכי.יהודה</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>תמיד.מ.רשׁית.ה.שׁנה.ו.עד.אחרית.שׁנה</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ל.מן.ה.יום.עד.ה.יום.ה.זה</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.שׁלושׁה.עשׂר.יום.בו.ב.ה.יום</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ל.מן.ה.יום.ו.עד.ה.יום.ה.זה</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.ה.שׁנה.ה.תשׁעית.ב.ה.חדשׁ.ה.עשׂירי.ב.ה.עשׂור.ל.ה.חדשׁ</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ל.מ.יום.ו.עד.ה.יום.ה.זה</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ל.מן.ה.יום.ו.עד.עתה</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>כל.ימי.חיי.הבלך.כל.ימי.הבלך</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>מן.ה.יום.ו.הלאה.ל.דרתיכם</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.יום.עשׂרים.ו.ארבעה.ל.עשׁתי.עשׂר.חדשׁ.ב.שׁנת.שׁתים.ל.דריושׁ</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.שׁנת.ה.ארבעים.ב.ה.חדשׁ.ה.חמישׁי.ב.אחד.ל.ה.חדשׁ</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Total\n",
       "ב.ה.שׁנה.ה.ראשׁונה.ב.ה.חדשׁ.ה.ראשׁון                    1\n",
       "מן.ה.יום.ו.עד.ה.יום.ה.זה                                1\n",
       "מספר.ה.ימים.שׁלשׁ.מאות.ו.תשׁעים.יום                     1\n",
       "ב.יום.ו.עד.ה.יום.ה.זה                                   1\n",
       "כ.ימות.שׁנות                                            1\n",
       "מ.ימי.ה.שׁפטים.ו.כל.ימי.מלכי.ישׂראל.ו.מלכי.יהודה        1\n",
       "תמיד.מ.רשׁית.ה.שׁנה.ו.עד.אחרית.שׁנה                     1\n",
       "ל.מן.ה.יום.עד.ה.יום.ה.זה                                1\n",
       "ב.שׁלושׁה.עשׂר.יום.בו.ב.ה.יום                           1\n",
       "ל.מן.ה.יום.ו.עד.ה.יום.ה.זה                              1\n",
       "ב.ה.שׁנה.ה.תשׁעית.ב.ה.חדשׁ.ה.עשׂירי.ב.ה.עשׂור.ל...      1\n",
       "ל.מ.יום.ו.עד.ה.יום.ה.זה                                 1\n",
       "ל.מן.ה.יום.ו.עד.עתה                                     1\n",
       "כל.ימי.חיי.הבלך.כל.ימי.הבלך                             1\n",
       "מן.ה.יום.ו.הלאה.ל.דרתיכם                                1\n",
       "ב.יום.עשׂרים.ו.ארבעה.ל.עשׁתי.עשׂר.חדשׁ.ב.שׁנת.ש...      1\n",
       "ב.שׁנת.ה.ארבעים.ב.ה.חדשׁ.ה.חמישׁי.ב.אחד.ל.ה.חדשׁ        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unanalyzed_times = collections.Counter()\n",
    "\n",
    "for time in all_times - analyzed_times:\n",
    "    surface = tokenize_surface(time, api)\n",
    "    unanalyzed_times[surface] += 1\n",
    "    \n",
    "print(sum(unanalyzed_times.values()), 'times not analyzed...')\n",
    "print()\n",
    "print(\"summary:\")\n",
    "\n",
    "unanalyzed_times = convert2pandas(unanalyzed_times)\n",
    "\n",
    "unanalyzed_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Exploration\n",
    "\n",
    "The most basic clustering for time phrases is their surface forms. What are the most common types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_time_forms = collections.Counter()\n",
    "\n",
    "for time in analyzed_times:\n",
    "    surface = tokenize_surface(time, api)\n",
    "    analyzed_time_forms[surface] += 1\n",
    "    \n",
    "analyzed_time_forms = convert2pandas(analyzed_time_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1149 unique surface forms found\n"
     ]
    }
   ],
   "source": [
    "print(f'{analyzed_time_forms.shape[0]} unique surface forms found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing top 20 surface forms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>עתה</th>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.ה.יום.ה.הוא</th>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ה.יום</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ל.עולם</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.ה.בקר</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>עד.ה.יום.ה.זה</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.יום</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>אז</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>שׁבעת.ימים</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>עד.עולם</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>אחרי.כן</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>כל.ה.ימים</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>כל.ה.יום</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>עד.ה.ערב</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>לילה</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.ה.עת.ה.היא</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.ה.יום.ה.שׁביעי</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>אחר</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>מחר</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>תמיד</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Total\n",
       "עתה                 342\n",
       "ב.ה.יום.ה.הוא       203\n",
       "ה.יום               191\n",
       "ל.עולם               85\n",
       "ב.ה.בקר              78\n",
       "עד.ה.יום.ה.זה        71\n",
       "ב.יום                68\n",
       "אז                   66\n",
       "שׁבעת.ימים           63\n",
       "עד.עולם              53\n",
       "אחרי.כן              47\n",
       "כל.ה.ימים            44\n",
       "כל.ה.יום             42\n",
       "עד.ה.ערב             41\n",
       "לילה                 41\n",
       "ב.ה.עת.ה.היא         37\n",
       "ב.ה.יום.ה.שׁביעי     36\n",
       "אחר                  34\n",
       "מחר                  31\n",
       "תמיד                 30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = 20\n",
    "print(f'showing top {top} surface forms')\n",
    "analyzed_time_forms.head(top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This top list accounts for a substantial proportion of all known time adverbials in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of times accounted for in top 20:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4132508378448054"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'ratio of times accounted for in top {top}:')\n",
    "analyzed_time_forms.head(top).sum()[0] / len(all_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formal Taxonomy, Dividing the Times\n",
    "\n",
    "**A time adverbial is defined as any construction that modifies event time.** The construction may be a word, phrase, or even clause. This project is focused on word and phrase level time adverbials. The time adverbials can be divided into two main forms: single-phrase and multi-phrase.\n",
    "\n",
    "**Single phrase time adverbials contain a single _profiled_ time word.** The \"profiled\" word is the head of the phrase, following Croft's model of headship as \"the primary information bearing unit\" (2001: 257ff). In a time adverbial, the head is typically a specialized term that indicates time, though not always (e.g. as is the case with event nouns). Besides the head, single phrasal adverbials can contain other words that modify the head. There are prepositional and non-prepositional varieties of single phrase adverbials. Note that in semantic headship as defined by Croft, it is the object of the preposition, not the preposition itself, which is considered the head of a phrase.\n",
    "\n",
    "**Multiphrasal time adverbials contain two or more profiled time elements which are coordinated together.** This coordination can come in the form of literal coordination, e.g. with ו, or various kinds of appositional functions, e.g. when multiple prepositions are \"stacked\" to coordinate a time within a specific position. Multi-phrasal time adverbials appear with any combination of prepositional and non-prepositional forms.\n",
    "\n",
    "The basic taxonomy looks like so:\n",
    "\n",
    "```\n",
    "single-phrase\n",
    "|     |\n",
    "|     prepositional\n",
    "|     |\n",
    "|     non-prepositional\n",
    "|\n",
    "multi-phrase\n",
    "      |\n",
    "      prep/non-prep combinations\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: Generate taxonomy from tags directly\n",
    "\n",
    "# # build up taxonomy as a directed graph\n",
    "# taxonomy = nx.DiGraph((\n",
    "#     ('time', 'single'),\n",
    "#     ('time', 'multi'),\n",
    "#     ('single', 'øprep'),\n",
    "#     ('single', 'prep'),\n",
    "#     ('øprep', 'bare'),\n",
    "#     ('prep', 'bare'),\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Deductive and Inductive Classification Process\n",
    "\n",
    "For classifying the current set of time adverbials, we will utilize a process of elimination. That deductive process is aided by the inductive analysis of time adverbial surface form data. In other words, the categories outlined above and to be outlined further below have been identified by looking at the quantities of the surface form counts to see which categories seem to exert influence. The goal is to be guided by the data, but at the same time derive categories which are useful for collocation research.\n",
    "\n",
    "### Matching (`CXBuilder`) and Searching (`SearchCX`)\n",
    "\n",
    "The `CXBuilder` class provides methods for testing any number of conditions on a provided element. It can then modify any matched CX, or compile it into a new `Construction` object. \n",
    "\n",
    "The tools provided by `CXSearch` can then scan the time adverbials for matches based on the `CXBuilder`'s rules.\n",
    "\n",
    "### Surface form counting\n",
    "\n",
    "Surface forms are counted by first being stripped of accentuation, then tokenized along their lexical boundaries, and finally joined on periods. We utilize prominent counts in the inductive side of the process.\n",
    "\n",
    "### Keeping Track\n",
    "\n",
    "We maintain a set of constructions which are and are not accounted for as we build and match the conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "We put together a custom `CXBuilder` for labeling the CXs. For single-phrase constructions, we simply will add an attribute to each CX object: `classification`. The attribute will be a list of class labels that correspond to a position in the taxonomy tree.\n",
    "\n",
    "**For single-phrase adverbials, the CXbuilder will simply add a classification tag, while a seperate builder will, instead, combine components of multi-phrase constructions into a single analyzed form.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy and Track Covered Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetSelection:\n",
    "    \"\"\"Get sets of CXs based on interesecting sets\"\"\"\n",
    "    def __init__(self, setdict):\n",
    "        \"\"\"Initialize.\n",
    "        \n",
    "        Args:\n",
    "            setdict: a dict of string to set mappings\n",
    "        \"\"\"\n",
    "        self.setdict = setdict\n",
    "    def __getitem__(self, sets):\n",
    "        \"\"\"Retrieve overlapping sets.\n",
    "        \n",
    "        Args:\n",
    "            sets: an iterable of strings which are\n",
    "                the names of the sets to be searched.\n",
    "        Returns:\n",
    "            The overlapping set.\n",
    "        \"\"\"\n",
    "        result = set()\n",
    "        for st in sets:\n",
    "            if not result:\n",
    "                result |= self.setdict[st]\n",
    "            else:\n",
    "                result = result & self.setdict[st]\n",
    "        return result\n",
    "    \n",
    "    def get_union(self, sets):\n",
    "        \"\"\"Return a union of the sets\"\"\"\n",
    "        result = set(\n",
    "            cx for stname, st in self.setdict.items()\n",
    "                if stname in sets\n",
    "                for cx in st\n",
    "        )\n",
    "        return result       \n",
    "\n",
    "def show_classes(classes, classtags, exclude=tuple(), \n",
    "                 counts=True, view=False,\n",
    "                 shuffle=False, end=100, head=50, \n",
    "                 **tfkwargs,\n",
    "                 ):\n",
    "    \"\"\"Iterate through overlapping sets and count/display their results\"\"\"\n",
    "    cxs = classes[classtags] - classes.get_union(exclude)\n",
    "    cl_counts = collections.Counter()\n",
    "    surface2cx = collections.defaultdict(set)\n",
    "    \n",
    "    # tokenize cx and count/store it for review\n",
    "    for cx in cxs:\n",
    "        surface = tokenize_surface(cx.slots, api)\n",
    "        cl_counts[surface] += 1\n",
    "        surface2cx[surface].add(cx)\n",
    "        \n",
    "    # display counts \n",
    "    if counts:\n",
    "        cl_counts = convert2pandas(cl_counts)\n",
    "        print(cl_counts.sum().sum(), 'results')\n",
    "        display(cl_counts.head(head))\n",
    "        \n",
    "    # display cxs in class tags\n",
    "    if view is True:\n",
    "        cxs = list(cxs)\n",
    "        if shuffle: \n",
    "            random.shuffle(cxs)\n",
    "        for cx in cxs[:end]:\n",
    "            se.showcx(cx, **tfkwargs)\n",
    "        return cxs\n",
    "            \n",
    "    # display cxs in an iterable of surface forms\n",
    "    elif view:\n",
    "        view_list = [\n",
    "            cx for surf in view\n",
    "                for cx in surface2cx[surf]\n",
    "        ]\n",
    "        if shuffle:\n",
    "            random.shuffle(view_list)\n",
    "        for cx in view_list[:end]:\n",
    "            se.showcx(cx, **tfkwargs)\n",
    "        return view_list\n",
    "    \n",
    "    else:\n",
    "        return list(cxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build up taxonomy and keep track of todo-cxs\n",
    "class Tracker:\n",
    "    \"\"\"A class for tracking tagged Constructions\"\"\"\n",
    "    \n",
    "    def __init__(self, classdict, cxset, \n",
    "                 exclude=set(),\n",
    "                 base={'single', 'non_single'}\n",
    "                ):\n",
    "        \"\"\"Initialize Tracker.\n",
    "        \n",
    "        Args:\n",
    "            classdict: dict of class string to set of\n",
    "                classified CX objects\n",
    "            cxset: a set of all CXs that are analyzed\n",
    "            base: the tag which represents the base\n",
    "                of the analysis\n",
    "        \"\"\"\n",
    "        self.setselect = SetSelection(classdict)\n",
    "        self.cxset = self.setselect.get_union(base)\n",
    "        self.classdict = {\n",
    "            cl:cxs for cl,cxs in classdict.items()\n",
    "                if cxs & self.cxset\n",
    "        }\n",
    "        self.exclude = exclude | base\n",
    "        \n",
    "    def tally_classes(self):\n",
    "        \"\"\"Return a Counter on classes\"\"\"\n",
    "        count = collections.Counter()\n",
    "        for cl, cxset in self.classdict.items():\n",
    "            count[cl] += len(cxset)\n",
    "        return convert2pandas(count)\n",
    "        \n",
    "    def get_found(self):\n",
    "        \"\"\"Get CXs that have already been classified.\"\"\"\n",
    "        return set(\n",
    "            cx for classname, cxs in self.classdict.items()\n",
    "                for cx in cxs if classname not in self.exclude\n",
    "        )\n",
    "        \n",
    "    def get_remaining(self):\n",
    "        \"\"\"Get CXs not yet classified.\"\"\"\n",
    "        found = self.get_found()\n",
    "        return self.cxset - found\n",
    "        \n",
    "    def remaining_data(self):\n",
    "        \"\"\"Make a count dict of all remaining forms\"\"\"\n",
    "        remaining = self.get_remaining()\n",
    "        count = collections.Counter()\n",
    "        form2cxs = collections.defaultdict(set)\n",
    "        for cx in remaining:\n",
    "            slots = cx.slots\n",
    "            surface = tokenize_surface(slots, api) \n",
    "            count[surface] += 1\n",
    "            form2cxs[surface].add(cx)\n",
    "        return (count, form2cxs)\n",
    "        \n",
    "    def remaining_forms(self):\n",
    "        \"\"\"Retrieve a sorted count of remaining CX surface forms\"\"\"\n",
    "        count,x = self.remaining_data()\n",
    "        return convert2pandas(count)\n",
    "    \n",
    "    def see_remaining(self, forms, end=10, shuffle=False, **tf_kwargs):\n",
    "        \"\"\"Display remaining cxs that are fed in\"\"\"\n",
    "        x,form2cxs = self.remaining_data()\n",
    "        cxs = list(\n",
    "            cx for form in forms\n",
    "                for cx in form2cxs[form]\n",
    "        )\n",
    "        if shuffle:\n",
    "            random.shuffle(cxs)\n",
    "        for cx in cxs[:end]:\n",
    "            se.showcx(cx, **tf_kwargs)\n",
    "        return cxs\n",
    "    \n",
    "    def percent(self, n1, total):\n",
    "        \"\"\"Calculate ratio\"\"\"\n",
    "        return round(n1/total, 2) * 100\n",
    "        \n",
    "    def prog(self, head=10):\n",
    "        \"\"\"Report progress dynamically.\"\"\"\n",
    "        \n",
    "        # report progress\n",
    "        to_do = len(self.get_remaining())\n",
    "        done = len(self.get_found())\n",
    "        done_progress = self.percent(done, done+to_do)\n",
    "        todo_progress = self.percent(to_do, done+to_do)\n",
    "        print(f'{done_progress}% ({done}) classified')\n",
    "        print(f'{todo_progress}% ({to_do}) unclassified')\n",
    "        \n",
    "        # report class counts\n",
    "        print()\n",
    "        print(f'Class counts:')\n",
    "        class_counts = self.tally_classes()\n",
    "        display(class_counts)\n",
    "        \n",
    "        # report forms of unclassified CXs\n",
    "        print()\n",
    "        remain_forms = self.remaining_forms()\n",
    "        print(f'Top {head} unclassified surface forms') \n",
    "        display(remain_forms.head(head))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CXBuilders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# sys.path.append('../cxs/')\n",
    "\n",
    "# from phrase_classes import SinglePhrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PREPROCESSING DATA \n",
    "\n",
    "# # copy cxs for modification by builder\n",
    "# cx_dataset = set(\n",
    "#     tuple(copy.deepcopy(cx_data))\n",
    "#         for ph, cx_data in phrase2cxs.items()\n",
    "# )\n",
    "\n",
    "# # compile acceptable head lexemes from single-phrased CXs\n",
    "# good_heads = set()\n",
    "# for cx_data in cx_dataset:\n",
    "#     if len(cx_data) == 1:\n",
    "#         cx = cx_data[0]\n",
    "#         head = list(cx.getsuccroles('head'))[-1]\n",
    "#         good_heads.add(F.lex.v(head))\n",
    "    \n",
    "# # tag patterns in CXs\n",
    "# sp = SinglePhrase(cx_dataset, good_heads, A)\n",
    "# sp.label_cxs()\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% (4297) classified\n",
      "0.0% (0) unclassified\n",
      "\n",
      "Class counts:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>single</th>\n",
       "      <td>4297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep</th>\n",
       "      <td>2604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>øprep</th>\n",
       "      <td>1693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>definite</th>\n",
       "      <td>1578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bare</th>\n",
       "      <td>1381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component</th>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_apposition</th>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantified</th>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardinal</th>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demonstrative</th>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genitive</th>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qualitative</th>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ordinal</th>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suffix</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geni_cardinal</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adjective</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total\n",
       "single           4297\n",
       "prep             2604\n",
       "øprep            1693\n",
       "definite         1578\n",
       "bare             1381\n",
       "component        1017\n",
       "def_apposition    753\n",
       "quantified        742\n",
       "cardinal          555\n",
       "demonstrative     525\n",
       "genitive          522\n",
       "qualitative       241\n",
       "ordinal           228\n",
       "suffix            137\n",
       "geni_cardinal      88\n",
       "adjective          16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 25 unclassified surface forms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Total]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "track = Tracker(\n",
    "    sp.class2cx,\n",
    "    cx_dataset,\n",
    "    exclude={\n",
    "        'single', 'component',\n",
    "        'prep', 'øprep',\n",
    "    },\n",
    ")\n",
    "\n",
    "track.prog(head=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See remaining forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CX prep_ph (182104, 182105, 182106, 182107),\n",
       " CX prep_ph (182108, 182109, 182110)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ph = phrase2cxs[1448639]\n",
    "test_ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = sp.single(test_ph[-1], test_ph)\n",
    "# test.cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se.showcx(test_ph[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remaining = track.see_remaining(['אחת'], condenseType='sentence', end=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = SetSelection(sp.class2cx)\n",
    "\n",
    "# show_cl = show_classes(\n",
    "#     classes,\n",
    "#     ('not_single',),\n",
    "#     #exclude=('single',),\n",
    "#     end=25,\n",
    "#     counts=True,\n",
    "#     view=['כל.ה.ימים'],\n",
    "#     shuffle=True,\n",
    "#     condenseType='sentence'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Phrasals\n",
    "\n",
    "### To-Do\n",
    "\n",
    "I have currently written the SinglePhrase builder with only single-phrased examples in mind. However, this misses the important fact that many multi-phrasal CXs will likewise have single-phrasal component parts. I can re-write the single phrase CXBuilder to receive cxs that are also from multi-phrasal items. Yet this approach would be complicated by the fact that not all phrases within a multi-phrasal time construction will be time-oriented. The result would be that I would have skewed class statistics. For example, if a phrase is \"למלך\" as part of a calendrical CX, it would end up getting counted as a \"prepositional\" and \"definite\" time cx. But it is not itself a time CX, only a part of one. But in other cases, the phrase may indeed also be able to function as its own independent time CX, such as in יום ביום. But even this example raises the issue of whether this CX can truly be decomposed into those smaller parts.\n",
    "\n",
    "It is worth considering whether it is better to:\n",
    "\n",
    "1. utilize the same rules in the single-phrasal builder to tag constituent phrases in multi-phrasal time CXs\n",
    "2. re-write many rules separately, at the risk of duplicating logic already handled in single-phrases.\n",
    "\n",
    "Option 1 has the strength of enforcing consistency across all categories, whereas option 2 has the ability to cater solutions specific to multi-phrasal constructions. \n",
    "\n",
    "**I lean toward option 2.** There are likely many phrases, specific to certain constructions, that do not contain heads that are lexicalized for time. These need to be defined individually. It might mean that certain lower level patterns are duplicated. But that would also mean that they are available for future restrictions and modifications specific to multi-phrasal constructions. \n",
    "\n",
    "An option 3 might be to require the SinglePhrase Builder as an argument to the MultiPhrase Builder, and use only the patterns which are relevant. This would allow me to take advantage of both situations.\n",
    "\n",
    "### Update 2019-12-19\n",
    "\n",
    "I am actually going with option 1. Why? I have found a way to separate time-oriented phrases from non-time oriented phrases by relying on a list of valid head words, harvested from the single-phrase time CXs. This list is augmented by manual additions where necessary. I have added a separate class title for those phrases which are part of a larger whole, `component`. Thus, I am able to maintain a separation from standalone single-phrase CXs and component single-phrase CXs. This is a nice approach. This way, my model accurately reflects the fact that component time CXs are typically composed of CXs that can and often do stand on their own. That is not to say that the situation is wholly compositional. But this does allow a way forward in which I can gradually add more nuance to the formal description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase2cxs2 = {\n",
    "    L.u(cx_tuple[0].slots[0],'timephrase')[0]: cx_tuple\n",
    "        for cx_tuple in cx_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiPhrase(CXbuilder):\n",
    "    \"\"\"Build composite time adverbial CXs.\"\"\"\n",
    "    \n",
    "    def __init__(self, phrase2cxs, semdistances, tf):\n",
    "        CXbuilder.__init__(self)\n",
    "        \n",
    "        # set up tf methods\n",
    "        self.tf = tf\n",
    "        self.F, self.T, self.L = tf.api.F, tf.api.T, tf.api.L\n",
    "        \n",
    "        # map cx to phrase node for context retrieval\n",
    "        self.phrase2cxs = phrase2cxs\n",
    "        self.cx2phrase = {\n",
    "            cx:ph \n",
    "                for ph in phrase2cxs\n",
    "                    for cx in phrase2cxs[ph]\n",
    "        }\n",
    "        \n",
    "        self.cxs = (        \n",
    "        )\n",
    "        self.dripbucket = (\n",
    "            self.cxph\n",
    "        )\n",
    "        \n",
    "        self.kind = 'multiphrase'\n",
    "        \n",
    "    def getP(self, cx):\n",
    "        \"\"\"Retrieve the context of a cx\"\"\"\n",
    "        phrase_node = self.cx2phrase[cx]\n",
    "        return Positions(\n",
    "            cx, \n",
    "            self.phrase2cxs[phrase_node],\n",
    "            default=Construction()\n",
    "        ).get\n",
    "        \n",
    "    def cxph(self, cx):\n",
    "        \"\"\"Dripbucket function that returns cx as is.\"\"\"\n",
    "        return cx\n",
    "        \n",
    "    def appo_time(self, cx):\n",
    "        \"\"\"Apposition of Time\"\"\"\n",
    "        P = self.getP(cx)\n",
    "        \n",
    "        return self.test(\n",
    "            {\n",
    "                'element': cx,\n",
    "                'name': 'appo_time',\n",
    "                'kind': self.kind,\n",
    "                'roles': {'head':cx, 'appo': P(1)},\n",
    "                'conds': {\n",
    "                    'single in cx.classification':\n",
    "                        'single' in cx.__dict__.get('classification',[]),\n",
    "                    'single in P1.classification':\n",
    "                        'single' in P(1).__dict__.get('classification',[])\n",
    "                }\n",
    "            },\n",
    "        )\n",
    "    \n",
    "mp = MultiPhrase(phrase2cxs2, semdists, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_cxs = [cx for cx_tuple in cx_dataset for cx in cx_tuple]\n",
    "\n",
    "# se.search(all_cxs, mp.appo_time, show=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ph = phrase2cxs2[1447112]\n",
    "\n",
    "# test_ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = mp.appo_time(test_ph[0])\n",
    "\n",
    "# se.showcx(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

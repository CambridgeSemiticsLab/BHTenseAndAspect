{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composing Time Constructions\n",
    "\n",
    "In this notebook we build and test a Hebrew phrase parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.9.0\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "122 features found and 5 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s No structure info in otext, the structure part of the T-API cannot be used\n",
      "  5.68s All features loaded/computed - for details use loadLog()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src:\n",
       "    local(\"SILEOT.ttf\"),\n",
       "    url(\"https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.woff?raw=true\");\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0a6611;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    direction: ltr;\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -0.1rem 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: x-small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 0.1em 0em;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-style: italic;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".ltr {\n",
       "    direction: ltr ! important;\n",
       "}\n",
       ".verse {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".vl {\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-end;\n",
       "    align-items: flex-end;\n",
       "    direction: ltr;\n",
       "    width: 100%;\n",
       "}\n",
       ".outeritem {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".sentence,.clause,.phrase {\n",
       "    margin-top: -1.2em;\n",
       "    margin-left: 1em;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 0.3em;\n",
       "    border-style: solid;\n",
       "    border-radius: 0.2em;\n",
       "    font-size: small;\n",
       "    display: block;\n",
       "    width: fit-content;\n",
       "    max-width: fit-content;\n",
       "    direction: ltr;\n",
       "}\n",
       ".atoms {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".satom,.catom,.patom {\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    border-radius: 0.3em;\n",
       "    border-style: solid;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".sentence {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".clause {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".phrase {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".satom {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 4px;\n",
       "}\n",
       ".catom {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".patom {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".word {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 1px solid #cccccc;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".lextp {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 2px solid #888888;\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".occs {\n",
       "    font-size: x-small;\n",
       "}\n",
       ".satom.l,.catom.l,.patom.l {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".satom.r,.catom.r,.patom.r {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".satom.lno,.catom.lno,.patom.lno {\n",
       "    border-left-style: none\n",
       "}\n",
       ".satom.rno,.catom.rno,.patom.rno {\n",
       "    border-right-style: none\n",
       "}\n",
       ".tr,.tr a:visited,.tr a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".trb,.trb a:visited,.trb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: normal;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".prb,.prb a:visited,.prb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".h,.h a:visited,.h a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".hb,.hb a:visited,.hb a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    line-height: 2;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".vn {\n",
       "  font-size: small !important;\n",
       "  padding-right: 1em;\n",
       "}\n",
       ".rela,.function,.typ {\n",
       "    font-family: monospace;\n",
       "    font-size: small;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".pdp,.pdp a:visited,.pdp a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".voc_lex {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vs {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vt {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".gloss {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #444444;\n",
       "}\n",
       ".vrs {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: #444444;\n",
       "}\n",
       ".nd {\n",
       "    font-family: monospace;\n",
       "    font-size: x-small;\n",
       "    color: #999999;\n",
       "}\n",
       ".hl {\n",
       "    background-color: #ffee66;\n",
       "}\n",
       "\n",
       "tr.tf, td.tf, th.tf {\n",
       "  text-align: left;\n",
       "}\n",
       "\n",
       "span.hldot {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder: 0.2rem solid var(--hl-rim);\n",
       "\tborder-radius: 0.4rem;\n",
       "\t/*\n",
       "\tdisplay: inline-block;\n",
       "\twidth: 0.8rem;\n",
       "\theight: 0.8rem;\n",
       "\t*/\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "\n",
       "span.hlup {\n",
       "\tborder-color: var(--hl-dark);\n",
       "\tborder-width: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 0.2rem;\n",
       "  padding: 0.2rem;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55, 100%,  60%, 0.9  );\n",
       "\t--hl-dark:          hsla( 55, 100%,  40%, 0.9  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import collections\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import copy\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from Levenshtein import distance as lev_dist\n",
    "from pprint import pprint\n",
    "\n",
    "# local packages\n",
    "from tf_tools.load import load_tf\n",
    "\n",
    "# load semantic vectors\n",
    "from paths import semvector\n",
    "with open(semvector, 'rb') as infile: \n",
    "    semdist = pickle.load(infile)\n",
    "\n",
    "# load and configure Text-Fabric\n",
    "TF, api, A = load_tf()\n",
    "F, E, T, L = api.F, api.E, api.T, api.L\n",
    "A.displaySetup(condenseType='phrase', withNodes=True, extraFeatures='st')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add grammar to path\n",
    "sys.path.append('../cxs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machinery\n",
    "\n",
    "We could use some machinery to do the hard work of looking in and around a node. In the older approach we used TF search templates. But these are not very efficient at scale, and they are always bound by the limits of the query language. I take another approach here: a set of classes that specify locations and directions within a specified context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from positions import Positions, PositionsTF, Walker, Dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Positions(TF)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Positions` class enables concise access to adjacent nodes within a given context. This allows us to write algorithms with query-like efficiency with all of the power of Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is instantiated on a word node and can provide contextual look-up data for a given word. For example, given a phrase containing the following word nodes:\n",
    "\n",
    "> (189681, 189682, **189683**, 189684, 189685, 189686) <br>\n",
    "\n",
    "representing the following phrase (space separated for clarity):\n",
    "\n",
    "> ב שׁנת **שׁלשׁים** ו שׁמנה שׁנה\n",
    "\n",
    "Given that the bolded node, `189683` is our `source` word, we instantiate the class, feeding in the node, the \"phrase_atom\" string (which is the context we want to search within), and an instance of Text-Fabric (`tf`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "      #    source node    context  TF instance  \n",
    "      #         |            |       |\n",
    "P = PositionsTF(189683, 'phrase_atom', A).get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to obtain the word adjacent one space forward, we simply ask `P` for `1`, which gives us the next word in the phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189684"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to ask for 4 words forward, we go beyond the bounds of the phrase. But `P` handles this by returning nothing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "P(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look back one word, we simply give a negative value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189682"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, `P` can be used to quickly call features on these words. For instance, in order to get the lexeme of the word two words in front of `189683`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CMNH/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P(2,'lex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we want to get a number of features, we can just add other features to the arguments. The result is a feature set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CMNH/', 'sg'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P(2, 'lex', 'nu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`P` can also handle features on the source node itself by giving a positionality of `0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CLC/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P(0, 'lex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Positions` also exists in a non-TF version\n",
    "\n",
    "When the non-tf version of `Positions` is provided any iterable, it can perform the same functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ps = ['The', 'good', 'dog', 'jumped.']\n",
    "\n",
    "P = Positions('good', test_ps).get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positions can perform a function on the result with an option `do`. In the example below, the word two words ahead is found and an upper-case function is called on the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JUMPED.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P(2, do=lambda w: w.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non-tf version of `Positions` makes it possible to do positionality searches with any ordered list of Python objects that represent linguistic units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Walker`\n",
    "\n",
    "`Walker` performs a similar function to `Positions`, except it is ambiguous to exact positions, walking either `ahead` or `back` from the source to a target node in the context. A function must be supplied that returns `True` on the target node.\n",
    "\n",
    "We instantiate the `Walker` using the same source and context as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 189683\n",
    "# get words inside source's phrase_atom\n",
    "positions = L.d(\n",
    "    L.u(189683,'phrase_atom')[0], 'word'\n",
    ")\n",
    "\n",
    "Wk = Walker(source, positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Walker` is demonstrated below with the same word. A simple `lambda` function is used to test for the lexeme. In the example below, we find the first word ahead of `189683` that is a cardinal number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189685"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wk.ahead(lambda w: F.ls.v(w) == 'card')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative demonstrates the `None` returned on the lack of a valid match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wk.ahead(lambda w: F.ls.v(w) == 'BOOGABOOGA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example wherein we walk backwards to the preposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189681"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wk.back(lambda w: F.sp.v(w) == 'prep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify that the walk should be interrupted under certain conditions with a `stop` function. In this case we walk forward to the next cardinal number, but the walk is interrupted when the `stop` function detects a conjunction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wk.ahead(lambda w: F.ls.v(w) == 'card',\n",
    "         stop=lambda w: F.sp.v(w) == 'conj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify the opposite with a `go` function argument, which defines the nodes that allowed to intervene between `source` and `target`. Below we specify that *only* a conjunction should intervene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189685"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wk.ahead(lambda w: F.ls.v(w) == 'card',\n",
    "         go=lambda w: F.sp.v(w) == 'conj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `go` and `stop` functions can be as permissive or strict as desired.\n",
    "\n",
    "Finally, we can tell `Walker` that the output of the validation function should be returned instead of the node itself with the optional argument `output=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'card'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_funct = lambda w: F.ls.v(w) if F.ls.v(w)=='card' else None\n",
    "\n",
    "Wk.ahead(val_funct, output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ability is useful for certain tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like `Positions`, `Walker` can be used in non-TF contexts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ps = ['The', 'bad', 'cat', 'swatted.']\n",
    "\n",
    "Wk_notf = Walker('bad', test_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'swatted.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wk_notf.ahead(lambda w: w.startswith('sw'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returning All Results along Path\n",
    "\n",
    "`Walker` can also return all results along the path by toggling `every=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'swatted.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wk_notf.ahead(lambda w: type(w)==str, every=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Dummy`\n",
    "\n",
    "When writing conditions and logic, we want an object that passively receives `NoneType`s or zero `int`s without throwing errors. Such an object should also return `None` to reflect its `False` value. `Dummy`, provides such functionality. `Dummy` can receive all of the arguments, kwargs, and function calls as a `Positions` or `Walker` object. But it returns absolutely nothing. Ouch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Dummy(None, 'phrase_atom', A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function call below returns `None`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.get(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As does this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.get(1, 'lex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And even this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.ahead(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`D` is essentially a souless void that consumes whatever you throw at it and gives nothing in return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For safe-calls on a `Position` or `Walker` object, assign nodes to it via a function with a `Dummy` given on null nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPos(node, context, tf):\n",
    "    \"\"\"A function to get Positions safely.\"\"\"\n",
    "    if node:\n",
    "        return PositionsTF(node, context, tf)\n",
    "    else:\n",
    "        return Dummy() # <- give dummy on empty node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = getPos(None, 'phrase_atom', A)\n",
    "P.get(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = getPos(1, 'phrase_atom', A)\n",
    "P.get(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need for Semantic Data\n",
    "\n",
    "The accurate processing of word connections depends on fuller semantic data than BHSA provides. Future semantic data could be stored in a similar way to word sets (`wsets`). \n",
    "\n",
    "For example, in the two phrases\n",
    "\n",
    "> (Exod 25:39) ככר זהב טהור <br>\n",
    "> (2 Sam 24:24) בכסף שקלים חמשׁים\n",
    "\n",
    "we see that זהב and כסף, despite being in two different positions with two different words indicates a kind of \"composed of\" semantic concept: \"round gold\" (i.e. round composed of gold) and \"silver shekels\" (shekels composed of silver). To process these kinds of links, we need a list of nouns that often function as \"material.\" But this is only the beginning. Many other words will have specific semantic values that motivate their syntactic behavior. Such a scope lies outside the bounds of this author's current project on Hebrew time phrases.\n",
    "\n",
    "## A Compromise: Time Phrases\n",
    "\n",
    "Since constructing these semantic classes is vastly time consuming, I want to start with a smaller set of cases. I will instead focus on parsing connections within time phrases for now. This is because I am analyzing time phrases in my current ongoing PhD project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disjoint(ph):\n",
    "    \"\"\"Isolate phrases with gaps.\"\"\"\n",
    "    ph = L.d(ph,'word')\n",
    "    for w in ph:\n",
    "        if ph[-1] == w:\n",
    "            break\n",
    "        elif (ph[ph.index(w)+1] - w) > 1:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4438 phrases ready\n"
     ]
    }
   ],
   "source": [
    "alltimes = [\n",
    "    ph for ph in F.otype.s('timephrase') \n",
    "]\n",
    "    \n",
    "timephrases = [ph for ph in alltimes if not disjoint(ph)]\n",
    "\n",
    "print(f'{len(timephrases)} phrases ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search & Display Functions\n",
    "\n",
    "The functions below allow for fast searching and displaying of queries using a `Construction` object, described in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cx_analysis.search import SearchCX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx_show = SearchCX(A)\n",
    "pretty, prettyconds, showcx, search = (\n",
    "    cx_show.pretty, cx_show.prettyconds, \n",
    "    cx_show.showcx, cx_show.search\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction Classes\n",
    "\n",
    "* `Construction` - an object that represents a linguistic construction; the class records roles and the words that occupy them, as well as has methods for accessing and retrieving data on embedded roles/other constructions\n",
    "* `CXBuilder` - matches conditions to build `Construction` objects; populates them with requisite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cx_analysis.cx import Construction\n",
    "from cx_analysis.build import CXbuilder, CXbuilderTF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Constructions\n",
    "\n",
    "The `wordConstructions` builder class recognizes word semantic classes and types based on provided criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word_grammar import Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subphrase Constructions\n",
    "\n",
    "The `SPConstructions` class prepares subphrase constructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phrase_grammar import Subphrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Constructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning word construction analysis...\n",
      "\t0:00:07.322392 COMPLETE \t[ 13579 ] words loaded\n"
     ]
    }
   ],
   "source": [
    "words = Words(A) # word CX builder\n",
    "\n",
    "# analyze all matches; return as dict\n",
    "start = datetime.now()\n",
    "print(f'Beginning word construction analysis...')\n",
    "wordcxs = words.cxdict(\n",
    "    s for tp in timephrases\n",
    "        for s in L.d(tp,'word')\n",
    ")\n",
    "print(f'\\t{datetime.now() - start} COMPLETE \\t[ {len(wordcxs)} ] words loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time phrase CX builder\n",
    "spc = Subphrases(wordcxs, semdist, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO-FIX\n",
    "\n",
    "* missed appo 361457 cx: 1450112 (בחים מספר ימי חיי הבלו)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty(1448320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_small = spc.appo_name(202679)\n",
    "# showcx(test_small, conds=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stretch Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On deck: adjectival preposition\n",
    "# check performance: 1448556\n",
    "\n",
    "test = spc.analyzestretch(L.d(1450075, 'word'), debug=False)\n",
    "\n",
    "# for res in test:\n",
    "#     showcx(res, conds=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = [w for ph in timephrases for w in L.d(ph, 'word')]\n",
    "\n",
    "# results = search(words, spc.appo_name, pattern='entity_name', show=100, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for res in results:\n",
    "#     head, appo = list(res.getsuccroles('head'))[-1], list(res.getsuccroles('appo'))[-1]\n",
    "#     hlex, alex = F.lex.v(int(head)), F.lex.v(int(appo))\n",
    "    \n",
    "#     showcx(res)\n",
    "#     print()\n",
    "#     print(f'lexs: {hlex} x {alex}')\n",
    "#     print(f'dist: {semdist[hlex][alex]}')\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stretch Tests on Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elements = sorted(set(L.u(res.element, 'timephrase')[0] for res in results))\n",
    "\n",
    "# for el in elements:\n",
    "    \n",
    "#     stretch = L.d(el, 'word')\n",
    "#     test = spc.analyzestretch(stretch)\n",
    "    \n",
    "#     for res in test:\n",
    "#         showcx(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on Random Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuff = [k for k in timephrases\n",
    "#             if len(L.d(k,'word')) > 4]\n",
    "# random.shuffle(shuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for phrase in shuff[:25]:\n",
    "    \n",
    "#     print('analyzing', phrase)\n",
    "#     elements = L.d(phrase,'word')\n",
    "    \n",
    "#     try:\n",
    "#         cxs = tpc.analyzestretch(elements)\n",
    "#         if cxs:\n",
    "#             for cx in cxs:\n",
    "#                 showcx(cx, refslots=elements)\n",
    "#         else:\n",
    "#             showcx(Construction(), refslots=elements)\n",
    "    \n",
    "#     except:\n",
    "#         sys.stderr.write(f'\\nFAIL...running with debug...\\n')\n",
    "#         pretty(phrase)\n",
    "#         tpc.analyzestretch(elements, debug=True)\n",
    "#         raise Exception('...debug complete...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on All Timephrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.000046 beginning subphrase analysis...\n",
      "\t0:00:12.153777\tdone with iter 500/4438\n",
      "\t0:00:24.698732\tdone with iter 1000/4438\n",
      "\t0:00:35.234626\tdone with iter 1500/4438\n",
      "\t0:00:44.588046\tdone with iter 2000/4438\n",
      "\t0:00:58.892290\tdone with iter 2500/4438\n",
      "\t0:01:12.228788\tdone with iter 3000/4438\n",
      "\t0:01:24.128717\tdone with iter 3500/4438\n",
      "\t0:01:35.129935\tdone with iter 4000/4438\n",
      "0:01:48.819077\tCOMPLETE\n",
      "--------------------\n",
      "4438 phrases matched with Constructions...\n",
      "0 phrases not yet matched with Constructions...\n"
     ]
    }
   ],
   "source": [
    "phrase2cxs = collections.defaultdict(list)\n",
    "nocxs = []\n",
    "\n",
    "# time it\n",
    "start = datetime.now()\n",
    "\n",
    "print(f'{datetime.now()-start} beginning subphrase analysis...')\n",
    "\n",
    "for i, phrase in enumerate(timephrases):\n",
    "     \n",
    "    # analyze all known relas\n",
    "    elements = L.d(phrase,'word')\n",
    "    \n",
    "    # analyze with debug exceptions\n",
    "    try:\n",
    "        cxs = spc.analyzestretch(elements)\n",
    "    except:\n",
    "        sys.stderr.write(f'\\nFAIL...running with debug...\\n')\n",
    "        pretty(phrase)\n",
    "        spc.analyzestretch(elements, debug=True)\n",
    "        raise Exception('...debug complete...')\n",
    "\n",
    "    # save those phrases that have no matching constructions\n",
    "    if not cxs:\n",
    "        nocxs.append(phrase)\n",
    "    else:\n",
    "        phrase2cxs[phrase] = cxs\n",
    "        \n",
    "    # report status\n",
    "    if i % 500 == 0 and i:\n",
    "        print(f'\\t{datetime.now()-start}\\tdone with iter {i}/{len(timephrases)}')\n",
    "        \n",
    "print(f'{datetime.now()-start}\\tCOMPLETE')\n",
    "print('-'*20)\n",
    "print(f'{len(phrase2cxs)} phrases matched with Constructions...')\n",
    "print(f'{len(nocxs)} phrases not yet matched with Constructions...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing Gaps\n",
    "\n",
    "### Identify Gaps\n",
    "\n",
    "Find timephrases that contain un-covered words besides waw conjunctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gapped = []\n",
    "# tested = []\n",
    "\n",
    "# for ph, cxs in phrase2cxs.items():\n",
    "    \n",
    "#     tested.append(ph)\n",
    "    \n",
    "#     ph_slots = set(\n",
    "#         s for s in L.d(ph,'word')\n",
    "#     )\n",
    "#     cx_slots = set(\n",
    "#         s for cx in cxs\n",
    "#             for s in cx.slots\n",
    "#     )\n",
    "    \n",
    "#     if ph_slots.difference(cx_slots):\n",
    "#         gapped.append(cxs)\n",
    "        \n",
    "# print(f'{len(gapped)} gapped phrases logged...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for gp in gapped[:25]:\n",
    "#     for cx in gp:\n",
    "#         showcx(cx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase Constructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developing a CXbuilder to connect all constructions in a complete phrase.\n",
    "\n",
    "\n",
    "## Ambiguity with Coordinate CXs\n",
    "\n",
    "Considerable ambiguity is present in several coordinate constructions:\n",
    "\n",
    "**`A B and C`**<br>\n",
    "Given A, B, C == nominal words. Is their relationship `A // B // C` or `A+B // C`. In other words: **what is the relationship of two adjacent nominal words given a list?** Is B a descriptor of A or is it an independent element? \n",
    "\n",
    "**`A of B and C`**<br>\n",
    "Is it, `(A of B) // (C)` or `(A of (B // C)`\n",
    "\n",
    "Or even:\n",
    "\n",
    "**`A of B C and D`**<br>\n",
    "This pattern combines elements from both ambiguous cases.\n",
    "\n",
    "### Method\n",
    "\n",
    "To address these ambiguities we will apply a battery of disambiguation attempts. At the core of these attempts is a [Semantic Vector Space](https://en.wikipedia.org/wiki/Vector_space_model), which is able to quantify the semantic distance between two words based on their contextual uses throughout the Hebrew Bible.\n",
    "\n",
    "The working hypothesis of this method is\n",
    "> Words in coordination with each other will be more semantically similar (i.e. the least distance in the vector space) than other candidates in the phrase.\n",
    "\n",
    "Semantic similarity in a vector space is not the only method used, however. Another aspect of semantic closeness is phrase structure. For instance, the identity of phrase types is taken into consideration above semantic similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_analysis.graph_nav as nav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Phrases(CXbuilder):\n",
    "    \"\"\"Build complete phrase constructions.\"\"\"\n",
    "    \n",
    "    def __init__(self, phrase2cxs, semdist, tf):\n",
    "        CXbuilder.__init__(self)\n",
    "        \n",
    "        # set up tf methods\n",
    "        self.tf = tf\n",
    "        self.F, self.T, self.L = tf.api.F, tf.api.T, tf.api.L\n",
    "        \n",
    "        # map cx to phrase node for context retrieval\n",
    "        self.cx2phrase = {\n",
    "            cx:ph \n",
    "                for ph in phrase2cxs\n",
    "                    for cx in phrase2cxs[ph]\n",
    "        }\n",
    "        \n",
    "        self.phrase2cxs = phrase2cxs\n",
    "        self.semdists = semdist\n",
    "        \n",
    "        self.cxs = (        \n",
    "            self.appo,\n",
    "            self.coord,\n",
    "        )\n",
    "        self.dripbucket = (\n",
    "            self.cxph,\n",
    "        )\n",
    "        \n",
    "        self.kind = 'phrase'\n",
    "        \n",
    "    def cxph(self, cx):\n",
    "        \"\"\"Dripbucket function that returns cx as is.\"\"\"\n",
    "        return cx\n",
    "        \n",
    "    def get_context(self, cx):\n",
    "        \"\"\"Get context for a given cx.\"\"\"\n",
    "        phrase = self.cx2phrase.get(cx, None)\n",
    "        if phrase:\n",
    "            return self.phrase2cxs[phrase]\n",
    "        else:\n",
    "            return tuple()\n",
    "        \n",
    "    def getP(self, cx):\n",
    "        \"\"\"Index positions on phrase context\"\"\"\n",
    "        positions = self.get_context(cx)\n",
    "        if positions:\n",
    "            return Positions(\n",
    "                cx, positions, default=Construction()\n",
    "            ).get\n",
    "        else:\n",
    "            return Dummy\n",
    "\n",
    "    def getWk(self, cx):\n",
    "        \"\"\"Index walks on phrase context\"\"\"\n",
    "        positions = self.get_context(cx)\n",
    "        if positions:\n",
    "            return Walker(cx, positions)\n",
    "        else:\n",
    "            return Dummy()\n",
    "    \n",
    "    def getindex(\n",
    "        self, indexable, index, \n",
    "        default=Construction()\n",
    "    ):\n",
    "        \"\"\"Safe index on iterables w/out IndexErrors.\"\"\"\n",
    "        try:\n",
    "            return indexable[index]\n",
    "        except:\n",
    "            return default\n",
    "    \n",
    "    def getname(self, cx):\n",
    "        \"\"\"Get a cx name\"\"\"\n",
    "        return cx.name\n",
    "    \n",
    "    def getkind(self, cx):\n",
    "        \"\"\"Get a cx kind.\"\"\"\n",
    "        return cx.kind\n",
    "    \n",
    "    def getsuccrole(self, cx, role, index=-1):\n",
    "        \"\"\"Get a cx role from a list of successive roles.\n",
    "        \n",
    "        e.g.\n",
    "        [big_head, medium_head, small_head][-1] == small_head\n",
    "        \"\"\"\n",
    "        cands = list(cx.getsuccroles(role))\n",
    "        try:\n",
    "            return cands[index]\n",
    "        except IndexError:\n",
    "            return Construction()\n",
    "    \n",
    "    def string_plus(self, cx, plus=1):\n",
    "        \"\"\"Stringifies a CX + N-slots for Levenshtein tests.\"\"\"\n",
    "        \n",
    "        # get all slots in the context for plussing\n",
    "        allslots = sorted(set(\n",
    "            s for scx in self.get_context(cx)\n",
    "                for s in scx.slots\n",
    "        ))\n",
    "        \n",
    "        # get plus slots\n",
    "        P = (Positions(self.getindex(cx.slots, -1), allslots).get\n",
    "                 if cx.slots and allslots else Dummy)\n",
    "        plusses = []\n",
    "        for i in range(plus, plus+1):\n",
    "            plusses.append(P(i,-1)) # -1 for null slots (== empty string in T.text)\n",
    "        plusses = [p for p in plusses if type(p) == int]\n",
    "        \n",
    "        # format the text string for Levenshtein testing\n",
    "        ptxt = T.text(\n",
    "            cx.slots + tuple(plusses),\n",
    "            fmt='text-orig-plain'\n",
    "        ) if cx.slots else ''\n",
    "        \n",
    "        return ptxt\n",
    "\n",
    "    def rank_candidates(self, cx, cx_patterns=[]):\n",
    "        \"\"\"Ranks preceding phrases on likelihood of a relationship\n",
    "        \n",
    "        TODO: Give a thorough explanation\n",
    "        \"\"\"\n",
    "        \n",
    "        # standard features and positional navigation\n",
    "        F, T = self.F, self.T\n",
    "        P = self.getP(cx)\n",
    "        semdist = self.semdists\n",
    "        Wk = self.getWk(cx)             \n",
    "            \n",
    "        # first we need to collect candidates\n",
    "        # there are two possibilities:\n",
    "        #    1. non-embedded candidates (i.e. have no other relations)\n",
    "        #    2. embedded candidates (i.e. already part of another subphrase)\n",
    "        # we give first preference to top level candidates as this seems \n",
    "        # to produce more accurate results\n",
    "        \n",
    "        # 1. get all top-level cxs behind this one that match in name\n",
    "        cx_behinds = Wk.back(\n",
    "            lambda c: c.name == cx.name,\n",
    "            every=True,\n",
    "            stop=lambda c: (\n",
    "                c.name == 'conj' and (c != P(-1))\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 2. if top level phrases produce no results,\n",
    "        #       look for embedded candidates\n",
    "        if not cx_behinds:\n",
    "            topcontext = self.get_context(cx)\n",
    "            \n",
    "            # gather all valid embedded candidates\n",
    "            subcontext = []\n",
    "            for topcx in topcontext:\n",
    "                for subcx in topcx.subgraph():\n",
    "                    if type(subcx) == int: # skip TF slots\n",
    "                        continue\n",
    "                    if (\n",
    "                        subcx in topcontext or subcx.name != 'conj'\n",
    "                        and subcx not in cx\n",
    "                    ):\n",
    "                        subcontext.append(subcx)        \n",
    "            \n",
    "            # walk the embedded candidates\n",
    "            # and collect those that are valid\n",
    "            Wk2 = Walker(cx, subcontext)\n",
    "            cx_behinds = Wk2.back(\n",
    "                lambda c: c.name != 'conj', \n",
    "                default=[P(-2)],\n",
    "                every=True,\n",
    "                stop=lambda c: (\n",
    "                    c.name == 'conj' and (c != P(-1))\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Now we apply a series of additional filters on the candidates:\n",
    "        \n",
    "        # map each candidate to its last slot to make sure\n",
    "        # every one is the last item in its phrase\n",
    "        # (check is made in next series of lines)\n",
    "        cx2last = {\n",
    "            cxb:self.getindex(sorted(cxb.slots), -1, 0)\n",
    "                for cxb in cx_behinds\n",
    "        }\n",
    "        \n",
    "        # find coordinate candidate subphrases that stand\n",
    "        # at the end of the phrase\n",
    "        cx_subphrases = []\n",
    "        for cx_back in cx_behinds:\n",
    "            for cxsp in cx_back.subgraph():\n",
    "                if type(cxsp) == int:\n",
    "                    continue\n",
    "                elif (\n",
    "                    cx2last[cx_back] in cxsp.slots # check last slot\n",
    "                    and cxsp.getrole('head')\n",
    "                ):\n",
    "                    cx_subphrases.append(cxsp)\n",
    "        \n",
    "        # get subphrase heads for semantic tests\n",
    "        cx2heads = [\n",
    "            (cxsp, self.getsuccrole(cxsp,'head'))\n",
    "                for cxsp in cx_behinds\n",
    "        ]\n",
    "\n",
    "        # get head of this cx\n",
    "        head1 = self.getsuccrole(cx,'head')     \n",
    "        head1lex = F.lex.v(head1)\n",
    "        \n",
    "        # sort on a set of priorities\n",
    "        # the default sort behavior is used (least to greatest)\n",
    "        # thus when a bigger value should be more important, \n",
    "        # a negative is added to the number\n",
    "        stringp = self.string_plus\n",
    "        \n",
    "        # arrange candidates by priority\n",
    "        cxpriority = []\n",
    "        for cxsp, headsp in cx2heads:\n",
    "            name_eq = 0 if cxsp.name == cx.name else 1\n",
    "            semantic_dist = semdist.get(\n",
    "                head1lex,{}\n",
    "            ).get(F.lex.v(headsp), np.inf)\n",
    "            size = -len(cxsp.slots)\n",
    "            levenshtein = lev_dist(stringp(cx), stringp(cxsp))\n",
    "            slot_dist = -next(iter(cxsp.slots), 0)\n",
    "            heads = (head1, headsp) # for reporting purposes only\n",
    "            \n",
    "            cxpriority.append((\n",
    "                name_eq,\n",
    "                semantic_dist,\n",
    "                size,\n",
    "                levenshtein,\n",
    "                slot_dist,\n",
    "                heads,\n",
    "                cxsp\n",
    "            ))\n",
    "            \n",
    "        # make the sorting\n",
    "        candidates = sorted(cxpriority, key=lambda k: k[:-1])\n",
    "        \n",
    "        # select the first priority candidate\n",
    "        cand = next(iter(candidates), (0,0,Construction()))\n",
    "        \n",
    "        # add data for conds report / debugging\n",
    "        stats = collections.defaultdict(str)\n",
    "        for namescore,sdist,leng,ldist,lslot,heads,cxp in candidates:\n",
    "            # name equality\n",
    "            stats['namescore'] += f'\\n\\t{cxp} namescore: {namescore}'\n",
    "            # semantic distance\n",
    "            stats['semdists'] += (\n",
    "                f'\\n\\t{round(sdist, 2)}, {F.lex.v(heads[0])} ~ {F.lex.v(heads[1])}, {cxp}'\n",
    "            )\n",
    "            # size of cx\n",
    "            stats['size'] += f'\\n\\t{cxp} length: {abs(leng)}'\n",
    "            \n",
    "            # Levenstein distance\n",
    "            stats['ldist'] += f'\\n\\t{cxp} dist: {ldist}'\n",
    "            \n",
    "            # dist of last slot\n",
    "            stats['lslot'] += f'\\n\\t{cxp} last slot: {abs(lslot)}'\n",
    "    \n",
    "        return (candidates, cand, stats)\n",
    "    \n",
    "    def coord(self, cx):\n",
    "        \"\"\"A coordinate construction.\n",
    "        \n",
    "        In order to match a coordinate cx, we need to determine\n",
    "        which item in the previous phrase this cx belongs with. \n",
    "        This is done using a semantic vector space, which can\n",
    "        quantify the approximate semantic distance between the\n",
    "        heads of this cx and a candidate cx.\n",
    "        \n",
    "        Criteria utilized in validating a coordinate cx between\n",
    "        an origin cx and a candidate cx are the following:\n",
    "            TODO: fill in\n",
    "        \"\"\"\n",
    "        \n",
    "        P = self.getP(cx)        \n",
    "        cands, cand, stats = self.rank_candidates(cx)\n",
    "        \n",
    "        return self.test(\n",
    "            {\n",
    "                'element': cx,\n",
    "                'name': 'coord',\n",
    "                'kind': self.kind,\n",
    "                'roles': {'part2':cx, 'conj': P(-1), 'part1': cand[-1]},\n",
    "                'conds': {\n",
    "                    'P(-1).name == conj':\n",
    "                        P(-1).name == 'conj',\n",
    "                    'bool(cand)':\n",
    "                        bool(cand[-1]),\n",
    "                    f'name matches {stats[\"namescore\"]}\\n':\n",
    "                        bool(cands),\n",
    "                    f'is shortest sem. distance of {stats[\"semdists\"]}\\n':\n",
    "                        bool(cands),\n",
    "                    f'is longest length of: {stats[\"size\"]}\\n':\n",
    "                        bool(cands),\n",
    "                    f'is shortest Levenshtein distance: {stats[\"ldist\"]}\\n':\n",
    "                        bool(cands),\n",
    "                    f'is closest last slot of: {stats[\"lslot\"]}\\n':\n",
    "                        bool(cands)\n",
    "                }\n",
    "            },\n",
    "        )\n",
    "    \n",
    "    def L_anchor(self, cx):\n",
    "        \"\"\"Find L anchor CXs\"\"\"\n",
    "        P = self.getP(cx)\n",
    "        prep = nav.get_role(cx, 'prep', default=Construction())\n",
    "        prep = next(iter(prep.slots), 0)\n",
    "        prep_lex = self.F.lex.v(prep)\n",
    "        return self.test(\n",
    "            {\n",
    "                'element': cx,\n",
    "                'name': 'L_anchor',\n",
    "                'kind': self.kind,\n",
    "                'roles': {'anchor': cx, 'head': P(-1)},\n",
    "                'conds': {\n",
    "                    'prep_lex == L':\n",
    "                        prep_lex == 'L',\n",
    "                    'bool(P-1)':\n",
    "                        bool(P(-1)),\n",
    "                },\n",
    "            },\n",
    "        )   \n",
    "    \n",
    "    def appo(self, cx):\n",
    "        \"\"\"Find appositional cxs\"\"\"\n",
    "        \n",
    "        P = self.getP(cx)\n",
    "        cands, cand, stats = self.rank_candidates(cx)\n",
    "                \n",
    "        return self.test(\n",
    "            {\n",
    "                'element': cx,\n",
    "                'name': 'appo',\n",
    "                'pattern': 'NP',\n",
    "                'kind': self.kind,\n",
    "                'roles': {'appo':cx, 'head': cand[-1]},\n",
    "                'conds': {\n",
    "                    'name(cx) not in not_NPset':\n",
    "                        cx.name not in {'prep_ph','conj'},\n",
    "                    'P(-1).name != conj':\n",
    "                        P(-1).name != 'conj',\n",
    "                    'bool(cand)':\n",
    "                        bool(cand[-1]),\n",
    "                    f'name matches {stats[\"namescore\"]}\\n':\n",
    "                        bool(cands),\n",
    "                    f'is shortest sem. distance of {stats[\"semdists\"]}\\n':\n",
    "                        bool(cands),\n",
    "                    f'is longest length of: {stats[\"size\"]}\\n':\n",
    "                        bool(cands),\n",
    "                    f'is shortest Levenshtein distance: {stats[\"ldist\"]}\\n':\n",
    "                        bool(cands),\n",
    "                    f'is closest last slot of: {stats[\"lslot\"]}\\n':\n",
    "                        bool(cands),\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'element': cx,\n",
    "                'name': 'appo',\n",
    "                'pattern': 'PP',\n",
    "                'kind': self.kind,\n",
    "                'roles': {'appo':cx, 'head': cand[-1]},\n",
    "                'conds': {\n",
    "                    'name(cx) == prep':\n",
    "                        cx.name == 'prep_ph',\n",
    "                    'P(-1).name != conj':\n",
    "                        P(-1).name != 'conj',\n",
    "                    'bool(cand)':\n",
    "                        bool(cand[-1]),\n",
    "                    f'name matches {stats[\"namescore\"]}\\n':\n",
    "                        bool(cands),\n",
    "                    f'is shortest sem. distance of {stats[\"semdists\"]}\\n':\n",
    "                        bool(cands),\n",
    "                    f'is longest length of: {stats[\"size\"]}\\n':\n",
    "                        bool(cands),\n",
    "                    f'is shortest Levenshtein distance: {stats[\"ldist\"]}\\n':\n",
    "                        bool(cands),\n",
    "                    f'is closest last slot of: {stats[\"lslot\"]}\\n':\n",
    "                        bool(cands)\n",
    "                }\n",
    "            }        \n",
    "        )\n",
    "    \n",
    "    \n",
    "    def adjacent(self, cx):\n",
    "        \"\"\"Find adjacent CXs\"\"\"\n",
    "        \n",
    "        P = self.getP(cx)\n",
    "        \n",
    "        return self.test(\n",
    "            {\n",
    "                'element': cx,\n",
    "                'name': 'appo',\n",
    "                'kind': self.kind,\n",
    "                'roles': {'head':cx, 'appo':P(1)},\n",
    "                'conds': {\n",
    "                    'cx.name != conj':\n",
    "                        cx.name != 'conj',\n",
    "                    'P(1).name != prep':\n",
    "                        P(1).name != 'prep',\n",
    "                    'bool(P(1))':\n",
    "                        bool(P(1)),\n",
    "                    f'name({P(1).name}) not in (conj, prep_ph)':\n",
    "                        P(1).name not in {'conj','prep_ph'},\n",
    "                }\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "cxp = Phrases(phrase2cxs, semdist, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.show(A.search('''\n",
    "\n",
    "# timephrase\n",
    "#     word pdp=subs ls#card|prpe lex#KL/|JWM/ st=a\n",
    "\n",
    "#     <: word lex=JWM/\n",
    "# ''')[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following phrases contain cases that still\n",
    "# need to be fixed for the coordinate cx; some should\n",
    "# actually be done in the previous cx builder at subphrase level\n",
    "\n",
    "to_fix = [\n",
    "    1450039, # coord, add adjacent advb cx with JWM\n",
    "    1450647, # coord, consider prioritizing Levenshtein over size\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><b>result</b> <i>1449813 -> CX coord (281784, 281785, 281786)</i></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Ezechiel&amp;chapter=34&amp;verse=12&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"show this passage in SHEBANQ\" sec=\"Ezekiel 34:12\">Ezekiel 34:12</a>\n",
       "<div class=\"atoms  \" >\n",
       "<a href=\"#\" class=\"nd\">817713</a>\n",
       "\n",
       "\n",
       "\n",
       "<div class=\"patom  \" >\n",
       "\n",
       "    <div class=\"phrase \" >\n",
       "        <a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Ezechiel&amp;chapter=34&amp;verse=12&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Ezekiel 34:12\" sec=\"Ezekiel 34:12\">phrase</a> <a href=\"#\" class=\"nd\">817713</a>  <span class=\"function\">Time</span> <span class=\"typ\">PP</span>\n",
       "    </div>\n",
       "    <div class=\"atoms\">\n",
       "\n",
       "<div class=\"word  \" >\n",
       "<a href=\"#\" class=\"nd\">281782</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1B\" title=\"show this lexeme in SHEBANQ\">בְּ</a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Ezechiel&amp;chapter=34&amp;verse=12&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Ezekiel 34:12\" sec=\"Ezekiel 34:12\">prep</a></span> <span class=\"gloss\">in</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>B</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>prep</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"word  \" >\n",
       "<a href=\"#\" class=\"nd\">281783</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1JWMn\" title=\"show this lexeme in SHEBANQ\">יֹ֥ום </a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Ezechiel&amp;chapter=34&amp;verse=12&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Ezekiel 34:12\" sec=\"Ezekiel 34:12\">subs</a></span> <span class=\"gloss\">day</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>JWM/</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>subs</span> <span class=\"st xft\"><span class=\"f\">st=</span>c</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"word  hl\"  style=\"background-color: #ffcc5c;\" >\n",
       "<a href=\"#\" class=\"nd\">281784</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1ONNn\" title=\"show this lexeme in SHEBANQ\">עָנָ֖ן </a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Ezechiel&amp;chapter=34&amp;verse=12&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Ezekiel 34:12\" sec=\"Ezekiel 34:12\">subs</a></span> <span class=\"gloss\">cloud</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>&lt;NN/</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>subs</span> <span class=\"st xft\"><span class=\"f\">st=</span>a</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"word  hl\"  style=\"background-color: #ffeead;\" >\n",
       "<a href=\"#\" class=\"nd\">281785</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1W\" title=\"show this lexeme in SHEBANQ\">וַ</a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Ezechiel&amp;chapter=34&amp;verse=12&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Ezekiel 34:12\" sec=\"Ezekiel 34:12\">conj</a></span> <span class=\"gloss\">and</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>W</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>conj</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"word  hl\"  style=\"background-color: #96ceb4;\" >\n",
       "<a href=\"#\" class=\"nd\">281786</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1ORPLn\" title=\"show this lexeme in SHEBANQ\">עֲרָפֶֽל׃ </a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Ezechiel&amp;chapter=34&amp;verse=12&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Ezekiel 34:12\" sec=\"Ezekiel 34:12\">subs</a></span> <span class=\"gloss\">darkness</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>&lt;RPL/</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>subs</span> <span class=\"st xft\"><span class=\"f\">st=</span>a</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background: #96ceb4; text-align: center\">part2</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background: #ffeead; text-align: center\">conj</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background: #ffcc5c; text-align: center\">part1</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   '__cx__': 'coord',\n",
      "    'conj': {'__cx__': 'conj', 'head': 281785},\n",
      "    'part1': {'__cx__': 'cont', 'head': 281784},\n",
      "    'part2': {'__cx__': 'cont', 'head': 281786}}\n",
      "\n",
      "-- CX coord (281784, 281785, 281786) --\n",
      "pattern: coord\n",
      "P(-1).name == conj                                       True\n",
      "bool(cand)                                               True\n",
      "name matches \n",
      "\tCX cont (281784,) namescore: 0\n",
      "\tCX cont (281783,) namescore: 0\n",
      "\tCX prep_ph (281782, 281783, 281784) namescore: 1\n",
      "\tCX geni_ph (281783, 281784) namescore: 1\n",
      "\tCX prep (281782,) namescore: 1\n",
      "                           True\n",
      "is shortest sem. distance of \n",
      "\t0.7, <RPL/ ~ <NN/, CX cont (281784,)\n",
      "\t1.08, <RPL/ ~ JWM/, CX cont (281783,)\n",
      "\t1.08, <RPL/ ~ JWM/, CX prep_ph (281782, 281783, 281784)\n",
      "\t1.08, <RPL/ ~ JWM/, CX geni_ph (281783, 281784)\n",
      "\tinf, <RPL/ ~ B, CX prep (281782,)\n",
      "                           True\n",
      "is longest length of: \n",
      "\tCX cont (281784,) length: 1\n",
      "\tCX cont (281783,) length: 1\n",
      "\tCX prep_ph (281782, 281783, 281784) length: 3\n",
      "\tCX geni_ph (281783, 281784) length: 2\n",
      "\tCX prep (281782,) length: 1\n",
      "                           True\n",
      "is shortest Levenshtein distance: \n",
      "\tCX cont (281784,) dist: 4\n",
      "\tCX cont (281783,) dist: 5\n",
      "\tCX prep_ph (281782, 281783, 281784) dist: 9\n",
      "\tCX geni_ph (281783, 281784) dist: 7\n",
      "\tCX prep (281782,) dist: 6\n",
      "                           True\n",
      "is closest last slot of: \n",
      "\tCX cont (281784,) last slot: 281784\n",
      "\tCX cont (281783,) last slot: 281783\n",
      "\tCX prep_ph (281782, 281783, 281784) last slot: 281782\n",
      "\tCX geni_ph (281783, 281784) last slot: 281783\n",
      "\tCX prep (281782,) last slot: 281782\n",
      "                           True\n",
      "\n",
      "-- CX cont (281786,) --\n",
      "pattern: cont\n",
      "bool(F.pdp.v(281786))                                    True\n",
      "\n",
      "-- CX conj (281785,) --\n",
      "pattern: conj\n",
      "bool(F.pdp.v(281785))                                    True\n",
      "\n",
      "-- CX cont (281784,) --\n",
      "pattern: cont\n",
      "bool(F.pdp.v(281784))                                    True\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = cxp.coord(phrase2cxs[1449813][-1])\n",
    "\n",
    "showcx(test, conds=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.freq_lex.v(363638)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1443373,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.u(363638,'lex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><b>result</b> <i>1450668 -> CX coord (363636, 363637, 363638)</i></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Threni&amp;chapter=1&amp;verse=7&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"show this passage in SHEBANQ\" sec=\"Lamentations 1:7\">Lamentations 1:7</a>\n",
       "<div class=\"atoms  \" >\n",
       "<a href=\"#\" class=\"nd\">872677</a>\n",
       "\n",
       "\n",
       "\n",
       "<div class=\"patom  \" >\n",
       "\n",
       "    <div class=\"phrase \" >\n",
       "        <a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Threni&amp;chapter=1&amp;verse=7&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Lamentations 1:7\" sec=\"Lamentations 1:7\">phrase</a> <a href=\"#\" class=\"nd\">872677</a>  <span class=\"function\">Time</span> <span class=\"typ\">NP</span>\n",
       "    </div>\n",
       "    <div class=\"atoms\">\n",
       "\n",
       "<div class=\"word  \" >\n",
       "<a href=\"#\" class=\"nd\">363635</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1JWMn\" title=\"show this lexeme in SHEBANQ\">יְמֵ֤י </a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Threni&amp;chapter=1&amp;verse=7&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Lamentations 1:7\" sec=\"Lamentations 1:7\">subs</a></span> <span class=\"gloss\">day</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>JWM/</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>subs</span> <span class=\"st xft\"><span class=\"f\">st=</span>c</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"word  hl\"  style=\"background-color: #ffcc5c;\" >\n",
       "<a href=\"#\" class=\"nd\">363636</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1ONJin\" title=\"show this lexeme in SHEBANQ\">עָנְיָהּ֙ </a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Threni&amp;chapter=1&amp;verse=7&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Lamentations 1:7\" sec=\"Lamentations 1:7\">subs</a></span> <span class=\"gloss\">poverty</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>&lt;NJ=/</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>subs</span> <span class=\"st xft\"><span class=\"f\">st=</span>a</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"word  hl\"  style=\"background-color: #ffeead;\" >\n",
       "<a href=\"#\" class=\"nd\">363637</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1W\" title=\"show this lexeme in SHEBANQ\">וּ</a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Threni&amp;chapter=1&amp;verse=7&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Lamentations 1:7\" sec=\"Lamentations 1:7\">conj</a></span> <span class=\"gloss\">and</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>W</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>conj</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"word  hl\"  style=\"background-color: #96ceb4;\" >\n",
       "<a href=\"#\" class=\"nd\">363638</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1MRWDn\" title=\"show this lexeme in SHEBANQ\">מְרוּדֶ֔יהָ </a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Threni&amp;chapter=1&amp;verse=7&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Lamentations 1:7\" sec=\"Lamentations 1:7\">subs</a></span> <span class=\"gloss\">homelessness</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>MRWD/</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>subs</span> <span class=\"st xft\"><span class=\"f\">st=</span>a</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background: #96ceb4; text-align: center\">part2</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background: #ffeead; text-align: center\">conj</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background: #ffcc5c; text-align: center\">part1</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   '__cx__': 'coord',\n",
      "    'conj': {'__cx__': 'conj', 'head': 363637},\n",
      "    'part1': {'__cx__': 'cont', 'head': 363636},\n",
      "    'part2': {'__cx__': 'cont', 'head': 363638}}\n",
      "\n",
      "-- CX coord (363636, 363637, 363638) --\n",
      "pattern: coord\n",
      "P(-1).name == conj                                       True\n",
      "bool(cand)                                               True\n",
      "name matches \n",
      "\tCX cont (363636,) namescore: 0\n",
      "\tCX cont (363635,) namescore: 0\n",
      "\tCX geni_ph (363635, 363636) namescore: 1\n",
      "                           True\n",
      "is shortest sem. distance of \n",
      "\t0.68, MRWD/ ~ <NJ=/, CX cont (363636,)\n",
      "\t1.39, MRWD/ ~ JWM/, CX cont (363635,)\n",
      "\t1.39, MRWD/ ~ JWM/, CX geni_ph (363635, 363636)\n",
      "                           True\n",
      "is longest length of: \n",
      "\tCX cont (363636,) length: 1\n",
      "\tCX cont (363635,) length: 1\n",
      "\tCX geni_ph (363635, 363636) length: 2\n",
      "                           True\n",
      "is shortest Levenshtein distance: \n",
      "\tCX cont (363636,) dist: 4\n",
      "\tCX cont (363635,) dist: 5\n",
      "\tCX geni_ph (363635, 363636) dist: 6\n",
      "                           True\n",
      "is closest last slot of: \n",
      "\tCX cont (363636,) last slot: 363636\n",
      "\tCX cont (363635,) last slot: 363635\n",
      "\tCX geni_ph (363635, 363636) last slot: 363635\n",
      "                           True\n",
      "\n",
      "-- CX cont (363638,) --\n",
      "pattern: cont\n",
      "bool(F.pdp.v(363638))                                    True\n",
      "\n",
      "-- CX conj (363637,) --\n",
      "pattern: conj\n",
      "bool(F.pdp.v(363637))                                    True\n",
      "\n",
      "-- CX cont (363636,) --\n",
      "pattern: cont\n",
      "bool(F.pdp.v(363636))                                    True\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = cxp.coord(phrase2cxs[1450668][-1])\n",
    "\n",
    "showcx(test, conds=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1450558,)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.u(862564,'timephrase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><b>result</b> <i>1450558 -> CX coord (348663, 348667, 348668)</i></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Proverbia&amp;chapter=7&amp;verse=9&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"show this passage in SHEBANQ\" sec=\"Proverbs 7:9\">Proverbs 7:9</a>\n",
       "<div class=\"atoms  \" >\n",
       "<a href=\"#\" class=\"nd\">862564</a>\n",
       "\n",
       "\n",
       "\n",
       "<div class=\"patom  l \" >\n",
       "\n",
       "    <div class=\"phrase \" >\n",
       "        <a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Proverbia&amp;chapter=7&amp;verse=9&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Proverbs 7:9\" sec=\"Proverbs 7:9\">phrase</a> <a href=\"#\" class=\"nd\">862564</a>  <span class=\"function\">Time</span> <span class=\"typ\">PP</span>\n",
       "    </div>\n",
       "    <div class=\"atoms\">\n",
       "\n",
       "<div class=\"word  \" >\n",
       "<a href=\"#\" class=\"nd\">348659</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1B\" title=\"show this lexeme in SHEBANQ\">בְּ</a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Proverbia&amp;chapter=7&amp;verse=9&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Proverbs 7:9\" sec=\"Proverbs 7:9\">prep</a></span> <span class=\"gloss\">in</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>B</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>prep</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"word  \" >\n",
       "<a href=\"#\" class=\"nd\">348660</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1NCPn\" title=\"show this lexeme in SHEBANQ\">נֶֽשֶׁף־</a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Proverbia&amp;chapter=7&amp;verse=9&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Proverbs 7:9\" sec=\"Proverbs 7:9\">subs</a></span> <span class=\"gloss\">breeze</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>NCP/</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>subs</span> <span class=\"st xft\"><span class=\"f\">st=</span>a</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"patom  r l \" >\n",
       "\n",
       "    <div class=\"phrase \" >\n",
       "        <a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Proverbia&amp;chapter=7&amp;verse=9&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Proverbs 7:9\" sec=\"Proverbs 7:9\">phrase</a> <a href=\"#\" class=\"nd\">862564</a>  <span class=\"function\">Time</span> <span class=\"typ\">PP</span>\n",
       "    </div>\n",
       "    <div class=\"atoms\">\n",
       "\n",
       "<div class=\"word  \" >\n",
       "<a href=\"#\" class=\"nd\">348661</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1B\" title=\"show this lexeme in SHEBANQ\">בְּ</a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Proverbia&amp;chapter=7&amp;verse=9&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Proverbs 7:9\" sec=\"Proverbs 7:9\">prep</a></span> <span class=\"gloss\">in</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>B</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>prep</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"word  \" >\n",
       "<a href=\"#\" class=\"nd\">348662</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1ORBn\" title=\"show this lexeme in SHEBANQ\">עֶ֥רֶב </a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Proverbia&amp;chapter=7&amp;verse=9&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Proverbs 7:9\" sec=\"Proverbs 7:9\">subs</a></span> <span class=\"gloss\">evening</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>&lt;RB/</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>subs</span> <span class=\"st xft\"><span class=\"f\">st=</span>a</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"word  hl\"  style=\"background-color: #ffcc5c;\" >\n",
       "<a href=\"#\" class=\"nd\">348663</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1JWMn\" title=\"show this lexeme in SHEBANQ\">יֹ֑ום </a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Proverbia&amp;chapter=7&amp;verse=9&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Proverbs 7:9\" sec=\"Proverbs 7:9\">subs</a></span> <span class=\"gloss\">day</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>JWM/</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>subs</span> <span class=\"st xft\"><span class=\"f\">st=</span>a</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"patom  r \" >\n",
       "\n",
       "    <div class=\"phrase \" >\n",
       "        <a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Proverbia&amp;chapter=7&amp;verse=9&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Proverbs 7:9\" sec=\"Proverbs 7:9\">phrase</a> <a href=\"#\" class=\"nd\">862564</a>  <span class=\"function\">Time</span> <span class=\"typ\">PP</span>\n",
       "    </div>\n",
       "    <div class=\"atoms\">\n",
       "\n",
       "<div class=\"word  \" >\n",
       "<a href=\"#\" class=\"nd\">348664</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1B\" title=\"show this lexeme in SHEBANQ\">בְּ</a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Proverbia&amp;chapter=7&amp;verse=9&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Proverbs 7:9\" sec=\"Proverbs 7:9\">prep</a></span> <span class=\"gloss\">in</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>B</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>prep</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"word  \" >\n",
       "<a href=\"#\" class=\"nd\">348665</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1AJCWNn\" title=\"show this lexeme in SHEBANQ\">אִישֹׁ֥ון </a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Proverbia&amp;chapter=7&amp;verse=9&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Proverbs 7:9\" sec=\"Proverbs 7:9\">subs</a></span> <span class=\"gloss\">pupil of eye</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>>JCWN/</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>subs</span> <span class=\"st xft\"><span class=\"f\">st=</span>c</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"word  \" >\n",
       "<a href=\"#\" class=\"nd\">348666</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1LJLHn\" title=\"show this lexeme in SHEBANQ\">לַ֝֗יְלָה </a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Proverbia&amp;chapter=7&amp;verse=9&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Proverbs 7:9\" sec=\"Proverbs 7:9\">subs</a></span> <span class=\"gloss\">night</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>LJLH/</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>subs</span> <span class=\"st xft\"><span class=\"f\">st=</span>a</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"word  hl\"  style=\"background-color: #ffeead;\" >\n",
       "<a href=\"#\" class=\"nd\">348667</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1W\" title=\"show this lexeme in SHEBANQ\">וַ</a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Proverbia&amp;chapter=7&amp;verse=9&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Proverbs 7:9\" sec=\"Proverbs 7:9\">conj</a></span> <span class=\"gloss\">and</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>W</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>conj</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"word  hl\"  style=\"background-color: #96ceb4;\" >\n",
       "<a href=\"#\" class=\"nd\">348668</a>\n",
       "<div class=\"h\"><a target=\"_blank\" href=\"https://shebanq.ancient-data.org/hebrew/word?version=c&amp;id=1APLHn\" title=\"show this lexeme in SHEBANQ\">אֲפֵלָֽה׃ </a></div>\n",
       "<div class=\"features\"> <span class=\"pdp\"><a href=\"https://shebanq.ancient-data.org/hebrew/text?book=Proverbia&amp;chapter=7&amp;verse=9&amp;version=c&amp;mr=m&amp;qw=q&amp;tp=txt_p&amp;tr=hb&amp;wget=v&amp;qget=v&amp;nget=vt\" title=\"Proverbs 7:9\" sec=\"Proverbs 7:9\">subs</a></span> <span class=\"gloss\">darkness</span> <span class=\"lex xft\"><span class=\"f\">lex=</span>>PLH/</span> <span class=\"sp xft\"><span class=\"f\">sp=</span>subs</span> <span class=\"st xft\"><span class=\"f\">st=</span>a</span></div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background: #96ceb4; text-align: center\">part2</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background: #ffeead; text-align: center\">conj</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background: #ffcc5c; text-align: center\">part1</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   '__cx__': 'coord',\n",
      "    'conj': {'__cx__': 'conj', 'head': 348667},\n",
      "    'part1': {'__cx__': 'cont', 'head': 348663},\n",
      "    'part2': {'__cx__': 'cont', 'head': 348668}}\n",
      "\n",
      "-- CX coord (348663, 348667, 348668) --\n",
      "pattern: coord\n",
      "P(-1).name == conj                                       True\n",
      "bool(cand)                                               True\n",
      "name matches \n",
      "\tCX cont (348663,) namescore: 0\n",
      "                           True\n",
      "is shortest sem. distance of \n",
      "\t0.68, >PLH/ ~ JWM/, CX cont (348663,)\n",
      "                           True\n",
      "is longest length of: \n",
      "\tCX cont (348663,) length: 1\n",
      "                           True\n",
      "is shortest Levenshtein distance: \n",
      "\tCX cont (348663,) dist: 6\n",
      "                           True\n",
      "is closest last slot of: \n",
      "\tCX cont (348663,) last slot: 348663\n",
      "                           True\n",
      "\n",
      "-- CX cont (348668,) --\n",
      "pattern: cont\n",
      "bool(F.pdp.v(348668))                                    True\n",
      "\n",
      "-- CX conj (348667,) --\n",
      "pattern: conj\n",
      "bool(F.pdp.v(348667))                                    True\n",
      "\n",
      "-- CX cont (348663,) --\n",
      "pattern: cont\n",
      "bool(F.pdp.v(348663))                                    True\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = cxp.coord(phrase2cxs[1450558][-1])\n",
    "\n",
    "showcx(test, conds=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stretch Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "testph = phrase2cxs[1446841]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = cxp.analyzestretch(\n",
    "#     testph, \n",
    "#     duplicate=True,\n",
    "#     debug=True)\n",
    "\n",
    "# for res in test:\n",
    "#     showcx(res, conds=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# TOFIX:\n",
    "* fix apposition - 1447545 (צען מצרים)\n",
    "\n",
    "# TOTEST: \n",
    "\n",
    "1450333 - from apposition to proper name\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print total number of phrases left to parse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    len([cx_tuple for cx_tuple in phrase2cxs.values() if len(cx_tuple) > 1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_gaps(cx):\n",
    "    \"\"\"Isolate cxs with gaps\"\"\"\n",
    "    timephrase = L.u(next(iter(cx.slots)),'phrase')[0]\n",
    "    if set(L.d(timephrase,'word')) - cx.slots:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def filt(cx):\n",
    "    \"\"\"Find specific lexeme\"\"\"\n",
    "    timephrase = L.u(next(iter(cx.slots)),'phrase')[0]\n",
    "    phrasewords = L.d(timephrase, 'word')\n",
    "    if (\n",
    "        {'JWM/', 'LJLH/'}.issubset(set(F.lex.v(w) for w in phrasewords))\n",
    "        and len(phrasewords) == 3\n",
    "    ):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elements = [\n",
    "#     cx for ph in list(phrase2cxs.values())\n",
    "#         for cx in ph\n",
    "# ]\n",
    "\n",
    "# results = search(\n",
    "#     elements, \n",
    "#     cxp.L_anchor, \n",
    "#     pattern='',\n",
    "#     shuffle=False,\n",
    "#     #select=lambda c: filt(c),\n",
    "#     extraFeatures='lex st',\n",
    "#     show=100\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Tests\n",
    "\n",
    "Testing across a whole phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = cxp.analyzestretch(phrase2cxs[1449168], debug=True)\n",
    "# for res in test:\n",
    "#     showcx(res, conds=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying timephrases\n",
    "\n",
    "This notebook will seek to establish a taxonomy of time phrases in Biblical Hebrew that is as comprehensive as possible. The `Construction` object is used as the starting point for the analysis. We already have a set of `Construction` objects (henceforth simply \"cx\") that have been preprocessed based on their subphrase grammar. These subphrases allow us to make certain selections of the data and place labels on the time phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.8.12\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "119 features found and 6 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s No structure info in otext, the structure part of the T-API cannot be used\n",
      "  6.55s All features loaded/computed - for details use loadLog()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src:\n",
       "    local(\"SILEOT.ttf\"),\n",
       "    url(\"https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.woff?raw=true\");\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0a6611;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    direction: ltr;\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -0.1rem 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: x-small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 0.1em 0em;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-style: italic;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".ltr {\n",
       "    direction: ltr ! important;\n",
       "}\n",
       ".verse {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".vl {\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-end;\n",
       "    align-items: flex-end;\n",
       "    direction: ltr;\n",
       "    width: 100%;\n",
       "}\n",
       ".outeritem {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".sentence,.clause,.phrase {\n",
       "    margin-top: -1.2em;\n",
       "    margin-left: 1em;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 0.3em;\n",
       "    border-style: solid;\n",
       "    border-radius: 0.2em;\n",
       "    font-size: small;\n",
       "    display: block;\n",
       "    width: fit-content;\n",
       "    max-width: fit-content;\n",
       "    direction: ltr;\n",
       "}\n",
       ".atoms {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".satom,.catom,.patom {\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    border-radius: 0.3em;\n",
       "    border-style: solid;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".sentence {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".clause {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".phrase {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".satom {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 4px;\n",
       "}\n",
       ".catom {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".patom {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".word {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 1px solid #cccccc;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".lextp {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 2px solid #888888;\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".occs {\n",
       "    font-size: x-small;\n",
       "}\n",
       ".satom.l,.catom.l,.patom.l {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".satom.r,.catom.r,.patom.r {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".satom.lno,.catom.lno,.patom.lno {\n",
       "    border-left-style: none\n",
       "}\n",
       ".satom.rno,.catom.rno,.patom.rno {\n",
       "    border-right-style: none\n",
       "}\n",
       ".tr,.tr a:visited,.tr a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".trb,.trb a:visited,.trb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: normal;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".prb,.prb a:visited,.prb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".h,.h a:visited,.h a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".hb,.hb a:visited,.hb a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    line-height: 2;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".vn {\n",
       "  font-size: small !important;\n",
       "  padding-right: 1em;\n",
       "}\n",
       ".rela,.function,.typ {\n",
       "    font-family: monospace;\n",
       "    font-size: small;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".pdp,.pdp a:visited,.pdp a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".voc_lex {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vs {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vt {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".gloss {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #444444;\n",
       "}\n",
       ".vrs {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: #444444;\n",
       "}\n",
       ".nd {\n",
       "    font-family: monospace;\n",
       "    font-size: x-small;\n",
       "    color: #999999;\n",
       "}\n",
       ".hl {\n",
       "    background-color: #ffee66;\n",
       "}\n",
       "\n",
       "tr.tf, td.tf, th.tf {\n",
       "  text-align: left;\n",
       "}\n",
       "\n",
       "span.hldot {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder: 0.2rem solid var(--hl-rim);\n",
       "\tborder-radius: 0.4rem;\n",
       "\t/*\n",
       "\tdisplay: inline-block;\n",
       "\twidth: 0.8rem;\n",
       "\theight: 0.8rem;\n",
       "\t*/\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "\n",
       "span.hlup {\n",
       "\tborder-color: var(--hl-dark);\n",
       "\tborder-width: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 0.2rem;\n",
       "  padding: 0.2rem;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55, 100%,  60%, 0.9  );\n",
       "\t--hl-dark:          hsla( 55, 100%,  40%, 0.9  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import collections\n",
    "import pickle\n",
    "import copy\n",
    "import random\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from helpers import barplot_counts, convert2pandas\n",
    "from tf_tools.load import load_tf\n",
    "from tf_tools.tokenizers import tokenize_surface\n",
    "from cx_analysis.cx import Construction\n",
    "from cx_analysis.build import CXbuilder\n",
    "from cx_analysis.search import SearchCX\n",
    "from positions import Positions\n",
    "from locations import cxs as cx_data\n",
    "\n",
    "TF, api, A = load_tf()\n",
    "F, E, T, L = api.F, api.E, api.T, api.L\n",
    "\n",
    "with open(cx_data, 'rb') as infile:\n",
    "    cx_load = pickle.load(infile)\n",
    "    phrase2cxs = cx_load['phrase2cxs']\n",
    "    \n",
    "se = SearchCX(A)\n",
    "A.displaySetup(condenseType='phrase', withNodes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "The current cx dataset excludes time phrases that have gaps inside. These will be analyzed at a later stage due to their complexity. Let's get a sense for how many there are and what is included in the analysis set. The `timephrase` object is a custom object built from the ETCBC phrase object. It makes several corrections as well as fusions of the time phrases. The `timephrase` object is what the Construction classes are built upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s 3881 results\n"
     ]
    }
   ],
   "source": [
    "all_times = A.search('timephrase', shallow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_times = set(phrase2cxs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 times not analyzed...\n",
      "\n",
      "summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ל.מן.ה.יום.ו.עד.ה.יום.ה.זה</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.שׁלושׁה.עשׂר.יום.בו.ב.ה.יום</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.יום.ו.עד.ה.יום.ה.זה</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>כ.ימות.שׁנות</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>מ.ימי.ה.שׁפטים.ו.כל.ימי.מלכי.ישׂראל.ו.מלכי.יהודה</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>תמיד.מ.רשׁית.ה.שׁנה.ו.עד.אחרית.שׁנה</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ל.מן.ה.יום.עד.ה.יום.ה.זה</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>מן.ה.יום.ו.עד.ה.יום.ה.זה</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ל.מ.יום.ו.עד.ה.יום.ה.זה</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.ה.שׁנה.ה.ראשׁונה.ב.ה.חדשׁ.ה.ראשׁון</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.ה.שׁנה.ה.תשׁעית.ב.ה.חדשׁ.ה.עשׂירי.ב.ה.עשׂור.ל.ה.חדשׁ</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>כל.ימי.חיי.הבלך.כל.ימי.הבלך</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ל.מן.ה.יום.ו.עד.עתה</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>מספר.ה.ימים.שׁלשׁ.מאות.ו.תשׁעים.יום</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>מן.ה.יום.ו.הלאה.ל.דרתיכם</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.יום.עשׂרים.ו.ארבעה.ל.עשׁתי.עשׂר.חדשׁ.ב.שׁנת.שׁתים.ל.דריושׁ</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.שׁנת.ה.ארבעים.ב.ה.חדשׁ.ה.חמישׁי.ב.אחד.ל.ה.חדשׁ</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Total\n",
       "ל.מן.ה.יום.ו.עד.ה.יום.ה.זה                              1\n",
       "ב.שׁלושׁה.עשׂר.יום.בו.ב.ה.יום                           1\n",
       "ב.יום.ו.עד.ה.יום.ה.זה                                   1\n",
       "כ.ימות.שׁנות                                            1\n",
       "מ.ימי.ה.שׁפטים.ו.כל.ימי.מלכי.ישׂראל.ו.מלכי.יהודה        1\n",
       "תמיד.מ.רשׁית.ה.שׁנה.ו.עד.אחרית.שׁנה                     1\n",
       "ל.מן.ה.יום.עד.ה.יום.ה.זה                                1\n",
       "מן.ה.יום.ו.עד.ה.יום.ה.זה                                1\n",
       "ל.מ.יום.ו.עד.ה.יום.ה.זה                                 1\n",
       "ב.ה.שׁנה.ה.ראשׁונה.ב.ה.חדשׁ.ה.ראשׁון                    1\n",
       "ב.ה.שׁנה.ה.תשׁעית.ב.ה.חדשׁ.ה.עשׂירי.ב.ה.עשׂור.ל...      1\n",
       "כל.ימי.חיי.הבלך.כל.ימי.הבלך                             1\n",
       "ל.מן.ה.יום.ו.עד.עתה                                     1\n",
       "מספר.ה.ימים.שׁלשׁ.מאות.ו.תשׁעים.יום                     1\n",
       "מן.ה.יום.ו.הלאה.ל.דרתיכם                                1\n",
       "ב.יום.עשׂרים.ו.ארבעה.ל.עשׁתי.עשׂר.חדשׁ.ב.שׁנת.ש...      1\n",
       "ב.שׁנת.ה.ארבעים.ב.ה.חדשׁ.ה.חמישׁי.ב.אחד.ל.ה.חדשׁ        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unanalyzed_times = collections.Counter()\n",
    "\n",
    "for time in all_times - analyzed_times:\n",
    "    surface = tokenize_surface(time, api)\n",
    "    unanalyzed_times[surface] += 1\n",
    "    \n",
    "print(sum(unanalyzed_times.values()), 'times not analyzed...')\n",
    "print()\n",
    "print(\"summary:\")\n",
    "\n",
    "unanalyzed_times = convert2pandas(unanalyzed_times)\n",
    "\n",
    "unanalyzed_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Exploration\n",
    "\n",
    "The most basic clustering for time phrases is their surface forms. What are the most common types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_time_forms = collections.Counter()\n",
    "\n",
    "for time in analyzed_times:\n",
    "    surface = tokenize_surface(time, api)\n",
    "    analyzed_time_forms[surface] += 1\n",
    "    \n",
    "analyzed_time_forms = convert2pandas(analyzed_time_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150 unique surface forms found\n"
     ]
    }
   ],
   "source": [
    "print(f'{analyzed_time_forms.shape[0]} unique surface forms found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing top 20 surface forms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>עתה</th>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.ה.יום.ה.הוא</th>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ה.יום</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ל.עולם</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.ה.בקר</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>עד.ה.יום.ה.זה</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.יום</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>אז</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>שׁבעת.ימים</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>עד.עולם</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>אחרי.כן</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>כל.ה.ימים</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>כל.ה.יום</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>לילה</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>עד.ה.ערב</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.ה.עת.ה.היא</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ב.ה.יום.ה.שׁביעי</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>אחר</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>מחר</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>תמיד</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Total\n",
       "עתה                 342\n",
       "ב.ה.יום.ה.הוא       203\n",
       "ה.יום               191\n",
       "ל.עולם               85\n",
       "ב.ה.בקר              78\n",
       "עד.ה.יום.ה.זה        71\n",
       "ב.יום                69\n",
       "אז                   66\n",
       "שׁבעת.ימים           63\n",
       "עד.עולם              53\n",
       "אחרי.כן              47\n",
       "כל.ה.ימים            44\n",
       "כל.ה.יום             42\n",
       "לילה                 41\n",
       "עד.ה.ערב             41\n",
       "ב.ה.עת.ה.היא         37\n",
       "ב.ה.יום.ה.שׁביעי     36\n",
       "אחר                  34\n",
       "מחר                  31\n",
       "תמיד                 30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = 20\n",
    "print(f'showing top {top} surface forms')\n",
    "analyzed_time_forms.head(top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This top list accounts for a substantial proportion of all known time adverbials in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of times accounted for in top 20:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.413295542385983"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'ratio of times accounted for in top {top}:')\n",
    "analyzed_time_forms.head(top).sum()[0] / len(all_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formal Taxonomy, Dividing the Times\n",
    "\n",
    "**A time adverbial is defined as any construction that modifies event time.** The construction may be a word, phrase, or even clause. This project is focused on word and phrase level time adverbials. The time adverbials can be divided into two main forms: single-phrase and multi-phrase.\n",
    "\n",
    "**Single phrase time adverbials contain a single _profiled_ time word.** The \"profiled\" word is the head of the phrase, following Croft's model of headship as \"the primary information bearing unit\" (2001: 257ff). In a time adverbial, the head is typically a specialized term that indicates time, though not always (e.g. as is the case with event nouns). Besides the head, single phrasal adverbials can contain other words that modify the head. There are prepositional and non-prepositional varieties of single phrase adverbials. Note that in semantic headship as defined by Croft, it is the object of the preposition, not the preposition itself, which is considered the head of a phrase.\n",
    "\n",
    "**Multiphrasal time adverbials contain two or more profiled time elements which are coordinated together.** This coordination can come in the form of literal coordination, e.g. with ו, or various kinds of appositional functions, e.g. when multiple prepositions are \"stacked\" to coordinate a time within a specific position. Multi-phrasal time adverbials appear with any combination of prepositional and non-prepositional forms.\n",
    "\n",
    "The basic taxonomy looks like so:\n",
    "\n",
    "```\n",
    "single-phrase\n",
    "|     |\n",
    "|     prepositional\n",
    "|     |\n",
    "|     non-prepositional\n",
    "|\n",
    "multi-phrase\n",
    "      |\n",
    "      prep/non-prep combinations\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: Generate taxonomy from tags directly\n",
    "\n",
    "# # build up taxonomy as a directed graph\n",
    "# taxonomy = nx.DiGraph((\n",
    "#     ('time', 'single'),\n",
    "#     ('time', 'multi'),\n",
    "#     ('single', 'øprep'),\n",
    "#     ('single', 'prep'),\n",
    "#     ('øprep', 'bare'),\n",
    "#     ('prep', 'bare'),\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Deductive and Inductive Classification Process\n",
    "\n",
    "For classifying the current set of time adverbials, we will utilize a process of elimination. That deductive process is aided by the inductive analysis of time adverbial surface form data. In other words, the categories outlined above and to be outlined further below have been identified by looking at the quantities of the surface form counts to see which categories seem to exert influence. The goal is to be guided by the data, but at the same time derive categories which are useful for collocation research.\n",
    "\n",
    "### Matching (`CXBuilder`) and Searching (`SearchCX`)\n",
    "\n",
    "The `CXBuilder` class provides methods for testing any number of conditions on a provided element. It can then modify any matched CX, or compile it into a new `Construction` object. \n",
    "\n",
    "The tools provided by `CXSearch` can then scan the time adverbials for matches based on the `CXBuilder`'s rules.\n",
    "\n",
    "### Surface form counting\n",
    "\n",
    "Surface forms are counted by first being stripped of accentuation, then tokenized along their lexical boundaries, and finally joined on periods. We utilize prominent counts in the inductive side of the process.\n",
    "\n",
    "### Keeping Track\n",
    "\n",
    "We maintain a set of constructions which are and are not accounted for as we build and match the conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "We put together a custom `CXBuilder` for labeling the CXs. For single-phrase constructions, we simply will add an attribute to each CX object: `classification`. The attribute will be a list of class labels that correspond to a position in the taxonomy tree.\n",
    "\n",
    "**For single-phrase adverbials, the CXbuilder will simply add a classification tag, while a seperate builder will, instead, combine components of multi-phrase constructions into a single analyzed form.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy and Track Covered Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build up taxonomy and keep track of todo-cxs\n",
    "class Tracker:\n",
    "    \"\"\"A class for tracking tagged Constructions\"\"\"\n",
    "    \n",
    "    def __init__(self, classdict, cxset, \n",
    "                 exclude=set(),\n",
    "                 base='single'\n",
    "                ):\n",
    "        \"\"\"Initialize Tracker.\n",
    "        \n",
    "        Args:\n",
    "            classdict: dict of class string to set of\n",
    "                classified CX objects\n",
    "            cxset: a set of all CXs that are analyzed\n",
    "            exclude: a set of class tags to ignore in \n",
    "                calculations of remaining classes\n",
    "        \"\"\"\n",
    "        self.classdict = classdict\n",
    "        self.cxset = classdict[base]\n",
    "        self.exclude = exclude | {base}\n",
    "        self.setselect = SetSelection(classdict) # select overlapping sets\n",
    "        \n",
    "    def tally_classes(self):\n",
    "        \"\"\"Return a Counter on classes\"\"\"\n",
    "        count = collections.Counter()\n",
    "        for cl, cxset in self.classdict.items():\n",
    "            count[cl] += len(cxset)\n",
    "        return convert2pandas(count)\n",
    "        \n",
    "    def get_found(self):\n",
    "        \"\"\"Get classified CXs\n",
    "        \n",
    "        !!NB!! Currently we wrap tagged cxs in a tuple so that\n",
    "        the found cxs can be compared with the original dataset\n",
    "        which is wrapped cxs. This works fine when dealing with \n",
    "        single phrasal cxs. But a better mapping solution will be \n",
    "        needed for multi-phrasal classification. Should probl use\n",
    "        the timephrase node number then. But may want to also build\n",
    "        a sanity check to make sure the whole tuple gets covered.\n",
    "        \"\"\"\n",
    "        return set(\n",
    "            cx for classname, cxs in self.classdict.items()\n",
    "                for cx in cxs if classname not in self.exclude\n",
    "        )\n",
    "        \n",
    "    def get_remaining(self):\n",
    "        \"\"\"Get CXs not yet classified.\"\"\"\n",
    "        found = self.get_found()\n",
    "        return self.cxset - found\n",
    "        \n",
    "    def remaining_data(self):\n",
    "        \"\"\"Make a count dict of all remaining forms\"\"\"\n",
    "        remaining = self.get_remaining()\n",
    "        count = collections.Counter()\n",
    "        form2cxs = collections.defaultdict(set)\n",
    "        for cx in remaining:\n",
    "            slots = cx.slots\n",
    "            surface = tokenize_surface(slots, api) \n",
    "            count[surface] += 1\n",
    "            form2cxs[surface].add(cx)\n",
    "        return (count, form2cxs)\n",
    "        \n",
    "    def remaining_forms(self):\n",
    "        \"\"\"Retrieve a sorted count of remaining CX surface forms\"\"\"\n",
    "        count,x = self.remaining_data()\n",
    "        return convert2pandas(count)\n",
    "    \n",
    "    def see_remaining(self, forms, end=10, shuffle=False, **tf_kwargs):\n",
    "        \"\"\"Display remaining cxs that are fed in\"\"\"\n",
    "        x,form2cxs = self.remaining_data()\n",
    "        cxs = list(\n",
    "            cx for form in forms\n",
    "                for cx in form2cxs[form]\n",
    "        )\n",
    "        if shuffle:\n",
    "            random.shuffle(cxs)\n",
    "        for cx in cxs[:end]:\n",
    "            se.showcx(cx, **tf_kwargs)\n",
    "        return cxs\n",
    "    \n",
    "    def percent(self, n1, total):\n",
    "        \"\"\"Calculate ratio\"\"\"\n",
    "        return round(n1/total, 2) * 100\n",
    "        \n",
    "    def prog(self, head=10):\n",
    "        \"\"\"Report progress dynamically.\"\"\"\n",
    "        \n",
    "        # report progress\n",
    "        to_do = len(self.get_remaining())\n",
    "        done = len(self.get_found())\n",
    "        done_progress = self.percent(done, done+to_do)\n",
    "        todo_progress = self.percent(to_do, done+to_do)\n",
    "        print(f'{done_progress}% ({done}) classified')\n",
    "        print(f'{todo_progress}% ({to_do}) unclassified')\n",
    "        \n",
    "        # report class counts\n",
    "        print()\n",
    "        print(f'Class counts:')\n",
    "        class_counts = self.tally_classes()\n",
    "        display(class_counts)\n",
    "        \n",
    "        # report forms of unclassified CXs\n",
    "        print()\n",
    "        remain_forms = self.remaining_forms()\n",
    "        print(f'Top {head} unclassified surface forms') \n",
    "        display(remain_forms.head(head))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetSelection:\n",
    "    \"\"\"Get sets of CXs based on interesecting sets\"\"\"\n",
    "    def __init__(self, setdict):\n",
    "        \"\"\"Initialize.\n",
    "        \n",
    "        Args:\n",
    "            setdict: a dict of string to set mappings\n",
    "        \"\"\"\n",
    "        self.setdict = setdict\n",
    "    def __getitem__(self, sets):\n",
    "        \"\"\"Retrieve overlapping sets.\n",
    "        \n",
    "        Args:\n",
    "            sets: an iterable of strings which are\n",
    "                the names of the sets to be searched.\n",
    "        Returns:\n",
    "            The overlapping set.\n",
    "        \"\"\"\n",
    "        result = set()\n",
    "        for st in sets:\n",
    "            if not result:\n",
    "                result |= self.setdict[st]\n",
    "            else:\n",
    "                result = result & self.setdict[st]\n",
    "        return result\n",
    "    \n",
    "    def get_union(self, sets):\n",
    "        \"\"\"Return a union of the sets\"\"\"\n",
    "        result = set(\n",
    "            cx for stname, st in self.setdict.items()\n",
    "                if stname in sets\n",
    "                for cx in st\n",
    "        )\n",
    "        return result       \n",
    "\n",
    "def show_classes(classes, classtags, exclude=tuple(), \n",
    "                 counts=True, view=False,\n",
    "                 shuffle=False, end=100, head=50, \n",
    "                 **tfkwargs,\n",
    "                 ):\n",
    "    \"\"\"Iterate through overlapping sets and count/display their results\"\"\"\n",
    "    cxs = classes[classtags] - classes.get_union(exclude)\n",
    "    cl_counts = collections.Counter()\n",
    "    surface2cx = collections.defaultdict(set)\n",
    "    \n",
    "    # tokenize cx and count/store it for review\n",
    "    for cx in cxs:\n",
    "        surface = tokenize_surface(cx.slots, api)\n",
    "        cl_counts[surface] += 1\n",
    "        surface2cx[surface].add(cx)\n",
    "        \n",
    "    # display counts \n",
    "    if counts:\n",
    "        cl_counts = convert2pandas(cl_counts)\n",
    "        print(cl_counts.sum().sum(), 'results')\n",
    "        display(cl_counts.head(head))\n",
    "        \n",
    "    # display cxs in class tags\n",
    "    if view is True:\n",
    "        cxs = list(cxs)\n",
    "        if shuffle: \n",
    "            random.shuffle(cxs)\n",
    "        for cx in cxs[:end]:\n",
    "            se.showcx(cx, **tfkwargs)\n",
    "        return cxs\n",
    "            \n",
    "    # display cxs in an iterable of surface forms\n",
    "    elif view:\n",
    "        view_list = [\n",
    "            cx for surf in view\n",
    "                for cx in surface2cx[surf]\n",
    "        ]\n",
    "        if shuffle:\n",
    "            random.shuffle(view_list)\n",
    "        for cx in view_list[:end]:\n",
    "            se.showcx(cx, **tfkwargs)\n",
    "        return view_list\n",
    "    \n",
    "    else:\n",
    "        return list(cxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CXBuilders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# copy cxs for modification by builder\n",
    "cx_dataset = set(\n",
    "    tuple(copy.deepcopy(cx_data))\n",
    "        for ph, cx_data in phrase2cxs.items()\n",
    ")\n",
    "\n",
    "class SinglePhrase(CXbuilder):\n",
    "    \"\"\"Modify cx classifications for single phrase CXs\"\"\"\n",
    "    \n",
    "    def __init__(self, cxset, tf):\n",
    "        CXbuilder.__init__(self) # initialize with standard CXbuilder methods\n",
    "        \n",
    "        self.cxset = cxset\n",
    "        self.api = tf\n",
    "        self.F, self.L = tf.api.F, tf.api.L\n",
    "        \n",
    "        # cx queries\n",
    "        # NB: order matters!\n",
    "        self.cxs = (\n",
    "            self.prep,\n",
    "            self.bare,\n",
    "            self.definite,\n",
    "            self.def_appo,\n",
    "            self.genitive,\n",
    "            self.quantified,\n",
    "            self.adjective,\n",
    "        )\n",
    "        self.prereq = self.single\n",
    "        self.kind = 'time_class'\n",
    "        \n",
    "        self.class2cx = collections.defaultdict(set)\n",
    "        \n",
    "    def test_result(self, test, *cases):\n",
    "        \"\"\"Add class attributes to CX results\"\"\"\n",
    "        if test:\n",
    "            result = test[-1]\n",
    "            cx = result['element']\n",
    "            classi= result['class']\n",
    "            cx.__dict__.setdefault('classification', []).extend(classi)\n",
    "            cx.match = result\n",
    "            cx.conds = result['conds']\n",
    "            cx.cases = (result,) + cx.cases\n",
    "            return cx\n",
    "        else:\n",
    "            return Construction(cases=cases, **cases[0])\n",
    "    \n",
    "    def findall(self, element):\n",
    "        \"\"\"Find all results with prerequisite\n",
    "        \n",
    "        NB this version of findall only returns\n",
    "        a single result: the construction object\n",
    "        itself, since it is modified in-place.\n",
    "        This version expects cx tuples with\n",
    "        only one cx.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        if self.prereq(element):\n",
    "            for funct in self.cxs:\n",
    "                cx = funct(element)\n",
    "                if cx:\n",
    "                    results.append(cx)\n",
    "        if results:\n",
    "            return results[0] # NB, only 1st matters as all are same obj\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def label_cxs(self):\n",
    "        \"\"\"Run all queries against dataset\"\"\"\n",
    "        for cxtuple in self.cxset:\n",
    "            cx = self.findall(cxtuple)\n",
    "            if cx:\n",
    "                for tag in cx.classification:\n",
    "                    self.class2cx[tag].add(cx)\n",
    "    \n",
    "    def geta(self, item, attrib, default=None):\n",
    "        \"\"\"Safely retrieve attribute from object\n",
    "        \n",
    "        Some objects in a CX graph are TF integer\n",
    "        nodes, while most are CX objects. In order\n",
    "        to safely call attributes on a given position,\n",
    "        we need to handle attribute errors when called\n",
    "        on an integer.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return item.__dict__[attrib]\n",
    "        except AttributeError:\n",
    "            return default\n",
    "    \n",
    "    def get_headword(self, cx):\n",
    "        \"\"\"Get a word that serves as head\"\"\"\n",
    "        head = list(cx.getsuccroles('head'))[-1]\n",
    "        return head\n",
    "    \n",
    "    def get_head_modi(self, head, cx, name, default=Construction()):\n",
    "        \"\"\"Retrieve a modifier on a particular head\"\"\"\n",
    "        for c in cx.graph:\n",
    "            if (self.geta(c,'name') == name) and (head in c):\n",
    "                return c\n",
    "        # unsuccessful search\n",
    "        return default\n",
    "    \n",
    "    def single(self, cxtuple):\n",
    "        \"\"\"Tag CXs as singles\"\"\"\n",
    "        cx1 = cxtuple[0]\n",
    "        relas = set(\n",
    "            self.geta(c,'name') for c in cx1\n",
    "        )\n",
    "        bhsa_phrase = L.u(cx1.slots[0], 'phrase')[0]\n",
    "        attr_cl = E.mother.t(bhsa_phrase)\n",
    "        \n",
    "        return self.test(\n",
    "            {\n",
    "                'element': cxtuple[0],\n",
    "                'class': ['single'],\n",
    "                'kind': self.kind,\n",
    "                'conds': {\n",
    "                    'len(cxtuple) == 1':\n",
    "                        len(cxtuple) == 1,\n",
    "                    'no apposition in cx':\n",
    "                        not relas & {'appo'},\n",
    "                    'no attributive clause on phrase':\n",
    "                        not attr_cl\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def prep(self, cxtuple):\n",
    "        \"\"\"Tag prepositional cxs\"\"\"\n",
    "        cx = cxtuple[0]\n",
    "        return self.test(\n",
    "            {\n",
    "                'element': cx,\n",
    "                'class': ['prep'],\n",
    "                'kind': self.kind,\n",
    "                'conds': {\n",
    "                    'cx.name == prep_ph':\n",
    "                        cx.name == 'prep_ph',\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'element': cx,\n",
    "                'class': ['øprep'],\n",
    "                'conds': {\n",
    "                    'cx.name != prep_ph':\n",
    "                        cx.name != 'prep_ph',\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def bare(self, cxtuple):\n",
    "        \"\"\"Tag bare, non-modified cxs\"\"\"\n",
    "        F = self.F\n",
    "        cx = cxtuple[0]\n",
    "        head_path = list(cx.getsuccroles('head'))\n",
    "        head = head_path[-1]\n",
    "        etcbc_phrase = self.L.u(int(head),'phrase')[0]\n",
    "        \n",
    "        # two types of units allowed in the path:\n",
    "        # word cxs or prep_ph\n",
    "        # trace path to head and collect relations along the way\n",
    "        cx_name = cx.name if cx.kind != 'word_cx' else cx.kind\n",
    "        head_phs = {cx_name}\n",
    "        for c in head_path:\n",
    "            if self.geta(c,'kind') == 'subphrase':\n",
    "                head_phs.add(c.name)\n",
    "            else:\n",
    "                head_phs.add('word_cx')\n",
    "        \n",
    "        prereqs = {\n",
    "            'head_phs is subset of {word_cx, prep_ph}':\n",
    "                head_phs.issubset({'word_cx', 'prep_ph', 'advb'}),\n",
    "            'F.st.v(head) != c':\n",
    "                F.st.v(int(head)) != 'c',\n",
    "            'not daughters(etcbc_phrase)':\n",
    "                not E.mother.t(etcbc_phrase),\n",
    "        }\n",
    "        \n",
    "        return self.test(\n",
    "            {\n",
    "                'element': cx,\n",
    "                'class': ['bare'],\n",
    "                'kind': self.kind,\n",
    "                'conds': dict({\n",
    "                    'F.prs.v(head) in {n/a, absent}':\n",
    "                        F.prs.v(int(head)) in {'n/a', 'absent'},\n",
    "                }, **prereqs)\n",
    "            },\n",
    "            {\n",
    "                'element': cx,\n",
    "                'class': ['suffix'],\n",
    "                'kind': self.kind,\n",
    "                'conds': dict({\n",
    "                    'F.prs.v(head) not in {n/a, absent}':\n",
    "                        F.prs.v(int(head)) not in {'n/a', 'absent'},\n",
    "                }, **prereqs)\n",
    "            },\n",
    "        )\n",
    "    \n",
    "    def definite(self, cxtuple):\n",
    "        \"\"\"A definite phrase\"\"\"\n",
    "        cx = cxtuple[0]\n",
    "        head = self.get_headword(cx)\n",
    "        def_ph = self.get_head_modi(head, cx, 'defi_ph')\n",
    "        \n",
    "        return self.test(\n",
    "            {\n",
    "                'element': cx,\n",
    "                'class': ['definite'],\n",
    "                'kind': self.kind,\n",
    "                'conds': {\n",
    "                    'cx contains defi phrase with head':\n",
    "                        bool(def_ph)\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        )\n",
    "    \n",
    "    def def_appo(self, cxtuple):\n",
    "        \"\"\"Definite apposition\"\"\"\n",
    "        \n",
    "        F = self.F\n",
    "        geta = self.geta\n",
    "        cx = cxtuple[0]\n",
    "        head = self.get_headword(cx)\n",
    "        \n",
    "        # get attribute cx if it contains head word\n",
    "        att_ph = self.get_head_modi(head, cx, 'attrib_ph')\n",
    "        \n",
    "        return self.test(\n",
    "            {\n",
    "                'element': cx,\n",
    "                'class': ['def_apposition'],\n",
    "                'kind': self.kind,\n",
    "                'conds': {\n",
    "                    f'cx contains attrib ph with head':\n",
    "                        bool(att_ph)\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'element': cx,\n",
    "                'class': ['def_apposition', 'demonstrative'],\n",
    "                'kind': self.kind,\n",
    "                'conds': {\n",
    "                    f'cx contains attrib ph with head':\n",
    "                        bool(att_ph),\n",
    "                    'apposition contains demonstrative':\n",
    "                        {'prde', 'prps'} & set(\n",
    "                            F.pdp.v(w) for w in att_ph.getrole('attrib', Construction()).slots\n",
    "                        )\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'element': cx,\n",
    "                'class': ['def_apposition', 'ordinal'],\n",
    "                'kind': self.kind,\n",
    "                'conds': {\n",
    "                    f'cx contains attrib ph with head':\n",
    "                        bool(att_ph),\n",
    "                    'apposition contains ordinal':\n",
    "                        'ordn' in set(\n",
    "                            geta(c,'name') for c in att_ph.graph\n",
    "                        ),\n",
    "                }\n",
    "            },\n",
    "        )\n",
    "    \n",
    "    def genitive(self, cxtuple):\n",
    "        \"\"\"Genitive relation on head\"\"\"\n",
    "        cx = cxtuple[0]\n",
    "        head = self.get_headword(cx)\n",
    "        geni_ph = self.get_head_modi(head, cx, 'geni_ph')\n",
    "        geni_items = set(\n",
    "            self.geta(c, 'name') for c in geni_ph\n",
    "        )\n",
    "        return self.test(\n",
    "            {\n",
    "                'element': cx,\n",
    "                'class': ['genitive'],\n",
    "                'kind': self.kind,\n",
    "                'conds': {\n",
    "                    'cx contains geni phrase on head':\n",
    "                        bool(geni_ph)\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'element': cx,\n",
    "                'class': ['geni_cardinal'],\n",
    "                'kind': self.kind,\n",
    "                'conds': {\n",
    "                    'cx contains geni phrase on head':\n",
    "                        bool(geni_ph),\n",
    "                    \n",
    "                    'a cardinal is genitive to this word':\n",
    "                        'card' in geni_items,\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def quantified(self, cxtuple):\n",
    "        \"\"\"Find quantified time phrases\"\"\"\n",
    "        cx = cxtuple[0]\n",
    "        head = self.get_headword(cx)\n",
    "        quant_ph = self.get_head_modi(head, cx, 'numb_ph')\n",
    "        geta = self.geta\n",
    "        return self.test(\n",
    "            {\n",
    "                'element': cx,\n",
    "                'class': ['quantified', 'cardinal'],\n",
    "                'kind': self.kind,\n",
    "                'conds': {\n",
    "                    'cx contains numbered phrase on head':\n",
    "                        bool(quant_ph),\n",
    "                    \n",
    "                    'does not contain qualitative quant':\n",
    "                        'qquant' not in set(\n",
    "                            geta(c,'name') for c in quant_ph\n",
    "                        )\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'element': cx,\n",
    "                'class': ['quantified', 'qualitative'],\n",
    "                'kind': self.kind,\n",
    "                'conds': {\n",
    "                    'cx contains numbered phrase on head':\n",
    "                        bool(quant_ph),\n",
    "                    \n",
    "                    'contains qualitative quant':\n",
    "                        'qquant' in set(\n",
    "                            geta(c,'name') for c in quant_ph\n",
    "                        )\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'element': cx,\n",
    "                'class': ['cardinal'],\n",
    "                'kind': self.kind,\n",
    "                'conds': {\n",
    "                    'cx.name == card_chain':\n",
    "                        cx.name == 'card_chain'\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def adjective(self, cxtuple):\n",
    "        \"\"\"Adjectival modifications via non-definite apposition\"\"\"\n",
    "        cx = cxtuple[0]\n",
    "        head = self.get_headword(cx)\n",
    "        adjv_ph = self.get_head_modi(head, cx, 'adjv_ph')\n",
    "        \n",
    "        return self.test(\n",
    "            {\n",
    "                'element': cx,\n",
    "                'class': ['adjective'],\n",
    "                'kind': self.kind,\n",
    "                'conds': {\n",
    "                    'cx contains adjectival phrase on head':\n",
    "                        bool(adjv_ph),\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'element': cx,\n",
    "                'class': ['demonstrative'],\n",
    "                'kind': self.kind,\n",
    "                'conds': {\n",
    "                    'cx is a demonstrative phrase':\n",
    "                        cx.name == 'demon_ph',\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    \n",
    "# tag patterns in CXs\n",
    "sp = SinglePhrase(cx_dataset, A)\n",
    "sp.label_cxs()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% (3281) classified\n",
      "0.0% (0) unclassified\n",
      "\n",
      "Class counts:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>single</th>\n",
       "      <td>3281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep</th>\n",
       "      <td>1895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>øprep</th>\n",
       "      <td>1386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>definite</th>\n",
       "      <td>1273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bare</th>\n",
       "      <td>1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_apposition</th>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantified</th>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demonstrative</th>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genitive</th>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardinal</th>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qualitative</th>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ordinal</th>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suffix</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adjective</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geni_cardinal</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total\n",
       "single           3281\n",
       "prep             1895\n",
       "øprep            1386\n",
       "definite         1273\n",
       "bare             1047\n",
       "def_apposition    633\n",
       "quantified        564\n",
       "demonstrative     485\n",
       "genitive          415\n",
       "cardinal          356\n",
       "qualitative       209\n",
       "ordinal           148\n",
       "suffix            118\n",
       "adjective          14\n",
       "geni_cardinal      14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 25 unclassified surface forms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Total]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "track = Tracker(\n",
    "    sp.class2cx,\n",
    "    cx_dataset,\n",
    "    exclude={\n",
    "        'single', 'multi',\n",
    "        'prep', 'øprep',\n",
    "    },\n",
    ")\n",
    "\n",
    "track.prog(head=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See remaining forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ph = phrase2cxs[1450440]\n",
    "# test_ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = sp.bare(test_ph)\n",
    "# test.conds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remaining = track.see_remaining(['ב.דור.אחר'], condenseType='sentence', end=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>שׁלשׁים.ו.שׁלושׁ</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Total\n",
       "שׁלשׁים.ו.שׁלושׁ      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = SetSelection(sp.class2cx)\n",
    "\n",
    "show_cl = show_classes(\n",
    "    classes,\n",
    "    ('single', 'cardinal'),\n",
    "    exclude=('quantified'),\n",
    "    end=5,\n",
    "    counts=True,\n",
    "    #view=['עתה.זה'],\n",
    "    shuffle=True,\n",
    "    condenseType='sentence'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Scratch Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Phrasals\n",
    "\n",
    "### To-Do\n",
    "\n",
    "I have currently written the SinglePhrase builder with only single-phrased examples in mind. However, this misses the important fact that many multi-phrasal CXs will likewise have single-phrasal component parts. I can re-write the single phrase CXBuilder to receive cxs that are also from multi-phrasal items. Yet this approach would be complicated by the fact that not all phrases within a multi-phrasal time construction will be time-oriented. The result would be that I would have skewed class statistics. For example, if a phrase is \"למלך\" as part of a calendrical CX, it would end up getting counted as a \"prepositional\" and \"definite\" time cx. But it is not itself a time CX, only a part of one. But in other cases, the phrase may indeed also be able to function as its own independent time CX, such as in יום ביום. But even this example raises the issue of whether this CX can truly be decomposed into those smaller parts.\n",
    "\n",
    "It is worth considering whether it is better to:\n",
    "\n",
    "1. utilize the same rules in the single-phrasal builder to tag constituent phrases in multi-phrasal time CXs\n",
    "2. re-write many rules separately, at the risk of duplicating logic already handled in single-phrases.\n",
    "\n",
    "Option 1 has the strength of enforcing consistency across all categories, whereas option 2 has the ability to cater solutions specific to multi-phrasal constructions. \n",
    "\n",
    "**I lean toward option 2.** There are likely many phrases, specific to certain constructions, that do not contain heads that are lexicalized for time. These need to be defined individually. It might mean that certain lower level patterns are duplicated. But that would also mean that they are available for future restrictions and modifications specific to multi-phrasal constructions. \n",
    "\n",
    "An option 3 might be to require the SinglePhrase Builder as an argument to the MultiPhrase Builder, and use only the patterns which are relevant. This would allow me to take advantage of both situations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
